{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!python\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from operator import itemgetter\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import (\n",
    "                                    Dense,\n",
    "                                    Conv2D, \n",
    "                                    BatchNormalization, \n",
    "                                    ReLU, \n",
    "                                    Add,\n",
    "                                    Input,\n",
    "                                    MaxPooling2D,\n",
    "                                    UpSampling2D,\n",
    "                                    )\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from math import exp\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de Datos/Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_MIN_OF_IMGS_FOR_TRAINING = 0\n",
    "NUMBER_MAX_OF_IMGS_FOR_TRAINING = 5000\n",
    "########################################################################################################################################################\n",
    "def generate_dataset_obj(obj):\n",
    "    if type(obj) == np.ndarray:\n",
    "        dim = obj.shape[0]\n",
    "        if dim == 1:\n",
    "            ret = generate_dataset_obj(obj[0])             \n",
    "        else:\n",
    "            ret = []\n",
    "            for i in range(dim):\n",
    "                ret.append(generate_dataset_obj(obj[i]))                \n",
    "\n",
    "    elif type(obj) == scipy.io.matlab.mio5_params.mat_struct:\n",
    "        ret = {}\n",
    "        for field_name in obj._fieldnames:            \n",
    "            field = generate_dataset_obj(obj.__dict__[field_name])\n",
    "            if field_name in must_be_list_fields:\n",
    "                field = [field]\n",
    "                ret[field_name] = field\n",
    "\n",
    "    else:\n",
    "        ret = obj\n",
    "\n",
    "    return ret\n",
    "########################################################################################################################################################\n",
    "def generate_dataset_obj(obj):\n",
    "    if type(obj) == np.ndarray:\n",
    "        dim = obj.shape[0]\n",
    "        if dim == 1:\n",
    "            ret = generate_dataset_obj(obj[0])             \n",
    "        else:\n",
    "            ret = []\n",
    "            for i in range(dim):\n",
    "                ret.append(generate_dataset_obj(obj[i]))                \n",
    "\n",
    "    elif type(obj) == scipy.io.matlab.mio5_params.mat_struct:\n",
    "        ret = {}\n",
    "        for field_name in obj._fieldnames:            \n",
    "            field = generate_dataset_obj(obj.__dict__[field_name])\n",
    "            if field_name in must_be_list_fields:\n",
    "                field = [field]\n",
    "                ret[field_name] = field\n",
    "\n",
    "    else:\n",
    "        ret = obj\n",
    "\n",
    "    return ret\n",
    "\n",
    "########################################################################################################################################################\n",
    "def print_dataset_obj(obj, depth = 0, maxIterInArray = 20):\n",
    "    prefix = \"  \"*depth\n",
    "    if type(obj) == dict:\n",
    "        for key in obj.keys():\n",
    "            print(\"{}{}\".format(prefix, key))\n",
    "            print_dataset_obj(obj[key], depth + 1)\n",
    "    elif type(obj) == list:\n",
    "        for i, value in enumerate(obj):\n",
    "            if i >= maxIterInArray:\n",
    "                break\n",
    "            print(\"{}{}\".format(prefix, i))\n",
    "            print_dataset_obj(value, depth + 1)\n",
    "    else:\n",
    "        print(\"{}{}\".format(prefix, obj))\n",
    "########################################################################################################################################################\n",
    "def return_image_joints(name,data):\n",
    "    for item in data: # guardar coordenadas de los joints\n",
    "        if item[0] == name:\n",
    "            #print(item[1]) \n",
    "            return item[1]\n",
    "########################################################################################################################################################\n",
    "rightconnections = [\n",
    "                    (0,1),(1,2),(3,4),(4,5),(2,6),\n",
    "                    (3,6),(6,7),(7,8),(8,9),(10,11),\n",
    "                    (11,12),(12,7),(13,7),(13,14),(14,15)\n",
    "                   ]\n",
    "size_img_x = 256\n",
    "size_img_y = 256\n",
    "def draw_img_joints(file_name, data, resize = False ):    \n",
    "    # Load image\n",
    "    #img = cv2.imread(Path_To_Single_Person_Images + \"/\" + file_name,1)  \n",
    "    img = image.load_img(Path_To_Single_Person_Images + \"/\" + file_name)\n",
    "    img = image.img_to_array(img) \n",
    "    img = img/255\n",
    "    if resize:\n",
    "        img = np.float32(tf.image.resize(img,(size_img_x, size_img_y)))  \n",
    "    pts = return_image_joints(file_name, data)        \n",
    "    #plt.imshow(img)  \n",
    "    X = [x[0] for x in pts]\n",
    "    Y = [y[1] for y in pts]\n",
    "    X = [int(x) for x in X]\n",
    "    Y = [int(y) for y in Y]\n",
    "    \n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if (i,j) in rightconnections:\n",
    "                if X[i]>0 and X[j]>0 and Y[i]>0 and Y[j]>0:\n",
    "                    img = cv2.line(img,(X[i],Y[i]),(X[j],Y[j]),(1,0,0),5)\n",
    "                    plt.scatter(X[i], Y[i], marker=\"o\", color=\"red\", s=20)\n",
    "                    plt.scatter(X[j], Y[j], marker=\"o\", color=\"red\", s=20)\n",
    "                    \n",
    "    plt.imshow(img)\n",
    "########################################################################################################################################################\n",
    "def crop_resize(imagen, joints, scale, margin = 0.2):\n",
    "    # CROP PART\n",
    "    xmin = 9999\n",
    "    ymin = 9999\n",
    "    xmax = -1\n",
    "    ymax = -1\n",
    "    body_height_margin = scale * 200 * margin\n",
    "    img_height = imagen.shape[0]\n",
    "    img_width = imagen.shape[1]\n",
    "    for item in joints:\n",
    "        if item[0] >= 0 and item[0] < xmin : xmin = item[0]\n",
    "        if item[1] >= 0 and item[1] < ymin : ymin = item[1] \n",
    "        if item[0] >= 0 and item[0] > xmax : xmax = item[0]\n",
    "        if item[1] >= 0 and item[1] > ymax : ymax = item[1]    \n",
    "    xmin = int(xmin - body_height_margin)\n",
    "    ymin = int(ymin - body_height_margin)\n",
    "    xmax = int(xmax + body_height_margin)\n",
    "    ymax = int(ymax + body_height_margin)\n",
    "    if xmin < 0: xmin = 0\n",
    "    if ymin < 0: ymin = 0\n",
    "    if xmax > img_width: xmax = img_width\n",
    "    if ymax > img_height: ymax = img_height\n",
    "    imagen = imagen[ymin:ymax, xmin:xmax, :]\n",
    "    #print(\"xmin:\",xmin,\", ymin: \",ymin,\", xmax: \",xmax,\", ymax: \",ymax)\n",
    "    #RESIZE PART\n",
    "    img_new_height = imagen.shape[0]\n",
    "    img_new_width = imagen.shape[1]\n",
    "    scala_x = img_new_width / size_img_x\n",
    "    scala_y = img_new_height / size_img_y\n",
    "    for i in range(16): # escala los puntos clave\n",
    "        joints[i] = np.array([(joints[i][0] - xmin) / scala_x, (joints[i][1] - ymin) / scala_y]) \n",
    "        #print(\"x:\",joints[i][0],\", y: \",joints[i][1])\n",
    "    imagen = tf.image.resize(imagen,(size_img_x, size_img_y))       \n",
    "    imagen = imagen/255\n",
    "    \n",
    "    return imagen\n",
    "########################################################################################################################################################    \n",
    "def load_image(train_data, a, b):\n",
    "    train = np.asarray(train_data[a:b])\n",
    "    train_image = np.zeros((b-a,size_img_x,size_img_y,3))\n",
    "    #print(train[2])\n",
    "    for i in tqdm(range(a,b)):\n",
    "        name_img = train[i][0]\n",
    "        img = image.load_img(Path_To_Single_Person_Images + '/' + name_img)\n",
    "        img = image.img_to_array(img) \n",
    "        #crop and resize\n",
    "        train_image[i] = crop_resize(img, train[i][1], train[i][2])\n",
    "    return train_image, train\n",
    "########################################################################################################################################################\n",
    "def MakeHeatmap(x, y, width, height, show = False):\n",
    "    # Probability as a function of distance from the center derived\n",
    "    # from a gaussian distribution with mean = 0 and stdv = 1\n",
    "    scaledGaussian = lambda x : exp(-(1/2)*(x**2))\n",
    "\n",
    "    imgSize = (height, width)\n",
    "    center_x = x\n",
    "    center_y = y\n",
    "\n",
    "    isotropicGrayscaleImage = np.zeros((imgSize[0],imgSize[1]),np.uint8)\n",
    "    \n",
    "    if center_x > 0 and center_y > 0 :\n",
    "        for i in range(imgSize[0]):\n",
    "            for j in range(imgSize[1]):\n",
    "\n",
    "                # find euclidian distance from center of image (x,y) \n",
    "                # and scale it to range of 0 to 2.5 as scaled Gaussian\n",
    "                # returns highest probability for x=0 and approximately\n",
    "                # zero probability for x > 2.5\n",
    "\n",
    "                distanceFromCenter = np.linalg.norm(np.array([i-center_y,j-center_x]))\n",
    "                #distanceFromCenter = 18*distanceFromCenter/(imgSize/2)\n",
    "                scaledGaussianProb = scaledGaussian(distanceFromCenter)\n",
    "                isotropicGrayscaleImage[i,j] = np.clip(scaledGaussianProb*255,0,255)   \n",
    "\n",
    "        return isotropicGrayscaleImage\n",
    "    else: \n",
    "        return isotropicGrayscaleImage\n",
    "########################################################################################################################################################    \n",
    "def Joints_heatmaps(lista_de_joints, heatmap_size_x, heatmap_size_y, num_heatmaps = 16, show = False):\n",
    "    heatmaps = np.zeros((16,64,64))\n",
    "    for i in range(num_heatmaps):\n",
    "        x, y = lista_de_joints[i] \n",
    "        x = x / 4 # entre 4 por que el array es de 256x256\n",
    "        y = y / 4 # entre 4 por que el array es de 256x256\n",
    "        heatmaps[i] = MakeHeatmap(x, y, heatmap_size_x, heatmap_size_y)\n",
    "    if show:\n",
    "        plotImages(heatmaps, num_heatmaps)\n",
    "    return heatmaps\n",
    "########################################################################################################################################################        \n",
    "def plotImages(images_arr, num_images):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(60,60))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "########################################################################################################################################################    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos, Generación de heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divimos la data para ingresarla al modelo,\n",
    "if os.path.isfile('X_train.npy') and os.path.isfile('X_test.npy') and os.path.isfile('y_train.npy') and os.path.isfile('y_test.npy'):    \n",
    "    #Primero comprobamos si existen ya datos para usar en el modelo, si hay los mapeamos, no se cargan a la ram, se leen desde disco \n",
    "    X_train = np.load('X_train.npy', mmap_mode='r')\n",
    "    X_test = np.load('X_test.npy', mmap_mode='r')\n",
    "    y_train = np.load('y_train.npy', mmap_mode='r')\n",
    "    y_test = np.load('y_test.npy', mmap_mode='r')  \n",
    "else:      \n",
    "    # si no existen entonces iniciamos el preprocesado:   \n",
    "    ########################################################################################################################################################\n",
    "    if os.path.isfile('lista_de_imagenes.npy') and os.path.isfile('lista_de_heatmaps.npy'):    \n",
    "        #Ahora cargamos las imagenes y sus heatmaps\n",
    "        lista_de_heatmaps = np.load('lista_de_heatmaps.npy', mmap_mode='r')  \n",
    "        lista_de_imagenes = np.load('lista_de_imagenes.npy', mmap_mode='r')    \n",
    "    else: \n",
    "        ########################################################################################################################################################\n",
    "        #darle formato de diccionario\n",
    "        matph = './mpii.mat'\n",
    "        decoded1 = loadmat(matph, struct_as_record=False)[\"RELEASE\"]\n",
    "        must_be_list_fields = [\"annolist\",\"image\",\"name\", \"annorect\", \"scale\", \"x\", \"y\", \"annopoints\", \"point\", \"id\"]\n",
    "        # Convert to dict\n",
    "        dataset_obj = generate_dataset_obj(decoded1)\n",
    "        # Print it out\n",
    "        #print_dataset_obj(dataset_obj)\n",
    "        len(dataset_obj['annolist'][0])\n",
    "        #solo queremos la información en 'annolist'\n",
    "        dataset = dataset_obj['annolist'][0]\n",
    "        ########################################################################################################################################################\n",
    "        #guardamos solo informacion de las imagenes que tienen solo una persona\n",
    "        train_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            if \"annopoints\" in dataset[i]['annorect'][0]:     \n",
    "                name = dataset[i]['image'][0]['name'][0]\n",
    "                scale = dataset[i]['annorect'][0]['scale'][0]\n",
    "                tupla = np.full((16, 3), -1) #creo un prototipo de array de joints lleno de -1 si la articulación es visible se reemplaza el -1\n",
    "                for j in range(len(dataset[i]['annorect'][0]['annopoints'][0]['point'][0])):     #ordena los puntos de articulaciones del id = 0 al id = 15       \n",
    "                    try:\n",
    "                        x = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['x'][0]\n",
    "                    except:\n",
    "                        x = -1\n",
    "                    try:\n",
    "                        y = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['y'][0]\n",
    "                    except:\n",
    "                        y = -1\n",
    "                    try:\n",
    "                        joint_id = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['id'][0]\n",
    "                    except:\n",
    "                        joint_id = -1          \n",
    "                    tupla[joint_id] = np.array([x,y,joint_id]) # esto lo ordena\n",
    "                #tupla = sorted(tupla, key = itemgetter(2)) \n",
    "                #tupla = tupla[np.argsort(tupla[:, 2])] \n",
    "                tupla = np.delete(tupla, 2, 1)  #quita id de las tuplas,                    \n",
    "                #pasa de tupla a array\n",
    "                tupla = np.asarray(tupla)        \n",
    "                train_data.append((name,tupla,scale))\n",
    "        #Creamos un array para guardar los nombres        \n",
    "        names = []\n",
    "        for item in train_data:#guardar nombres de las imagenes que voy a usar en \"name\"\n",
    "            names.append(item[0])\n",
    "        ########################################################################################################################################################\n",
    "        #Crear Carpeta para guardar imagenes del dataset\n",
    "        Path_To_Raw_Images = 'DataSet/mpii_human_pose_v1_images'\n",
    "        Path_To_Single_Person_Images = 'DataSet/mpii_human_pose_v1_images/SinglePersonImagesWithData'\n",
    "        os.chdir(Path_To_Raw_Images)\n",
    "\n",
    "        if os.path.isdir('SinglePersonImagesWithData') is False:\n",
    "            os.makedirs('SinglePersonImagesWithData')\n",
    "            for images in names:\n",
    "                shutil.move(images, 'SinglePersonImagesWithData')\n",
    "\n",
    "        os.chdir('../../')\n",
    "\n",
    "        #Demostración dibujar joints en imagenes con data\n",
    "        #draw_img_joints('060111501.jpg',train_data)\n",
    "        ########################################################################################################################################################\n",
    "        #Ahora cargamos las imagenes\n",
    "        lista_de_imagenes, lista_de_joints = load_image(train_data,NUMBER_MIN_OF_IMGS_FOR_TRAINING,NUMBER_MAX_OF_IMGS_FOR_TRAINING)\n",
    "        np.save('lista_de_imagenes', lista_de_imagenes)\n",
    "        ########################################################################################################################################################\n",
    "        #Ahora creamos los heatmaps para lista_de_imagenes:\n",
    "        heatmap_size_x = 64\n",
    "        heatmap_size_y = 64 \n",
    "        #dibujo_test_heatmaps = Joints_heatmaps(lista_de_joints[0][1], heatmap_size_x, heatmap_size_y, show = False)\n",
    "        #creamos los heatmaps de nuestra data\n",
    "        lista_de_heatmaps = np.zeros((NUMBER_MAX_OF_IMGS_FOR_TRAINING - NUMBER_MIN_OF_IMGS_FOR_TRAINING,heatmap_size_x,heatmap_size_y,16))\n",
    "        for i in tqdm(range(lista_de_joints.shape[0])):\n",
    "            joints = return_image_joints(lista_de_joints[i][0], lista_de_joints)\n",
    "            lista_de_heatmaps[i] = np.moveaxis(Joints_heatmaps(joints, heatmap_size_x, heatmap_size_y), 0, -1) # change shape from 16x64x64 to 64x64x16\n",
    "        #guardamos el array    \n",
    "        np.save('lista_de_heatmaps', lista_de_heatmaps)\n",
    "        #liberamos memoria cargando los archivos desde disco\n",
    "        lista_de_heatmaps = np.load('lista_de_heatmaps.npy', mmap_mode='r')  \n",
    "        lista_de_imagenes = np.load('lista_de_imagenes.npy', mmap_mode='r') \n",
    "        #plotImages(lista_de_heatmaps[67], 16)\n",
    "    ######################################################################################################################################################## \n",
    "    X_train, X_test, y_train, y_test = train_test_split(lista_de_imagenes, lista_de_heatmaps, random_state=7, test_size=0.2)\n",
    "    #guardamos en disco y liberamos ram\n",
    "    np.save('X_train', X_train)\n",
    "    X_train = np.load('X_train.npy', mmap_mode='r')\n",
    "    np.save('X_test', X_test)\n",
    "    X_test = np.load('X_test.npy', mmap_mode='r')\n",
    "    np.save('y_train', y_train)\n",
    "    y_train = np.load('y_train.npy', mmap_mode='r')\n",
    "    np.save('y_test', y_test)\n",
    "    y_test = np.load('y_test.npy', mmap_mode='r')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###test part\\nimgidtest = 9\\nprint(\"image name: \",lista_de_joints[imgidtest][0])\\nprint(\"joints locations: \\n\",lista_de_joints[imgidtest][1])\\nprint(\"scale: \",lista_de_joints[imgidtest][2])\\nplt.imshow(lista_de_imagenes[imgidtest])\\nplotImages(np.moveaxis(lista_de_heatmaps[imgidtest], -1, 0),16)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"###test part\n",
    "imgidtest = 9\n",
    "print(\"image name: \",lista_de_joints[imgidtest][0])\n",
    "print(\"joints locations: \\n\",lista_de_joints[imgidtest][1])\n",
    "print(\"scale: \",lista_de_joints[imgidtest][2])\n",
    "plt.imshow(lista_de_imagenes[imgidtest])\n",
    "plotImages(np.moveaxis(lista_de_heatmaps[imgidtest], -1, 0),16)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(inputs, \n",
    "           filters, \n",
    "           kernel_size = 1,\n",
    "           strides = 1,\n",
    "           padding = 'same',\n",
    "           kernel_initializer = 'he_normal',\n",
    "           activation = True,\n",
    "           batch_normalization = True,\n",
    "           name = \"conv\"):\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,\n",
    "            use_bias=False, kernel_initializer=kernel_initializer)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = ReLU()(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquitectura ResNetV2 de cuello de botella\n",
    "def ResNetV2(inputs, filters, strides = 1, lift_channels = False, name = 'bloque'):\n",
    "    \n",
    "    res = inputs\n",
    "    #incrementa el número de canales si es necesario\n",
    "    if lift_channels:\n",
    "        res = conv2D(\n",
    "            inputs,\n",
    "            filters,\n",
    "            activation = False,\n",
    "            batch_normalization = False)\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    #conv de tamaño 1x1\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters/2)\n",
    "    \n",
    "    #conv de tamaño 3x3\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters/2,\n",
    "        kernel_size = 3)\n",
    "    \n",
    "    #conv de tamaño 1x1\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters,\n",
    "        activation = False,\n",
    "        batch_normalization = False)\n",
    "    \n",
    "    x = Add()([res,x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassUnit(inputs, depth, filters, resnet_per_block, name = 'hourglass_'):    \n",
    "    \n",
    "    #Capas \"superiores\"\n",
    "    up_1 = ResNetV2(inputs,filters)\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        up_1 = ResNetV2(up_1, filters)\n",
    "    \n",
    "    #Capas \"inferiores\"\n",
    "    #Reducir resolución\n",
    "    low_1 = MaxPooling2D(pool_size = 2, strides = 2)(inputs)\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        low_1 = ResNetV2(low_1, filters)\n",
    "    \n",
    "    low_2 = low_1\n",
    "    if depth > 1 : \n",
    "        low_2 = HourglassUnit(low_1, depth-1, filters, resnet_per_block)\n",
    "    else:\n",
    "        low_2 = ResNetV2(low_2, filters)\n",
    "    \n",
    "    low_3 = low_2\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        low_3 = ResNetV2(low_3, filters)\n",
    "    \n",
    "    #Aumentar resolución\n",
    "    up_2 = UpSampling2D()(low_3)\n",
    "    \n",
    "    return Add()([up_1,up_2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassNetwork(input_shape = (256,256,3), stacks = 8, resnet_per_block = 3, heatmaps = 16):\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    #la data llega en formato 256x256x3, la pasamos a 64x64x256\n",
    "    #preprocessing\n",
    "    #amplia canales a 64\n",
    "    x = conv2D(\n",
    "        inputs,\n",
    "        filters = 64,\n",
    "        kernel_size = 7,\n",
    "        strides = 2)\n",
    "    #amplia canales de 64 a 128 \n",
    "    x = ResNetV2(x, filters = 128, lift_channels = True)\n",
    "    x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "    x = ResNetV2(x, filters = 128)\n",
    "    #amplia canales de 64 a 128\n",
    "    x = ResNetV2(x, filters = 256, lift_channels = True)\n",
    "    skip = x\n",
    "    y_heatmaps = []\n",
    "    \n",
    "    for i in range(stacks):\n",
    "        x = HourglassUnit(skip, depth = 4, filters = 256, resnet_per_block = resnet_per_block)\n",
    "        \n",
    "        x = ResNetV2(x, filters = 256)\n",
    "        \n",
    "        #prediccion de 256 canales \n",
    "        x = conv2D(x, filters = 256)\n",
    "        \n",
    "        #prediccion temporal de heatmaps\n",
    "        y = conv2D(x, filters = heatmaps)\n",
    "        #agregamos el resultado temportal al array de resultados para la supervision intermedia\n",
    "        y_heatmaps.append(y)\n",
    "        \n",
    "        #ahora regresamos el tensor y al orden de 256 canales si es que no es el ultimo output\n",
    "        if i < stacks - 1:\n",
    "            y_recovery1 = conv2D(x, filters = 256, activation = False, batch_normalization = False)\n",
    "            y_recovery2 = conv2D(y, filters = 256, activation = False, batch_normalization = False)\n",
    "            skip = Add()([skip, y_recovery1, y_recovery2])\n",
    "    #print(y_heatmaps)\n",
    "    return Model(inputs = inputs, outputs = y_heatmaps, name = 'HourglassNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# tasa de decrecimiento del learning rate por numero de epoch\n",
    "def lr_schedule(epoch): #tome esto de resnet.ipynb\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-4\n",
    "    if epoch > 90:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 50:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 25:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr \n",
    "############################################################################\n",
    "# custom loss mean_squared_error function, sirve para magnificar la presencia de todos los pixeles > que 0 en los mapas de calor\n",
    "def custom_loss_mse_function(y_true, y_pred):\n",
    "    weights = tf.cast(y_true > 0, dtype=tf.float32) * 81 + 1\n",
    "    return tf.reduce_mean(tf.math.square(y_true - y_pred) * weights)\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('single_person_modelv5.h5'):\n",
    "    # verificamos si hay algun punto de guardado del modelo\n",
    "    model = load_model('single_person_modelv5.h5', custom_objects={'custom_loss_mse_function': custom_loss_mse_function})\n",
    "else:    \n",
    "    # si no lo hay creamos el modelo desde cero\n",
    "    model = HourglassNetwork(stacks = 4, resnet_per_block = 1)\n",
    "    rms = RMSprop(lr=lr_schedule(0))\n",
    "    model.compile(optimizer=rms, loss=custom_loss_mse_function, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos puntos de guardado del modelo para que guarde solo la mejor version durante el entrenamiento:\n",
    "checkpoint = ModelCheckpoint('single_person_modelv5.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# modificaciones al learning rate per epoch:\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "# modificaciones al learning rate por estancamiento:\n",
    "lr_reducer = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor = 0.1,\n",
    "                               patience = 5,\n",
    "                               min_lr = 0,\n",
    "                              verbose = 1)\n",
    "# agregamos estas funciones al callback_list\n",
    "callbacks_list = [checkpoint, lr_scheduler, lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 567.0613 - re_lu_65_loss: 382.6257 - re_lu_121_loss: 96.8728 - re_lu_177_loss: 49.4522 - re_lu_233_loss: 38.1111 - re_lu_65_accuracy: 0.0967 - re_lu_121_accuracy: 0.1764 - re_lu_177_accuracy: 0.2696 - re_lu_233_accuracy: 0.3483   ETA: 2:29 - loss: 566.2825 - re_lu_65_loss: 388.6387 - re_lu_121_loss: 93.9368 - re_lu_177_loss: 47.4719 - re_lu_233_loss: 36.2352 - re_lu_65_accura - ETA: 49s - loss: 566.7886 - re_lu_65_loss: 383.8509 - re_lu_121_loss: 96.4272 - re_lu_177_loss: 48.9134 - re_lu_233_loss: 37.5974 - re_lu_65_accuracy: 0.0956 - re_lu_121_accuracy: 0.1760 - re_lu_177_accuracy: 0.2696 - re_lu_233_accuracy: - ETA: 48s - loss: 566.5687 - re_lu_65_loss: 383.6232 - re_lu_121_loss: 96.4116 - re_lu_177_loss: 48.9181 - re_lu_233_loss: 37.6160 - re_lu_65_accuracy: 0.0956 - re_lu_121_accuracy: 0.1760 - re_lu_177_accura - ETA: 41s - loss: 567.1870 - re_lu_65_loss: 383.6412 - re_lu - ETA: 9s - loss: 565.4659 - re_lu_65_loss: 381.8928 - re_lu_121_loss: 96.5366 - re_lu_177_loss: 49.1436 - re_lu_233_loss: 37.8931 - re_lu_65_accuracy: 0.0967 - re_lu_ - ETA: 2s - loss: 566.6642 - re_lu_65_loss: 382.2919 - re_lu_121_loss: 96.8111 - re_lu_177_loss: 49.4578 - re_lu_233_loss: 38.1038 - re_lu_65_accuracy: 0.0967 - re_lu_121_accuracy: 0.1764 - re_lu_177_accuracy: 0.2696 \n",
      "Epoch 00001: loss improved from inf to 567.06134, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 233s 233ms/step - loss: 567.0613 - re_lu_65_loss: 382.6257 - re_lu_121_loss: 96.8728 - re_lu_177_loss: 49.4522 - re_lu_233_loss: 38.1111 - re_lu_65_accuracy: 0.0967 - re_lu_121_accuracy: 0.1764 - re_lu_177_accuracy: 0.2696 - re_lu_233_accuracy: 0.3483 - val_loss: 11446.3906 - val_re_lu_65_loss: 2678.6047 - val_re_lu_121_loss: 2812.9094 - val_re_lu_177_loss: 2957.2600 - val_re_lu_233_loss: 2997.6174 - val_re_lu_65_accuracy: 0.0822 - val_re_lu_121_accuracy: 0.1396 - val_re_lu_177_accuracy: 0.2335 - val_re_lu_233_accuracy: 0.1945\n",
      "Learning rate:  0.0001\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 570.5137 - re_lu_65_loss: 379.3721 - re_lu_121_loss: 98.3507 - re_lu_177_loss: 52.0453 - re_lu_233_loss: 40.7454 - re_lu_65_accuracy: 0.0984 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.2752 - re_lu_233_accuracy: 0.3624\n",
      "Epoch 00002: loss did not improve from 567.06134\n",
      "1000/1000 [==============================] - 219s 219ms/step - loss: 570.5137 - re_lu_65_loss: 379.3721 - re_lu_121_loss: 98.3507 - re_lu_177_loss: 52.0453 - re_lu_233_loss: 40.7454 - re_lu_65_accuracy: 0.0984 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.2752 - re_lu_233_accuracy: 0.3624 - val_loss: 11400.7451 - val_re_lu_65_loss: 2676.7732 - val_re_lu_121_loss: 2802.1152 - val_re_lu_177_loss: 2942.5391 - val_re_lu_233_loss: 2979.3193 - val_re_lu_65_accuracy: 0.0806 - val_re_lu_121_accuracy: 0.1363 - val_re_lu_177_accuracy: 0.2196 - val_re_lu_233_accuracy: 0.1921\n",
      "Learning rate:  0.0001\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 560.1949 - re_lu_65_loss: 373.9570 - re_lu_121_loss: 95.7445 - re_lu_177_loss: 50.7073 - re_lu_233_loss: 39.7859 - re_lu_65_accuracy: 0.0979 - re_lu_121_accuracy: 0.1837 - re_lu_177_accuracy: 0.2776 - re_lu_233_accuracy: 0.3624\n",
      "Epoch 00003: loss improved from 567.06134 to 560.19489, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 560.1949 - re_lu_65_loss: 373.9570 - re_lu_121_loss: 95.7445 - re_lu_177_loss: 50.7073 - re_lu_233_loss: 39.7859 - re_lu_65_accuracy: 0.0979 - re_lu_121_accuracy: 0.1837 - re_lu_177_accuracy: 0.2776 - re_lu_233_accuracy: 0.3624 - val_loss: 11434.0605 - val_re_lu_65_loss: 2679.5791 - val_re_lu_121_loss: 2812.1292 - val_re_lu_177_loss: 2951.8076 - val_re_lu_233_loss: 2990.5437 - val_re_lu_65_accuracy: 0.0802 - val_re_lu_121_accuracy: 0.1396 - val_re_lu_177_accuracy: 0.2352 - val_re_lu_233_accuracy: 0.2085\n",
      "Learning rate:  0.0001\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 549.9429 - re_lu_65_loss: 368.1332 - re_lu_121_loss: 93.1568 - re_lu_177_loss: 49.6074 - re_lu_233_loss: 39.0449 - re_lu_65_accuracy: 0.0993 - re_lu_121_accuracy: 0.1859 - re_lu_177_accuracy: 0.2841 - re_lu_233_accuracy: 0.3712\n",
      "Epoch 00004: loss improved from 560.19489 to 549.94287, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 236s 236ms/step - loss: 549.9429 - re_lu_65_loss: 368.1332 - re_lu_121_loss: 93.1568 - re_lu_177_loss: 49.6074 - re_lu_233_loss: 39.0449 - re_lu_65_accuracy: 0.0993 - re_lu_121_accuracy: 0.1859 - re_lu_177_accuracy: 0.2841 - re_lu_233_accuracy: 0.3712 - val_loss: 11460.7783 - val_re_lu_65_loss: 2683.8589 - val_re_lu_121_loss: 2820.8364 - val_re_lu_177_loss: 2960.8655 - val_re_lu_233_loss: 2995.2236 - val_re_lu_65_accuracy: 0.0800 - val_re_lu_121_accuracy: 0.1481 - val_re_lu_177_accuracy: 0.2394 - val_re_lu_233_accuracy: 0.1947\n",
      "Learning rate:  0.0001\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 542.1893 - re_lu_65_loss: 363.2005 - re_lu_121_loss: 91.0505 - re_lu_177_loss: 49.0681 - re_lu_233_loss: 38.8703 - re_lu_65_accuracy: 0.1007 - re_lu_121_accuracy: 0.1890 - re_lu_177_accuracy: 0.2915 - re_lu_233_accuracy: 0.3804\n",
      "Epoch 00005: loss improved from 549.94287 to 542.18933, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 231s 231ms/step - loss: 542.1893 - re_lu_65_loss: 363.2005 - re_lu_121_loss: 91.0505 - re_lu_177_loss: 49.0681 - re_lu_233_loss: 38.8703 - re_lu_65_accuracy: 0.1007 - re_lu_121_accuracy: 0.1890 - re_lu_177_accuracy: 0.2915 - re_lu_233_accuracy: 0.3804 - val_loss: 11469.4414 - val_re_lu_65_loss: 2682.7903 - val_re_lu_121_loss: 2822.0737 - val_re_lu_177_loss: 2965.8840 - val_re_lu_233_loss: 2998.6914 - val_re_lu_65_accuracy: 0.0807 - val_re_lu_121_accuracy: 0.1399 - val_re_lu_177_accuracy: 0.2468 - val_re_lu_233_accuracy: 0.1879\n",
      "Learning rate:  0.0001\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 534.5566 - re_lu_65_loss: 358.5069 - re_lu_121_loss: 89.1401 - re_lu_177_loss: 48.4084 - re_lu_233_loss: 38.5014 - re_lu_65_accuracy: 0.1005 - re_lu_121_accuracy: 0.1911 - re_lu_177_accuracy: 0.2926 - re_lu_233_accuracy: 0.3886\n",
      "Epoch 00006: loss improved from 542.18933 to 534.55664, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 230s 230ms/step - loss: 534.5566 - re_lu_65_loss: 358.5069 - re_lu_121_loss: 89.1401 - re_lu_177_loss: 48.4084 - re_lu_233_loss: 38.5014 - re_lu_65_accuracy: 0.1005 - re_lu_121_accuracy: 0.1911 - re_lu_177_accuracy: 0.2926 - re_lu_233_accuracy: 0.3886 - val_loss: 11448.8936 - val_re_lu_65_loss: 2685.2925 - val_re_lu_121_loss: 2820.1763 - val_re_lu_177_loss: 2956.0361 - val_re_lu_233_loss: 2987.3892 - val_re_lu_65_accuracy: 0.0803 - val_re_lu_121_accuracy: 0.1454 - val_re_lu_177_accuracy: 0.2470 - val_re_lu_233_accuracy: 0.2258\n",
      "Learning rate:  0.0001\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 527.4626 - re_lu_65_loss: 353.6660 - re_lu_121_loss: 87.5653 - re_lu_177_loss: 47.9923 - re_lu_233_loss: 38.2388 - re_lu_65_accuracy: 0.0996 - re_lu_121_accuracy: 0.1916 - re_lu_177_accuracy: 0.3005 - re_lu_233_accuracy: 0.3981\n",
      "Epoch 00007: loss improved from 534.55664 to 527.46259, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "1000/1000 [==============================] - 229s 229ms/step - loss: 527.4626 - re_lu_65_loss: 353.6660 - re_lu_121_loss: 87.5653 - re_lu_177_loss: 47.9923 - re_lu_233_loss: 38.2388 - re_lu_65_accuracy: 0.0996 - re_lu_121_accuracy: 0.1916 - re_lu_177_accuracy: 0.3005 - re_lu_233_accuracy: 0.3981 - val_loss: 11480.3340 - val_re_lu_65_loss: 2688.6055 - val_re_lu_121_loss: 2828.7737 - val_re_lu_177_loss: 2966.4001 - val_re_lu_233_loss: 2996.5581 - val_re_lu_65_accuracy: 0.0815 - val_re_lu_121_accuracy: 0.1561 - val_re_lu_177_accuracy: 0.2491 - val_re_lu_233_accuracy: 0.2251\n",
      "Learning rate:  0.0001\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 514.7222 - re_lu_65_loss: 347.0925 - re_lu_121_loss: 84.2692 - re_lu_177_loss: 46.3734 - re_lu_233_loss: 36.9872 - re_lu_65_accuracy: 0.0999 - re_lu_121_accuracy: 0.1934 - re_lu_177_accuracy: 0.3031 - re_lu_233_accuracy: 0.4011\n",
      "Epoch 00008: loss improved from 527.46259 to 514.72217, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 228s 228ms/step - loss: 514.7222 - re_lu_65_loss: 347.0925 - re_lu_121_loss: 84.2692 - re_lu_177_loss: 46.3734 - re_lu_233_loss: 36.9872 - re_lu_65_accuracy: 0.0999 - re_lu_121_accuracy: 0.1934 - re_lu_177_accuracy: 0.3031 - re_lu_233_accuracy: 0.4011 - val_loss: 11509.9287 - val_re_lu_65_loss: 2691.6479 - val_re_lu_121_loss: 2833.6348 - val_re_lu_177_loss: 2975.0234 - val_re_lu_233_loss: 3009.6211 - val_re_lu_65_accuracy: 0.0802 - val_re_lu_121_accuracy: 0.1581 - val_re_lu_177_accuracy: 0.2704 - val_re_lu_233_accuracy: 0.2199\n",
      "Learning rate:  0.0001\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 508.9382 - re_lu_65_loss: 343.2572 - re_lu_121_loss: 83.0109 - re_lu_177_loss: 45.8760 - re_lu_233_loss: 36.7940 - re_lu_65_accuracy: 0.1004 - re_lu_121_accuracy: 0.1943 - re_lu_177_accuracy: 0.3085 - re_lu_233_accuracy: 0.4095\n",
      "Epoch 00009: loss improved from 514.72217 to 508.93820, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 508.9382 - re_lu_65_loss: 343.2572 - re_lu_121_loss: 83.0109 - re_lu_177_loss: 45.8760 - re_lu_233_loss: 36.7940 - re_lu_65_accuracy: 0.1004 - re_lu_121_accuracy: 0.1943 - re_lu_177_accuracy: 0.3085 - re_lu_233_accuracy: 0.4095 - val_loss: 11517.7188 - val_re_lu_65_loss: 2694.7903 - val_re_lu_121_loss: 2837.9500 - val_re_lu_177_loss: 2978.6731 - val_re_lu_233_loss: 3006.3088 - val_re_lu_65_accuracy: 0.0804 - val_re_lu_121_accuracy: 0.1646 - val_re_lu_177_accuracy: 0.2592 - val_re_lu_233_accuracy: 0.2288\n",
      "Learning rate:  0.0001\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 499.8631 - re_lu_65_loss: 338.2332 - re_lu_121_loss: 80.7749 - re_lu_177_loss: 44.8748 - re_lu_233_loss: 35.9804 - re_lu_65_accuracy: 0.1013 - re_lu_121_accuracy: 0.1949 - re_lu_177_accuracy: 0.3104 - re_lu_233_accuracy: 0.4151\n",
      "Epoch 00010: loss improved from 508.93820 to 499.86310, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 499.8631 - re_lu_65_loss: 338.2332 - re_lu_121_loss: 80.7749 - re_lu_177_loss: 44.8748 - re_lu_233_loss: 35.9804 - re_lu_65_accuracy: 0.1013 - re_lu_121_accuracy: 0.1949 - re_lu_177_accuracy: 0.3104 - re_lu_233_accuracy: 0.4151 - val_loss: 11515.5254 - val_re_lu_65_loss: 2692.9141 - val_re_lu_121_loss: 2836.0049 - val_re_lu_177_loss: 2975.8684 - val_re_lu_233_loss: 3010.7412 - val_re_lu_65_accuracy: 0.0809 - val_re_lu_121_accuracy: 0.1586 - val_re_lu_177_accuracy: 0.2555 - val_re_lu_233_accuracy: 0.2342\n",
      "Learning rate:  0.0001\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 494.0894 - re_lu_65_loss: 334.2185 - re_lu_121_loss: 79.4963 - re_lu_177_loss: 44.4634 - re_lu_233_loss: 35.9113 - re_lu_65_accuracy: 0.1010 - re_lu_121_accuracy: 0.1961 - re_lu_177_accuracy: 0.3181 - re_lu_233_accuracy: 0.4252   ETA: 1:00 - loss: 492.5702 - re_lu_65_loss: 333.1182 - re_lu_121_loss: 79.3330 - re_lu_177_loss: 44.2808 - re_lu_233_loss: 35.8385 - re_lu_65_accuracy: 0.1007 - re_lu_121_ - ETA: 45s - loss: 494.1237 - re_lu_65_loss: 334.3806 - re_lu_121_loss: 79.4856 - re_lu_177_loss: 44.3873 - re_lu_233_loss: 35.8705 - re_lu_65_accuracy: 0.1009 - re_lu_121_accuracy: 0.1 - ETA: 34s - loss: 493.2983 - re_lu_65_loss: 333.6111 - re_lu_121_loss: 79.3118 - re_lu_177_loss: 44.4905 - re_lu_233_loss: 35.8852 - re_lu_65_accuracy: 0.1012 - re_lu_121_acc - ETA: 20s - loss: 491.9960 - re_lu_65_loss: 332.7514 - re_lu_121_loss: 79.0819 - re_lu\n",
      "Epoch 00011: loss improved from 499.86310 to 494.08942, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 494.0894 - re_lu_65_loss: 334.2185 - re_lu_121_loss: 79.4963 - re_lu_177_loss: 44.4634 - re_lu_233_loss: 35.9113 - re_lu_65_accuracy: 0.1010 - re_lu_121_accuracy: 0.1961 - re_lu_177_accuracy: 0.3181 - re_lu_233_accuracy: 0.4252 - val_loss: 11520.5947 - val_re_lu_65_loss: 2696.5593 - val_re_lu_121_loss: 2839.5481 - val_re_lu_177_loss: 2973.8237 - val_re_lu_233_loss: 3010.6704 - val_re_lu_65_accuracy: 0.0801 - val_re_lu_121_accuracy: 0.1446 - val_re_lu_177_accuracy: 0.2623 - val_re_lu_233_accuracy: 0.2427\n",
      "Learning rate:  0.0001\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 488.2760 - re_lu_65_loss: 329.9338 - re_lu_121_loss: 78.2078 - re_lu_177_loss: 44.2481 - re_lu_233_loss: 35.8865 - re_lu_65_accuracy: 0.1024 - re_lu_121_accuracy: 0.1954 - re_lu_177_accuracy: 0.3239 - re_lu_233_accuracy: 0.4385   ETA: 1:12 - loss: 488.2763 - re_lu_65_loss: 328.7961 - re_lu_121_loss: 78.4462 - re_lu_177_loss: 44.7263 - re_lu_233_loss: 36.3076 - re_lu_65_accuracy: 0.1024 - re_lu_121_accuracy: 0.1950 - - ETA: 1:07 - loss: 487.4977 - re_lu_65_loss: 328.2588 - re_lu_121_loss: 78.3473 - re_lu_177_loss: 44.6719 - re_lu_233_loss: 36.2198 - re_lu_65_accuracy: 0.1025 - re_lu_121_accuracy: 0.1953 - re_lu_177_accuracy: 0.3226 - re_lu_233_accuracy: 0. - ETA: 1:06 - loss: 487.4443 - re_lu_65_loss: 328.2441 - re_lu_121_loss: 78.3361 - re_lu_177_loss: 44.6549 - re_lu_233_loss: 36.2093 - re_lu_65_accuracy: 0.1025 - re_lu_12 - ETA: 13s - loss: 488.0004 - re_lu_65_loss: 329.4917 - re_lu_121_loss: 78.2115 - re_lu_177_loss: 44.3426 - re_lu_233_loss: 35.9548 - re_lu_65_accuracy: 0.1023 - re_lu_121_accuracy: 0.1956 - re_lu_177_accuracy: 0.3234 - re_lu_23 - ETA: 10s - loss: 487.8742 - re_lu_65_loss: 329.3893 - re_lu_121_loss: 78.2190 - re_lu_177_loss: 44.3259 - re_lu_233_loss: 35.9403 - re_lu_65_accuracy: 0.1023 - re_lu_121_accuracy: 0.1955 - re_lu_177_accuracy: 0.3235 - re_lu_233_accu - ETA: 8s - loss: 487.5588 - re_lu_65_loss: 329.2070 - re_lu_121_loss: 78.1430 - re_lu_177_loss: 44.2935 - re_lu_233_loss: 35.9155 - re_lu_65_accurac\n",
      "Epoch 00012: loss improved from 494.08942 to 488.27603, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "1000/1000 [==============================] - 208s 208ms/step - loss: 488.2760 - re_lu_65_loss: 329.9338 - re_lu_121_loss: 78.2078 - re_lu_177_loss: 44.2481 - re_lu_233_loss: 35.8865 - re_lu_65_accuracy: 0.1024 - re_lu_121_accuracy: 0.1954 - re_lu_177_accuracy: 0.3239 - re_lu_233_accuracy: 0.4385 - val_loss: 11546.3438 - val_re_lu_65_loss: 2697.5913 - val_re_lu_121_loss: 2847.1577 - val_re_lu_177_loss: 2985.4448 - val_re_lu_233_loss: 3016.1528 - val_re_lu_65_accuracy: 0.0826 - val_re_lu_121_accuracy: 0.1547 - val_re_lu_177_accuracy: 0.2728 - val_re_lu_233_accuracy: 0.2439\n",
      "Learning rate:  0.0001\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 479.9844 - re_lu_65_loss: 325.4986 - re_lu_121_loss: 76.2392 - re_lu_177_loss: 43.2567 - re_lu_233_loss: 34.9900 - re_lu_65_accuracy: 0.1030 - re_lu_121_accuracy: 0.2011 - re_lu_177_accuracy: 0.3311 - re_lu_233_accuracy: 0.4457 - ETA: 47s - loss: 478.5461 - re_lu_65_loss: 324.4892 - re_lu_121_loss: 75.8640 - re_lu_177_loss: 43.1718 - re_lu_233_loss: 35.0209 - re_lu_65_accuracy: 0.1033 - re_lu_121_ac - ETA: 33s - loss: 479.3186 - re_lu_65_loss: 325.3233 - re_lu_121_loss: - ETA: 5s - loss: 479.8021 - re_lu_65_loss: 325.1748 - re_lu_121_loss: 76.3184 - re_lu_177_loss: 43.2958 - re_lu_233_loss: 35.0133 - re_lu_65_accuracy: 0.1030 - re_lu_121_accuracy: 0.2013 - re_lu_177_accuracy: 0.3307 - re_lu_233_accuracy - ETA: 4s - loss: 480.3368 - re_lu_65_loss: 325.5959 - re_lu_121_loss: 76.3742 - re_lu_177_loss: 43.3276 - re_lu_233_loss: 35.0391 - re_lu_65_accuracy: 0.1029 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.3308 - re_lu_233_accuracy: 0.44 - ETA: 4s - loss: 480.4348 - re_lu_65_loss: 325.6666 - re_lu_121_loss: 76.3744 - re_lu_177_loss: 43.3409 - re_lu_233_loss: 35.0529 - re_lu_65_accuracy: 0.1029 - re_lu_121_accuracy: 0.2012 - re_lu_1 - ETA: 0s - loss: 480.0924 - re_lu_65_loss: 325.5838 - re_lu_121_loss: 76.2460 - re_lu_177_loss: 43.2655 - re_lu_233_loss: 34.9973 - re_lu_65_accuracy: 0.1030 - re_lu_121_accuracy: 0.2011 - re_lu_177_accuracy: 0.3311 - re_lu_233_accuracy: 0.44\n",
      "Epoch 00013: loss improved from 488.27603 to 479.98438, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 213s 213ms/step - loss: 479.9844 - re_lu_65_loss: 325.4986 - re_lu_121_loss: 76.2392 - re_lu_177_loss: 43.2567 - re_lu_233_loss: 34.9900 - re_lu_65_accuracy: 0.1030 - re_lu_121_accuracy: 0.2011 - re_lu_177_accuracy: 0.3311 - re_lu_233_accuracy: 0.4457 - val_loss: 11534.3096 - val_re_lu_65_loss: 2698.6921 - val_re_lu_121_loss: 2845.9187 - val_re_lu_177_loss: 2978.5779 - val_re_lu_233_loss: 3011.1191 - val_re_lu_65_accuracy: 0.0802 - val_re_lu_121_accuracy: 0.1497 - val_re_lu_177_accuracy: 0.2995 - val_re_lu_233_accuracy: 0.2763\n",
      "Learning rate:  0.0001\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 471.8639 - re_lu_65_loss: 320.5589 - re_lu_121_loss: 74.5701 - re_lu_177_loss: 42.3132 - re_lu_233_loss: 34.4215 - re_lu_65_accuracy: 0.1033 - re_lu_121_accuracy: 0.2004 - re_lu_177_accuracy: 0.3343 - re_lu_233_accuracy: 0.4488 - ETA: 24s - loss: 475.8318 - re_lu_65_loss: 323.7844 - re_lu_12\n",
      "Epoch 00014: loss improved from 479.98438 to 471.86389, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 211s 211ms/step - loss: 471.8639 - re_lu_65_loss: 320.5589 - re_lu_121_loss: 74.5701 - re_lu_177_loss: 42.3132 - re_lu_233_loss: 34.4215 - re_lu_65_accuracy: 0.1033 - re_lu_121_accuracy: 0.2004 - re_lu_177_accuracy: 0.3343 - re_lu_233_accuracy: 0.4488 - val_loss: 11557.6982 - val_re_lu_65_loss: 2702.3962 - val_re_lu_121_loss: 2851.6860 - val_re_lu_177_loss: 2986.4036 - val_re_lu_233_loss: 3017.2153 - val_re_lu_65_accuracy: 0.0857 - val_re_lu_121_accuracy: 0.1619 - val_re_lu_177_accuracy: 0.2925 - val_re_lu_233_accuracy: 0.2922\n",
      "Learning rate:  0.0001\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 464.7177 - re_lu_65_loss: 316.1627 - re_lu_121_loss: 72.9102 - re_lu_177_loss: 41.6903 - re_lu_233_loss: 33.9544 - re_lu_65_accuracy: 0.1040 - re_lu_121_accuracy: 0.2019 - re_lu_177_accuracy: 0.3390 - re_lu_233_accuracy: 0.4582   ETA: 1:16 - loss: 464.2712 - re_lu_65_loss: 315.9059 - re_lu_121_loss: 72.5896 - re_lu_177_loss: 41.8 - ETA: 1:01 - loss: 463.5855 - re_lu_65_loss: 315.2346 - re_lu_121_loss: 72.5957 - re_lu_177_loss: 41.7819 - re_lu_233_loss: 33.9733 - re_l - ETA: 40s - loss: 464.0976 - re_lu_65_loss: 315.5507 - re_lu_121_loss: 72.7420 - re_lu_177_loss: 41.8223 - re_lu_233_loss: 33.9827 - re_lu_65_accuracy: 0.1038 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.339 - ETA: 34s - loss: 46\n",
      "Epoch 00015: loss improved from 471.86389 to 464.71771, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 218s 218ms/step - loss: 464.7177 - re_lu_65_loss: 316.1627 - re_lu_121_loss: 72.9102 - re_lu_177_loss: 41.6903 - re_lu_233_loss: 33.9544 - re_lu_65_accuracy: 0.1040 - re_lu_121_accuracy: 0.2019 - re_lu_177_accuracy: 0.3390 - re_lu_233_accuracy: 0.4582 - val_loss: 11588.9102 - val_re_lu_65_loss: 2705.1216 - val_re_lu_121_loss: 2859.3237 - val_re_lu_177_loss: 2997.1846 - val_re_lu_233_loss: 3027.2759 - val_re_lu_65_accuracy: 0.0844 - val_re_lu_121_accuracy: 0.1635 - val_re_lu_177_accuracy: 0.2919 - val_re_lu_233_accuracy: 0.2662\n",
      "Learning rate:  0.0001\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 461.2224 - re_lu_65_loss: 313.4016 - re_lu_121_loss: 72.1320 - re_lu_177_loss: 41.5372 - re_lu_233_loss: 34.1514 - re_lu_65_accuracy: 0.1045 - re_lu_121_accuracy: 0.2031 - re_lu_177_accuracy: 0.3459 - re_lu_233_accuracy: 0.4573\n",
      "Epoch 00016: loss improved from 464.71771 to 461.22244, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 461.2224 - re_lu_65_loss: 313.4016 - re_lu_121_loss: 72.1320 - re_lu_177_loss: 41.5372 - re_lu_233_loss: 34.1514 - re_lu_65_accuracy: 0.1045 - re_lu_121_accuracy: 0.2031 - re_lu_177_accuracy: 0.3459 - re_lu_233_accuracy: 0.4573 - val_loss: 11579.8652 - val_re_lu_65_loss: 2704.8308 - val_re_lu_121_loss: 2860.7642 - val_re_lu_177_loss: 2991.0750 - val_re_lu_233_loss: 3023.1946 - val_re_lu_65_accuracy: 0.0832 - val_re_lu_121_accuracy: 0.1639 - val_re_lu_177_accuracy: 0.3025 - val_re_lu_233_accuracy: 0.3073\n",
      "Learning rate:  0.0001\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 452.4706 - re_lu_65_loss: 308.3517 - re_lu_121_loss: 70.1402 - re_lu_177_loss: 40.6731 - re_lu_233_loss: 33.3054 - re_lu_65_accuracy: 0.1052 - re_lu_121_accuracy: 0.2060 - re_lu_177_accuracy: 0.3494 - re_lu_233_accuracy: 0.4655\n",
      "Epoch 00017: loss improved from 461.22244 to 452.47055, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 452.4706 - re_lu_65_loss: 308.3517 - re_lu_121_loss: 70.1402 - re_lu_177_loss: 40.6731 - re_lu_233_loss: 33.3054 - re_lu_65_accuracy: 0.1052 - re_lu_121_accuracy: 0.2060 - re_lu_177_accuracy: 0.3494 - re_lu_233_accuracy: 0.4655 - val_loss: 11590.9541 - val_re_lu_65_loss: 2705.2661 - val_re_lu_121_loss: 2858.1523 - val_re_lu_177_loss: 2996.9312 - val_re_lu_233_loss: 3030.6074 - val_re_lu_65_accuracy: 0.0867 - val_re_lu_121_accuracy: 0.1737 - val_re_lu_177_accuracy: 0.3001 - val_re_lu_233_accuracy: 0.2878\n",
      "Learning rate:  0.0001\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 447.4599 - re_lu_65_loss: 304.5258 - re_lu_121_loss: 69.3852 - re_lu_177_loss: 40.3264 - re_lu_233_loss: 33.2226 - re_lu_65_accuracy: 0.1066 - re_lu_121_accuracy: 0.2044 - re_lu_177_accuracy: 0.3586 - re_lu_233_accuracy: 0.4656\n",
      "Epoch 00018: loss improved from 452.47055 to 447.45993, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 447.4599 - re_lu_65_loss: 304.5258 - re_lu_121_loss: 69.3852 - re_lu_177_loss: 40.3264 - re_lu_233_loss: 33.2226 - re_lu_65_accuracy: 0.1066 - re_lu_121_accuracy: 0.2044 - re_lu_177_accuracy: 0.3586 - re_lu_233_accuracy: 0.4656 - val_loss: 11594.8320 - val_re_lu_65_loss: 2707.8999 - val_re_lu_121_loss: 2861.1243 - val_re_lu_177_loss: 2998.2161 - val_re_lu_233_loss: 3027.5889 - val_re_lu_65_accuracy: 0.0857 - val_re_lu_121_accuracy: 0.1651 - val_re_lu_177_accuracy: 0.3150 - val_re_lu_233_accuracy: 0.2893\n",
      "Learning rate:  0.0001\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 442.3154 - re_lu_65_loss: 301.4711 - re_lu_121_loss: 68.1495 - re_lu_177_loss: 39.8599 - re_lu_233_loss: 32.8345 - re_lu_65_accuracy: 0.1080 - re_lu_121_accuracy: 0.2062 - re_lu_177_accuracy: 0.3638 - re_lu_233_accuracy: 0.4796\n",
      "Epoch 00019: loss improved from 447.45993 to 442.31540, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 442.3154 - re_lu_65_loss: 301.4711 - re_lu_121_loss: 68.1495 - re_lu_177_loss: 39.8599 - re_lu_233_loss: 32.8345 - re_lu_65_accuracy: 0.1080 - re_lu_121_accuracy: 0.2062 - re_lu_177_accuracy: 0.3638 - re_lu_233_accuracy: 0.4796 - val_loss: 11617.5059 - val_re_lu_65_loss: 2709.6533 - val_re_lu_121_loss: 2869.7385 - val_re_lu_177_loss: 3005.7957 - val_re_lu_233_loss: 3032.3210 - val_re_lu_65_accuracy: 0.0873 - val_re_lu_121_accuracy: 0.1694 - val_re_lu_177_accuracy: 0.3172 - val_re_lu_233_accuracy: 0.3183\n",
      "Learning rate:  0.0001\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 436.6742 - re_lu_65_loss: 298.0820 - re_lu_121_loss: 67.0741 - re_lu_177_loss: 39.1905 - re_lu_233_loss: 32.3273 - re_lu_65_accuracy: 0.1069 - re_lu_121_accuracy: 0.2051 - re_lu_177_accuracy: 0.3690 - re_lu_233_accuracy: 0.4934\n",
      "Epoch 00020: loss improved from 442.31540 to 436.67422, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 436.6742 - re_lu_65_loss: 298.0820 - re_lu_121_loss: 67.0741 - re_lu_177_loss: 39.1905 - re_lu_233_loss: 32.3273 - re_lu_65_accuracy: 0.1069 - re_lu_121_accuracy: 0.2051 - re_lu_177_accuracy: 0.3690 - re_lu_233_accuracy: 0.4934 - val_loss: 11632.2285 - val_re_lu_65_loss: 2713.2209 - val_re_lu_121_loss: 2871.2810 - val_re_lu_177_loss: 3009.9514 - val_re_lu_233_loss: 3037.7800 - val_re_lu_65_accuracy: 0.0849 - val_re_lu_121_accuracy: 0.1642 - val_re_lu_177_accuracy: 0.3224 - val_re_lu_233_accuracy: 0.3120\n",
      "Learning rate:  0.0001\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 431.6131 - re_lu_65_loss: 293.7852 - re_lu_121_loss: 66.5971 - re_lu_177_loss: 38.9144 - re_lu_233_loss: 32.3164 - re_lu_65_accuracy: 0.1080 - re_lu_121_accuracy: 0.2021 - re_lu_177_accuracy: 0.3685 - re_lu_233_accuracy: 0.4949\n",
      "Epoch 00021: loss improved from 436.67422 to 431.61310, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 431.6131 - re_lu_65_loss: 293.7852 - re_lu_121_loss: 66.5971 - re_lu_177_loss: 38.9144 - re_lu_233_loss: 32.3164 - re_lu_65_accuracy: 0.1080 - re_lu_121_accuracy: 0.2021 - re_lu_177_accuracy: 0.3685 - re_lu_233_accuracy: 0.4949 - val_loss: 11595.6768 - val_re_lu_65_loss: 2711.6533 - val_re_lu_121_loss: 2864.3225 - val_re_lu_177_loss: 2995.8364 - val_re_lu_233_loss: 3023.8689 - val_re_lu_65_accuracy: 0.0858 - val_re_lu_121_accuracy: 0.1739 - val_re_lu_177_accuracy: 0.3219 - val_re_lu_233_accuracy: 0.3161\n",
      "Learning rate:  0.0001\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 425.2750 - re_lu_65_loss: 289.5995 - re_lu_121_loss: 64.9973 - re_lu_177_loss: 38.5559 - re_lu_233_loss: 32.1223 - re_lu_65_accuracy: 0.1058 - re_lu_121_accuracy: 0.2062 - re_lu_177_accuracy: 0.3758 - re_lu_233_accuracy: 0.4976\n",
      "Epoch 00022: loss improved from 431.61310 to 425.27502, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "1000/1000 [==============================] - 215s 215ms/step - loss: 425.2750 - re_lu_65_loss: 289.5995 - re_lu_121_loss: 64.9973 - re_lu_177_loss: 38.5559 - re_lu_233_loss: 32.1223 - re_lu_65_accuracy: 0.1058 - re_lu_121_accuracy: 0.2062 - re_lu_177_accuracy: 0.3758 - re_lu_233_accuracy: 0.4976 - val_loss: 11634.9590 - val_re_lu_65_loss: 2714.4155 - val_re_lu_121_loss: 2871.5547 - val_re_lu_177_loss: 3009.2996 - val_re_lu_233_loss: 3039.6909 - val_re_lu_65_accuracy: 0.0836 - val_re_lu_121_accuracy: 0.1627 - val_re_lu_177_accuracy: 0.3199 - val_re_lu_233_accuracy: 0.3210\n",
      "Learning rate:  0.0001\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 421.0634 - re_lu_65_loss: 287.5420 - re_lu_121_loss: 64.0148 - re_lu_177_loss: 37.9432 - re_lu_233_loss: 31.5636 - re_lu_65_accuracy: 0.1079 - re_lu_121_accuracy: 0.2077 - re_lu_177_accuracy: 0.3823 - re_lu_233_accuracy: 0.5029\n",
      "Epoch 00023: loss improved from 425.27502 to 421.06335, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 421.0634 - re_lu_65_loss: 287.5420 - re_lu_121_loss: 64.0148 - re_lu_177_loss: 37.9432 - re_lu_233_loss: 31.5636 - re_lu_65_accuracy: 0.1079 - re_lu_121_accuracy: 0.2077 - re_lu_177_accuracy: 0.3823 - re_lu_233_accuracy: 0.5029 - val_loss: 11663.5869 - val_re_lu_65_loss: 2720.4563 - val_re_lu_121_loss: 2885.5061 - val_re_lu_177_loss: 3015.5466 - val_re_lu_233_loss: 3042.0813 - val_re_lu_65_accuracy: 0.0866 - val_re_lu_121_accuracy: 0.1620 - val_re_lu_177_accuracy: 0.3701 - val_re_lu_233_accuracy: 0.3224\n",
      "Learning rate:  0.0001\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 415.3610 - re_lu_65_loss: 283.4765 - re_lu_121_loss: 63.1890 - re_lu_177_loss: 37.4950 - re_lu_233_loss: 31.2006 - re_lu_65_accuracy: 0.1103 - re_lu_121_accuracy: 0.2049 - re_lu_177_accuracy: 0.3858 - re_lu_233_accuracy: 0.5045\n",
      "Epoch 00024: loss improved from 421.06335 to 415.36102, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 415.3610 - re_lu_65_loss: 283.4765 - re_lu_121_loss: 63.1890 - re_lu_177_loss: 37.4950 - re_lu_233_loss: 31.2006 - re_lu_65_accuracy: 0.1103 - re_lu_121_accuracy: 0.2049 - re_lu_177_accuracy: 0.3858 - re_lu_233_accuracy: 0.5045 - val_loss: 11639.5186 - val_re_lu_65_loss: 2717.8997 - val_re_lu_121_loss: 2878.0488 - val_re_lu_177_loss: 3010.1755 - val_re_lu_233_loss: 3033.3975 - val_re_lu_65_accuracy: 0.0888 - val_re_lu_121_accuracy: 0.1620 - val_re_lu_177_accuracy: 0.3391 - val_re_lu_233_accuracy: 0.3277\n",
      "Learning rate:  0.0001\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 411.5833 - re_lu_65_loss: 281.0863 - re_lu_121_loss: 62.1128 - re_lu_177_loss: 37.2726 - re_lu_233_loss: 31.1115 - re_lu_65_accuracy: 0.1119 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.3920 - re_lu_233_accuracy: 0.5164   ETA: 2:35 - loss: 401.8839 - re_lu_65_loss: 273.0648 - re_lu_121_loss: 60.4209 - re_lu_177_loss: 37.3526 - re_lu_23 - ETA: 2:22 - loss: 411.4029 - re_lu_65_loss: 280.0117 - re_lu_121_loss: 62.2861 - re_lu_177_loss: 37.7438 - re_lu_233_lo - ETA: 2:11 - loss: 418.2319 - re_lu_65_loss: 285.7063 - re_lu_121_loss: 62 - ETA: 1:55 - los - ETA: 43s - loss: 410.7246 - re_lu_65_loss: 280.5154 - re_lu_121_loss: 61.7520 - re_lu_177_loss: 37.2772 - re_lu_2 - ETA: 19s - loss: 413.3015 - re_lu_65_loss: 282.3318 - re_lu_121_loss: 62.2639 - re_lu_177_loss: 37.4367 - re_lu_233_loss: 31.2689 - re_lu_65_accuracy: 0.1119 - re_lu_121_accuracy: 0.2008 - re_lu_177_accuracy: 0.3909 - re_lu_233 - ETA: 16s - loss: 412.8327 - re_lu_65_loss: 282.0055 - re_lu_121_loss: 62.2179 - re_lu_177_loss: 37.3887 - re_lu_233_loss: 31.2206 - re_lu_65_accura - ETA: 4s - loss: 411.8031 - re_lu_65_loss: 281.1993 - re_lu_121_loss: 62.1391 - re_lu_177_loss: 37.3178 - re_lu_233_loss: 31.1468 - re_lu_65_accuracy: 0.1118 - re_lu_121_accuracy: 0.2009 - re_lu_177_accuracy: 0.3918 - re_lu_23 - ETA: 3s - loss: 411.4303 - re_lu_65_loss: 280.9499 - re_lu_121_loss: 62.0744 - re_lu_177_loss: 37.2806 - re_lu_233_loss: 31.1253 - re_lu_65_accuracy: 0.1119 - re_lu_121_accuracy: 0.2011 - re_lu_177_accuracy:\n",
      "Epoch 00025: loss improved from 415.36102 to 411.58331, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 411.5833 - re_lu_65_loss: 281.0863 - re_lu_121_loss: 62.1128 - re_lu_177_loss: 37.2726 - re_lu_233_loss: 31.1115 - re_lu_65_accuracy: 0.1119 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.3920 - re_lu_233_accuracy: 0.5164 - val_loss: 11659.8496 - val_re_lu_65_loss: 2717.7939 - val_re_lu_121_loss: 2883.8850 - val_re_lu_177_loss: 3017.3364 - val_re_lu_233_loss: 3040.8374 - val_re_lu_65_accuracy: 0.0914 - val_re_lu_121_accuracy: 0.1630 - val_re_lu_177_accuracy: 0.3536 - val_re_lu_233_accuracy: 0.3441\n",
      "Learning rate:  0.0001\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 405.5243 - re_lu_65_loss: 277.0158 - re_lu_121_loss: 61.2112 - re_lu_177_loss: 36.6117 - re_lu_233_loss: 30.6852 - re_lu_65_accuracy: 0.1129 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.3969 - re_lu_233_accuracy: 0.5207 - ETA: 26s - loss: 405.4637 - re_lu_65_loss: 276.2044 - re_lu_121_loss: 61.5547 - ETA: 3s - loss: 405.7900 - re_lu_65_loss: 276.9630 - re_lu_121_loss: 61.3710 - re_lu_177_loss: 36.7037 - re_lu_233_loss: 30.7518 - re_lu_65_accuracy: 0.1130 - re_lu_121_accuracy: 0.2029 - re_lu_177_accuracy:\n",
      "Epoch 00026: loss improved from 411.58331 to 405.52432, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 405.5243 - re_lu_65_loss: 277.0158 - re_lu_121_loss: 61.2112 - re_lu_177_loss: 36.6117 - re_lu_233_loss: 30.6852 - re_lu_65_accuracy: 0.1129 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.3969 - re_lu_233_accuracy: 0.5207 - val_loss: 11656.5557 - val_re_lu_65_loss: 2716.9060 - val_re_lu_121_loss: 2879.3247 - val_re_lu_177_loss: 3015.0256 - val_re_lu_233_loss: 3045.2998 - val_re_lu_65_accuracy: 0.0932 - val_re_lu_121_accuracy: 0.1553 - val_re_lu_177_accuracy: 0.3554 - val_re_lu_233_accuracy: 0.3681\n",
      "Learning rate:  1e-05\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 390.1620 - re_lu_65_loss: 269.5150 - re_lu_121_loss: 57.6511 - re_lu_177_loss: 34.3278 - re_lu_233_loss: 28.6680 - re_lu_65_accuracy: 0.1127 - re_lu_121_accuracy: 0.1988 - re_lu_177_accuracy: 0.3989 - re_lu_233_accuracy: 0.5266   ETA: 2:43 - loss: 399.2961 - re_lu_65_loss: 275.8567 - re_lu_121_loss: 57.4301 - re_lu_177_loss: 35.6118 - re_lu_233_loss: 30.3975 - re - ETA: 2:17 - loss: 375.7623 - re_lu_65_loss: 258.9909 - re_lu_121_loss: 54.7578 - re_lu_177_loss: 33.5830 - re_lu_233_loss: 28.4305 - re_lu_65_acc - ETA: 2:08 - loss: 380.2724 - re_lu_65_loss: 263.2186 - re_lu_121_loss: 55.2891 - re_lu_177_loss: 33.4668 - re_lu_233_loss: 28.2979 - re_lu_65_accuracy: 0.1122 - re_lu_121_accuracy: 0.1976 - re_lu_177_accuracy: 0.3990 - re_lu_233_accuracy: 0. - ETA: 2:08 - loss: 382.1280 - re_lu_65_loss: 264.3398 - re_lu_121_loss: 55.6304 - re_lu_177_loss: 33.6780 - re_lu_233_loss: 28.4798 - re_lu_65_accuracy: 0.1122 - re_lu_121_accuracy: 0.1976 - re_lu_177_accuracy: 0.3988 - re_lu_233_accuracy:  - ETA: 2:07 - loss: 382.2316 - re_lu_65_loss: 264.444 - ETA: 1:28 - loss: 393.3185 - re_lu_65_loss: 271.3334 - re_lu_121_loss: 58.0279 - re_lu_177_loss: 34.8259 - re_lu_233_loss: 29.1312 - re_lu_65_accuracy: 0.1122 - re_lu_121_accuracy: 0.1978 - re_lu_177_accuracy: 0.3995 - re_lu_233_accuracy:  - ETA: 1:28 - loss: 393.1219 - re_lu_65_loss: 271.2088 - re_lu_121_loss: 57.9891 - re_lu_177_loss: 34.8081 - re_lu_233_loss: 29.1160 - re_lu_65_accuracy: 0.1122 - re_lu_12 - ETA: 59s - loss: 393.4668 - re_lu_65_loss: 271.0475 - re_lu_121_loss: 58.2700 - re_lu_177_loss: 34.9403 - re_lu_233_loss: 29.2090 - re_ - ETA: 40s - loss: 392.0685 - re_lu_65_loss: 270.4731 - re_lu_121_loss: 58.0766 - re_lu_177_loss: 34.6482 - re_lu_233_loss: 28.8705 - re_lu_65_accuracy: 0.1124 - re_l - ETA: 26s - loss: 392.3557 - re_lu_65_loss: 270.9489 - re_lu_121_loss: 58.0369 - re_lu_177_loss: 34.5535 - re_lu_233_loss: 28.8163 - re_lu_65_acc - ETA: 9s - loss: 390.9746 - re_lu_65_loss: 269.8494 - re_lu_121_loss: 57.9774 - re_lu_177_loss: 34.4340 - re_lu_233_loss: 28.7138 - re_lu_65_accuracy: 0.1126 - re_lu_121_accuracy: 0. - ETA: 3s - loss: 390.4525 - re_lu_65_loss: 269.7319 - re_lu_121_loss: 57.7478 - re_lu_177_loss: 34.3248 - re_lu_233_loss: 28.6479 - re_lu_65_accuracy: 0.1126 - re_lu_121_accuracy: 0.1987 - re_lu_177_acc\n",
      "Epoch 00027: loss improved from 405.52432 to 390.16196, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 390.1620 - re_lu_65_loss: 269.5150 - re_lu_121_loss: 57.6511 - re_lu_177_loss: 34.3278 - re_lu_233_loss: 28.6680 - re_lu_65_accuracy: 0.1127 - re_lu_121_accuracy: 0.1988 - re_lu_177_accuracy: 0.3989 - re_lu_233_accuracy: 0.5266 - val_loss: 11672.6602 - val_re_lu_65_loss: 2718.5220 - val_re_lu_121_loss: 2883.7129 - val_re_lu_177_loss: 3019.9417 - val_re_lu_233_loss: 3050.4873 - val_re_lu_65_accuracy: 0.0913 - val_re_lu_121_accuracy: 0.1546 - val_re_lu_177_accuracy: 0.3495 - val_re_lu_233_accuracy: 0.3483\n",
      "Learning rate:  1e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 382.4515 - re_lu_65_loss: 267.0126 - re_lu_121_loss: 55.5065 - re_lu_177_loss: 32.7195 - re_lu_233_loss: 27.2134 - re_lu_65_accuracy: 0.1139 - re_lu_121_accuracy: 0.1997 - re_lu_177_accuracy: 0.3997 - re_lu_233_accuracy: 0.5222   ETA: 2:49 - loss: 399.7411 - re_lu_65_loss: 278.1508 - re_lu_121_loss: 57.5612 - re_lu_177_loss: 34.9206 - re_lu_233_loss: 29.1085 - re_lu_65_accuracy: 0.1130 - re_lu_121_accuracy: 0.1963 - re_lu_177_accuracy: - ETA: 2:49 - loss: 379.1788 - re_lu_65_loss: 261.1437 - re_lu_121_loss: 55.5003 - re_lu_177_loss: 33.9477 - re_lu_233_loss: 28.5872 - re_lu_65_accuracy: 0.1142 - re_lu_121_accuracy: 0.2023 - ETA: 2:44 - loss: 373.7356 - re_lu_65_loss: 256.8422 - re_lu_121_loss: 55.2428 - re_lu_177_loss: 33.3492 - re_lu_233_loss: 28.3014 - re_lu_65_accuracy: 0.1134 - re_lu_121_accuracy: 0.2013 - re_lu_177_accuracy: 0.4028 - re_lu_233_accuracy: 0. - ETA: 2:44 - loss: 373.2497 - re_lu_65_loss: 256.0803 - re_lu_121_loss: 55.3985 - re_lu_177_loss: 33.4028 - re_lu_233_loss: 28.3682 - re_lu_65_accuracy: 0.1136 - re_lu_121_accuracy: 0.2029 - re_lu_177_acc - ETA: 2:41 - loss: 377.7909 - re_lu_65_loss: 262.5026 - re_lu_121_loss: 54.8316 - re_lu_177_loss: 32.7071 - re_lu_233_loss: 27.7496 - re_lu_65_accuracy: 0.1131 - re_l - ETA: 2:34 - loss: 368.9083 - re_lu_65_l - ETA: 1:55 - loss: 377.8523 - re_lu_65_loss: 264.1088 - re_lu_121_loss: 54.4359 - re_lu_177_loss: 32.1284 - re_lu_23 - ETA: 1:21 - loss: 382.0549 - re_lu_65_loss: 266.8408 - re_lu_121_loss: 55.3094 - re_lu_177_loss: 32.6468  - ETA: 1:09 - loss: 383.3043 - re_lu_65_loss: 267.9523 - re_lu_121_loss: 55.3302 - re_lu_177_loss: 32.7786 - re_lu_233_loss: 27.2435 - re_lu_65_accuracy: 0.1141 - re_lu_121_accuracy: 0.2006 - re_lu_177_accuracy: 0.3987 - re_lu_23 - ETA: 1:07 - loss: 383.4948 - re_lu_65_loss: 268.1569 - re_lu_121_loss: 55.3184 - re_lu_177_loss: 32.7775 - re_lu_233_loss: 27.2423 - re_lu_65_accuracy: 0.1141 - re_lu_121_accuracy: 0.2007 - re_lu_177_accuracy: 0.3990  - ETA: 1:05 - loss: 383.7900 - re_lu_65_loss: 268.3333 - re_lu_121_loss: 55.4533 - re_lu_177_loss: 32.7663 - re_lu_233_loss: 27.2374 - re_lu_65_accuracy: 0.1142 - re_lu_121_accuracy: 0. - ETA: 59s - loss: 383.4414 - re_lu_65_loss: 268.1793 - re_lu_121_loss: 55.3957 - re_lu_177_loss: 32.6824 - re_lu_233_loss: 27.1843 - re_lu_65_accuracy: 0.1142 - re_lu_121_accuracy: 0.2004 - re_lu_177_accuracy: 0.3994 - re_lu_233_ac - ETA: 56s - loss: 382.1165 - re_lu_65_loss: 267.3534 - re_lu_121_l - ETA: 25s - loss: 379.6225 - re_lu_65_loss: 265.2464 - re_lu_121_loss: 54.7487 - re_lu_177_loss: 32.5193 - re_lu_233_loss: 27.10 - ETA: 7s - loss: 381.2451 - re_lu_65_loss: 266.1552 - re_lu_121_loss: 55.3356 - re_lu_177_loss: 32.6123 - re_lu_233_loss: 27.1426 - re_lu_65_accuracy: 0.1139 - re_lu_121_accuracy: 0.1998 - re_lu_177_acc - ETA: 3s - loss: 381.6408 - re_lu_65_loss: 266.4871 - re_lu_121_loss: 55.4147 - re_lu_177_loss: 32.6237 - re_lu_233_loss: 27.1159 - re_lu_65_accuracy: 0.1139 - re_lu_121_accuracy: 0.1997 - re_lu_177_accuracy: 0.3995 - re_l - ETA: 1s - loss: 381.9494 - re_lu_65_loss: 266.7074 - re_lu_121_loss: 55.4482 - re_lu_177_loss: 32.6494 - re_lu_233_loss: 27.1450 - re_lu_65_accuracy: 0.1139 - re_lu_121_accuracy: 0.1997 - re_lu_177_accuracy: 0.3995 - re_lu_233_\n",
      "Epoch 00028: loss improved from 390.16196 to 382.45148, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 382.4515 - re_lu_65_loss: 267.0126 - re_lu_121_loss: 55.5065 - re_lu_177_loss: 32.7195 - re_lu_233_loss: 27.2134 - re_lu_65_accuracy: 0.1139 - re_lu_121_accuracy: 0.1997 - re_lu_177_accuracy: 0.3997 - re_lu_233_accuracy: 0.5222 - val_loss: 11678.1963 - val_re_lu_65_loss: 2719.4861 - val_re_lu_121_loss: 2885.4744 - val_re_lu_177_loss: 3021.9963 - val_re_lu_233_loss: 3051.2419 - val_re_lu_65_accuracy: 0.0924 - val_re_lu_121_accuracy: 0.1557 - val_re_lu_177_accuracy: 0.3589 - val_re_lu_233_accuracy: 0.3508\n",
      "Learning rate:  1e-05\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 376.3739 - re_lu_65_loss: 264.5464 - re_lu_121_loss: 53.9916 - re_lu_177_loss: 31.6495 - re_lu_233_loss: 26.1863 - re_lu_65_accuracy: 0.1144 - re_lu_121_accuracy: 0.2000 - re_lu_177_accuracy: 0.4017 - re_lu_233_accuracy: 0.5214 - ETA: 40s - loss: 380.3985 - re_lu_65_loss: 268.4403 - re_lu_121_loss: 54.3585 - re_lu_177_loss: 31.6296 - re_lu_233_loss: 25.9702 - re_lu_65_accuracy: 0.1141 - re_lu_121_accuracy: 0.1999 - re_lu_177_accuracy: 0.4018 - re_lu - ETA: 36s - loss: 379.6049 - re_lu_65_loss: 267.8482 - re_lu_121_loss: 54.2431 - re_lu_177_loss: 31.5672 - re_lu_233_loss: 25.9465 - re_lu_65_accuracy: 0.1142 - re_lu_121_accuracy: 0.2000 - re_lu_177_accuracy: 0.4013 - re_lu_23\n",
      "Epoch 00029: loss improved from 382.45148 to 376.37390, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 376.3739 - re_lu_65_loss: 264.5464 - re_lu_121_loss: 53.9916 - re_lu_177_loss: 31.6495 - re_lu_233_loss: 26.1863 - re_lu_65_accuracy: 0.1144 - re_lu_121_accuracy: 0.2000 - re_lu_177_accuracy: 0.4017 - re_lu_233_accuracy: 0.5214 - val_loss: 11680.1748 - val_re_lu_65_loss: 2719.1541 - val_re_lu_121_loss: 2885.5298 - val_re_lu_177_loss: 3022.8062 - val_re_lu_233_loss: 3052.6838 - val_re_lu_65_accuracy: 0.0929 - val_re_lu_121_accuracy: 0.1581 - val_re_lu_177_accuracy: 0.3574 - val_re_lu_233_accuracy: 0.3497\n",
      "Learning rate:  1e-05\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 372.7649 - re_lu_65_loss: 262.9418 - re_lu_121_loss: 53.2666 - re_lu_177_loss: 30.9920 - re_lu_233_loss: 25.5648 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.2003 - re_lu_177_accuracy: 0.4016 - re_lu_233_accuracy: 0.5200 - ETA: 43s - loss: 372.7879 - re_lu_65_loss: 263.1162 - re_lu_121_loss: 53.0699 - re_lu_177_loss: 30.9822 - re_lu_233_loss: 25.6197 - re_lu_65_accuracy: 0.1149 - re_lu_121_accuracy: 0.1999 - re_lu_177_accuracy: 0.40 - ETA: 37s - loss: 374.0094 - re_lu_65_loss: 264.0096 - re_lu_121_loss: 53.3020 - re_lu_177_loss: 31.0818 - re_lu_233_loss: 25. - ETA: 16s - loss: 371.8520 - re_lu_65_loss: 262.2430 - re_lu_121_loss: 53.0402 - re_lu_177_loss: 31.0105 - re_lu_233_loss: 25.5586 - re_lu_65_accuracy: 0.1149 - re_lu_121_accuracy: 0.2007 - re_lu_177_accuracy: 0.4016 - re_lu_233_accu - ETA: 14s - loss: 371.7619 - re_lu_65_loss: 262.1654 - re_lu_121_loss: 53.0383 - re_lu_177_loss: 31.0073 - \n",
      "Epoch 00030: loss improved from 376.37390 to 372.76486, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 372.7649 - re_lu_65_loss: 262.9418 - re_lu_121_loss: 53.2666 - re_lu_177_loss: 30.9920 - re_lu_233_loss: 25.5648 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.2003 - re_lu_177_accuracy: 0.4016 - re_lu_233_accuracy: 0.5200 - val_loss: 11682.9346 - val_re_lu_65_loss: 2720.2683 - val_re_lu_121_loss: 2886.8853 - val_re_lu_177_loss: 3023.2576 - val_re_lu_233_loss: 3052.5220 - val_re_lu_65_accuracy: 0.0917 - val_re_lu_121_accuracy: 0.1534 - val_re_lu_177_accuracy: 0.3531 - val_re_lu_233_accuracy: 0.3493\n",
      "Learning rate:  1e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 368.5865 - re_lu_65_loss: 261.5596 - re_lu_121_loss: 52.1482 - re_lu_177_loss: 30.0870 - re_lu_233_loss: 24.7919 - re_lu_65_accuracy: 0.1148 - re_lu_121_accuracy: 0.2018 - re_lu_177_accuracy: 0.4029 - re_lu_233_accuracy: 0.5192   ETA: 1:52 - loss: 369.7094 - re_lu_65_loss: 263.9149 - re_lu_121_loss: 51.5748 - re_lu_177_loss: 29.6951 - re_lu_ - ETA: 1:19 - loss: 372.8152 - re_lu_65_loss: 265.1936 - re_lu_121_loss: 52.4559 - re_lu_177_loss: 30.1 - ETA: 1:06 - loss: 372.1334 - re_lu_65_loss: 264.9440 - re_lu_121_los - ETA: 4s - loss: 368.4655 - re_lu_65_loss: 261.5394 - re_lu_121_loss: 52.0788 - re_lu_177_loss: 30.0724 - re_lu_233_loss: 24.7751 - re_lu_65_accuracy: 0.1149 - re_lu_121_accuracy: 0.2017 - re_lu_177_accuracy: - ETA: 1s - loss: 368.4223 - re_lu_65_loss: 261.5467 - re_lu_121_loss: 52.0756 - re_lu_177_loss: 30.0443 - re_lu_233_loss: 24.7559 - re_lu_65_accuracy: 0.1148 - re_lu_121_accuracy: 0.2019 - re_lu_177_accuracy: 0.4028 - re_lu_233_accu\n",
      "Epoch 00031: loss improved from 372.76486 to 368.58652, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 368.5865 - re_lu_65_loss: 261.5596 - re_lu_121_loss: 52.1482 - re_lu_177_loss: 30.0870 - re_lu_233_loss: 24.7919 - re_lu_65_accuracy: 0.1148 - re_lu_121_accuracy: 0.2018 - re_lu_177_accuracy: 0.4029 - re_lu_233_accuracy: 0.5192 - val_loss: 11687.2471 - val_re_lu_65_loss: 2720.4319 - val_re_lu_121_loss: 2887.7134 - val_re_lu_177_loss: 3025.2617 - val_re_lu_233_loss: 3053.8408 - val_re_lu_65_accuracy: 0.0931 - val_re_lu_121_accuracy: 0.1590 - val_re_lu_177_accuracy: 0.3557 - val_re_lu_233_accuracy: 0.3461\n",
      "Learning rate:  1e-05\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 367.0763 - re_lu_65_loss: 261.1433 - re_lu_121_loss: 51.6160 - re_lu_177_loss: 29.8041 - re_lu_233_loss: 24.5128 - re_lu_65_accuracy: 0.1146 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.4037 - re_lu_233_accuracy: 0.5188   ETA: 2:38 - l - ETA: 2:19 - loss: 365.6700 -  - ETA: 50s - loss: 369.6013 - re_lu_65_loss: 262.2608 - re_lu_121_loss: 52.2060 - re_lu_177_loss: 30.2689 - re_lu_233_loss: 24.8657 - re_lu_65_accuracy: 0.1148 - re_lu_121_accuracy: 0.2046 - re_lu_177_acc - ETA: 43s - loss: 371.1380 - re_lu_65_loss: 263.7839 - re_lu_121_loss: 52.2690 - re_lu_177_loss: 30.2538 - re_lu_233_loss: 24.8314 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.2040 - re_lu_177_accuracy: 0.4048 - re_lu_23 - ETA: 40s - loss: 370.7049 - re_lu_65_loss: 263.7150 - re_lu_121_loss: 52.0835 - re_lu_177 - ETA: 12s - loss: 367.6107 - re_lu_65_loss: 261.5479 - re_lu_121_loss: 51.6066 - re_lu_177_loss: 29.8637 - re_lu_233_loss: 24.5924 - re_l - ETA: 1s - loss: 367.4062 - re_lu_65_loss: 261.3607 - re_lu_121_loss: 51.6712 - re_lu_177_loss: 29.8381 - re_lu_233_loss: 24.5364 - re_lu_65_accuracy: 0.1146 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.4041 - re_lu_\n",
      "Epoch 00032: loss improved from 368.58652 to 367.07626, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 367.0763 - re_lu_65_loss: 261.1433 - re_lu_121_loss: 51.6160 - re_lu_177_loss: 29.8041 - re_lu_233_loss: 24.5128 - re_lu_65_accuracy: 0.1146 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.4037 - re_lu_233_accuracy: 0.5188 - val_loss: 11693.9043 - val_re_lu_65_loss: 2721.4731 - val_re_lu_121_loss: 2889.1370 - val_re_lu_177_loss: 3026.6157 - val_re_lu_233_loss: 3056.6802 - val_re_lu_65_accuracy: 0.0924 - val_re_lu_121_accuracy: 0.1560 - val_re_lu_177_accuracy: 0.3512 - val_re_lu_233_accuracy: 0.3332\n",
      "Learning rate:  1e-05\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 361.5858 - re_lu_65_loss: 258.6349 - re_lu_121_loss: 50.4980 - re_lu_177_loss: 28.8160 - re_lu_233_loss: 23.6367 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.2033 - re_lu_177_accuracy: 0.4047 - re_lu_233_accuracy: 0.5183   ETA: 1:23 - loss: 363.7693 - re_lu_65_loss: 259.1643 - re_lu_121_loss: 51.2352 - re_lu_177_loss: 29.3677 - re_lu_233_loss: 24.0021  - ETA: 43s - loss: 362.5776 - re_lu_65_loss: 259.4258 - re_lu_121_loss: 50.5846 - re_lu_177_loss: 28.8811 - re_lu_233_loss: 23.6860 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.2029 - re_lu_177_accur - ETA: 36s - loss: 362.6336 - re_lu_65_loss: 259.6536 - re_lu_121_loss: 50.5069 - re_lu_177_loss: 28.8241 - re_lu_233_loss: 23.6489 - re_lu_65_accuracy: - ETA: 19s - loss: 362.3836 - re_lu_65_loss: 259.2180 - re_lu_121_loss: 50.57\n",
      "Epoch 00033: loss improved from 367.07626 to 361.58585, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 361.5858 - re_lu_65_loss: 258.6349 - re_lu_121_loss: 50.4980 - re_lu_177_loss: 28.8160 - re_lu_233_loss: 23.6367 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.2033 - re_lu_177_accuracy: 0.4047 - re_lu_233_accuracy: 0.5183 - val_loss: 11688.7051 - val_re_lu_65_loss: 2719.9897 - val_re_lu_121_loss: 2888.3948 - val_re_lu_177_loss: 3025.8293 - val_re_lu_233_loss: 3054.4912 - val_re_lu_65_accuracy: 0.0931 - val_re_lu_121_accuracy: 0.1587 - val_re_lu_177_accuracy: 0.3625 - val_re_lu_233_accuracy: 0.3367\n",
      "Learning rate:  1e-05\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 361.3185 - re_lu_65_loss: 259.0987 - re_lu_121_loss: 50.1747 - re_lu_177_loss: 28.6198 - re_lu_233_loss: 23.4253 - re_lu_65_accuracy: 0.1151 - re_lu_121_accuracy: 0.2036 - re_lu_177_accuracy: 0.4054 - re_lu_233_accuracy: 0.5215   ETA: 1:29 - loss: 364.2232 - re_lu_65_loss: 262.1446 - re_lu_121_loss: 5 - ETA: 44s - loss: 365.0120 - re_lu_6 - ETA: 8s - loss: 362.5074 - re_lu_65_loss: 259.9427 - re_lu_121_loss: 50.3765 - re_lu_177_loss: 28.7117 - re_lu_233_loss: 23.4765 - re_lu_65_accuracy: 0.1150 - re - ETA: 1s - loss: 361.3431 - re_lu_65_loss: 259.0704 - re_lu_121_loss: 50.2031 - re_lu_177_loss: 28.6359 - re_lu_233_loss: 23.4337 - re_lu_65_accuracy: 0.1151 - re_lu_121_accuracy: 0.2035 - re_lu_177_accuracy: 0.4054 - re_lu_\n",
      "Epoch 00034: loss improved from 361.58585 to 361.31848, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 361.3185 - re_lu_65_loss: 259.0987 - re_lu_121_loss: 50.1747 - re_lu_177_loss: 28.6198 - re_lu_233_loss: 23.4253 - re_lu_65_accuracy: 0.1151 - re_lu_121_accuracy: 0.2036 - re_lu_177_accuracy: 0.4054 - re_lu_233_accuracy: 0.5215 - val_loss: 11692.9609 - val_re_lu_65_loss: 2720.9199 - val_re_lu_121_loss: 2889.3208 - val_re_lu_177_loss: 3027.4131 - val_re_lu_233_loss: 3055.3081 - val_re_lu_65_accuracy: 0.0931 - val_re_lu_121_accuracy: 0.1567 - val_re_lu_177_accuracy: 0.3527 - val_re_lu_233_accuracy: 0.3387\n",
      "Learning rate:  1e-05\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 359.5745 - re_lu_65_loss: 258.0398 - re_lu_121_loss: 49.8843 - re_lu_177_loss: 28.4226 - re_lu_233_loss: 23.2279 - re_lu_65_accuracy: 0.1160 - re_lu_121_accuracy: 0.2033 - re_lu_177_accuracy: 0.4069 - re_lu_233_accuracy: 0.5221   ETA: 2:42 - loss: 338.3046 - re_lu_65_loss: 2\n",
      "Epoch 00035: loss improved from 361.31848 to 359.57452, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 200s 200ms/step - loss: 359.5745 - re_lu_65_loss: 258.0398 - re_lu_121_loss: 49.8843 - re_lu_177_loss: 28.4226 - re_lu_233_loss: 23.2279 - re_lu_65_accuracy: 0.1160 - re_lu_121_accuracy: 0.2033 - re_lu_177_accuracy: 0.4069 - re_lu_233_accuracy: 0.5221 - val_loss: 11699.1289 - val_re_lu_65_loss: 2723.5229 - val_re_lu_121_loss: 2890.5620 - val_re_lu_177_loss: 3027.6707 - val_re_lu_233_loss: 3057.3723 - val_re_lu_65_accuracy: 0.0932 - val_re_lu_121_accuracy: 0.1565 - val_re_lu_177_accuracy: 0.3561 - val_re_lu_233_accuracy: 0.3423\n",
      "Learning rate:  1e-05\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 358.5227 - re_lu_65_loss: 257.0307 - re_lu_121_loss: 49.6488 - re_lu_177_loss: 28.5191 - re_lu_233_loss: 23.3241 - re_lu_65_accuracy: 0.1150 - re_lu_121_accuracy: 0.2019 - re_lu_177_accuracy: 0.4080 - re_lu_233_accuracy: 0.5218   ETA: 2:25 - loss: 359.5255 - re_lu_65_loss: 255.0409 - re_lu_121_loss: 50.8329 - re_l - ETA: 2:11 - loss: 352.8931 - re_lu_65_loss: 250.8227 -  - ETA: 1:32 - loss: 359.0389 - re_lu_65_loss: 256.8194 - re_lu_121_loss: 49.8723 - re_lu_177_loss: 28.8389 - re_lu_233_loss: 23.5083 - re_lu_65_accuracy: 0.1148 - re_lu_121_accuracy: 0.2004 - re_lu_177_accurac - ETA: 1:07 - loss: 361.6126 - re_lu_65_loss: 259.3298 - ETA: 2s - loss: 359.3229 - re_lu_65_loss: 257.5818 - re_lu_121_loss: 49.7825 - re_lu_177_loss: 28.5887 - re_lu_233_loss: 23.3699 - re_lu_65_accuracy: 0.1149 - re_lu_121_accuracy: 0.2016 - re_lu_177_accuracy: 0.4\n",
      "Epoch 00036: loss improved from 359.57452 to 358.52267, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 358.5227 - re_lu_65_loss: 257.0307 - re_lu_121_loss: 49.6488 - re_lu_177_loss: 28.5191 - re_lu_233_loss: 23.3241 - re_lu_65_accuracy: 0.1150 - re_lu_121_accuracy: 0.2019 - re_lu_177_accuracy: 0.4080 - re_lu_233_accuracy: 0.5218 - val_loss: 11704.0518 - val_re_lu_65_loss: 2723.0249 - val_re_lu_121_loss: 2892.1326 - val_re_lu_177_loss: 3029.4753 - val_re_lu_233_loss: 3059.4216 - val_re_lu_65_accuracy: 0.0924 - val_re_lu_121_accuracy: 0.1619 - val_re_lu_177_accuracy: 0.3608 - val_re_lu_233_accuracy: 0.3454\n",
      "Learning rate:  1e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 357.8801 - re_lu_65_loss: 256.7996 - re_lu_121_loss: 49.5968 - re_lu_177_loss: 28.3032 - re_lu_233_loss: 23.1804 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2021 - re_lu_177_accuracy: 0.4078 - re_lu_233_accuracy: 0.5229   ETA: 1:01 - loss: 357.8936 - re_lu_65_loss: 256.1382 - re_lu_121_loss: 49.9735 - re_lu_177_loss: 28.4623 - re_lu_233_loss: 23.3196 - re_lu - ETA: 44s - loss: 358.5987 - re_lu_65_loss: 257.3086 - re_lu_121_loss: 49.7556 - re_lu_177_loss: 28.2980 - re_lu_233_loss: 23.2364 - re_lu_65_accuracy: 0.1154 - re_lu_121_accuracy: 0.2021 - re_lu_177 - ETA: 36s - loss: 358.7368 - re_lu_65_loss: 257.0462 - re_lu_121_loss: 50.0827 - re_lu_177_loss: 28.3632 - re_lu_233_loss: 23.2448 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2021 - re_lu_177_accuracy: 0.4074 - re_lu_233_accu - ETA: 34s - loss: 358.9110 - re_lu_65_loss: 257.0363 - re_lu_121_loss: 50.1326 - re_lu_177_loss: 28.4625 - re_lu_233_loss: 23.2798 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy - ETA: 22s - loss: 359.4481 - re_lu_65_loss: 257.5646 - re_lu_121_loss: 50.0617 - re_lu_177_loss: 28.4968 - re_lu_233_l - ETA: 4s - loss: 358.1377 - re_lu_65_loss: 256.7434 - re_lu_121_loss: 49.7640 - re_lu_177_loss: 28.3862 - re_lu_233_loss: 23.2440 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2021 - re_\n",
      "Epoch 00037: loss improved from 358.52267 to 357.88013, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "1000/1000 [==============================] - 199s 199ms/step - loss: 357.8801 - re_lu_65_loss: 256.7996 - re_lu_121_loss: 49.5968 - re_lu_177_loss: 28.3032 - re_lu_233_loss: 23.1804 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2021 - re_lu_177_accuracy: 0.4078 - re_lu_233_accuracy: 0.5229 - val_loss: 11702.1689 - val_re_lu_65_loss: 2722.9287 - val_re_lu_121_loss: 2891.6875 - val_re_lu_177_loss: 3029.1572 - val_re_lu_233_loss: 3058.3948 - val_re_lu_65_accuracy: 0.0935 - val_re_lu_121_accuracy: 0.1574 - val_re_lu_177_accuracy: 0.3669 - val_re_lu_233_accuracy: 0.3477\n",
      "Learning rate:  1e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 355.3581 - re_lu_65_loss: 255.4294 - re_lu_121_loss: 49.1282 - re_lu_177_loss: 27.9217 - re_lu_233_loss: 22.8790 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.4082 - re_lu_233_accuracy: 0.5193 - ETA: 16s - loss: 356.9633 - re_lu_65_loss: 256.5598 - re_lu_121_loss: 49.4267 - re_lu_177_loss: 28.0193 - re_lu_233_los - ETA: 2s - loss: 355.7511 - re_lu_65_loss: 255.7517 - re_lu_121_loss: 49.1878 - re_lu_177_loss: 27.9339 - re_lu_233_loss: 22.8779 - re_lu_65_accuracy: 0.1152 - re_lu_121_accuracy: 0.2026 - re_lu_177_accuracy: 0.4083 - \n",
      "Epoch 00038: loss improved from 357.88013 to 355.35809, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 355.3581 - re_lu_65_loss: 255.4294 - re_lu_121_loss: 49.1282 - re_lu_177_loss: 27.9217 - re_lu_233_loss: 22.8790 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2028 - re_lu_177_accuracy: 0.4082 - re_lu_233_accuracy: 0.5193 - val_loss: 11707.2754 - val_re_lu_65_loss: 2724.5330 - val_re_lu_121_loss: 2893.1782 - val_re_lu_177_loss: 3030.1328 - val_re_lu_233_loss: 3059.4316 - val_re_lu_65_accuracy: 0.0935 - val_re_lu_121_accuracy: 0.1614 - val_re_lu_177_accuracy: 0.3623 - val_re_lu_233_accuracy: 0.3361\n",
      "Learning rate:  1e-05\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 353.9396 - re_lu_65_loss: 254.8139 - re_lu_121_loss: 48.7157 - re_lu_177_loss: 27.7360 - re_lu_233_loss: 22.6742 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2024 - re_lu_177_accuracy: 0.4092 - re_lu_233_accuracy: 0.5215   ETA: 2:22 - loss: 362.7130 - re_lu_65_loss: 258.9836 - re_lu_121_loss: 51.0020 - re_lu_177_loss: 29.0813 - re_lu_233_loss: 23.6460 - re_lu_65_a - ETA: 2:14 - loss: 361.6779 - re_lu_65_loss: 259.2061 - re_lu_121_loss: 50.2850 - re_lu_177_lo - ETA: 1:40 - loss: 354.2758 - re_lu_65_loss: 254.1945 - re_lu_121_loss: 48.8595 - re_lu_177_loss: 28.2868 - re_lu_233_loss: 22.9353\n",
      "Epoch 00039: loss improved from 355.35809 to 353.93958, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 353.9396 - re_lu_65_loss: 254.8139 - re_lu_121_loss: 48.7157 - re_lu_177_loss: 27.7360 - re_lu_233_loss: 22.6742 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2024 - re_lu_177_accuracy: 0.4092 - re_lu_233_accuracy: 0.5215 - val_loss: 11708.9170 - val_re_lu_65_loss: 2725.0369 - val_re_lu_121_loss: 2894.4463 - val_re_lu_177_loss: 3030.1975 - val_re_lu_233_loss: 3059.2390 - val_re_lu_65_accuracy: 0.0938 - val_re_lu_121_accuracy: 0.1558 - val_re_lu_177_accuracy: 0.3624 - val_re_lu_233_accuracy: 0.3410\n",
      "Learning rate:  1e-05\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 350.4471 - re_lu_65_loss: 252.9269 - re_lu_121_loss: 48.0795 - re_lu_177_loss: 27.1716 - re_lu_233_loss: 22.2691 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.2026 - re_lu_177_accuracy: 0.4094 - re_lu_233_accuracy: 0.5245   ETA: 1:06 - loss: 351.2736 - re_lu_65_loss: 253.3564 - re_lu_121_loss: 48.2208 - re_lu_177_loss: 27.3340 - re_lu_233_loss: 22.3622  - ETA: 53s - loss: 350.5025 - re_lu_65_loss: 252.6539 - re_lu_121_loss: 48.0451 - re_lu_177_loss: 27.3667 - re_lu_233_loss: 22.4366 - \n",
      "Epoch 00040: loss improved from 353.93958 to 350.44705, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 350.4471 - re_lu_65_loss: 252.9269 - re_lu_121_loss: 48.0795 - re_lu_177_loss: 27.1716 - re_lu_233_loss: 22.2691 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.2026 - re_lu_177_accuracy: 0.4094 - re_lu_233_accuracy: 0.5245 - val_loss: 11711.7285 - val_re_lu_65_loss: 2725.1250 - val_re_lu_121_loss: 2894.4893 - val_re_lu_177_loss: 3031.2305 - val_re_lu_233_loss: 3060.8904 - val_re_lu_65_accuracy: 0.0940 - val_re_lu_121_accuracy: 0.1527 - val_re_lu_177_accuracy: 0.3622 - val_re_lu_233_accuracy: 0.3427\n",
      "Learning rate:  1e-05\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 350.7483 - re_lu_65_loss: 253.0144 - re_lu_121_loss: 48.2136 - re_lu_177_loss: 27.2763 - re_lu_233_loss: 22.2442 - re_lu_65_accuracy: 0.1165 - re_lu_121_accuracy: 0.2024 - re_lu_177_accuracy: 0.4100 - re_lu_233_accuracy: 0.5218   ETA: 2:41 - loss: 362.2942 - re_lu_65_loss: 260.2453 - re_lu_121_loss: 51.0378 - re_lu_177_loss: 27.9359 - re_lu_233_loss: 23.0752 - re_lu_ - ETA: 2:33 - loss: 351.2794 - re_lu_65_loss: 251.9676 - re_lu_121_loss: 49.3461 - re_lu_177_loss: 27.5064 - re_lu_233_loss: 22.4593 - re_lu_65_accuracy: 0.1177 - re_lu_121_accuracy: 0.2029 - re_lu_177_accuracy: 0.4168 - re_lu_233_accura - ETA: 2:32 - loss: 352.7857 - re_lu_65 - ETA: 1:52 - loss: 351.3106 - re_lu_65_loss: 252.1861 - re_lu_121_loss: 49.2257 - re_lu_177_loss: 27.4152 - re_lu_233_loss: 22.4836 - re_lu_65_accuracy: 0.1171 - re_lu_121_accu - ETA: 1:46 - loss: 352.8194 - re_lu_65_loss: 253.2064 - re_lu_121_loss: 49.4462 - re_lu_177_loss: 27.5988 - re_lu_233_loss: 22.5680 - re_lu_65_accuracy: 0.1169 - re_lu_121_accuracy: 0.2006 - re_lu_177_accuracy: 0.4106 - re_lu_23 - ETA: 1:45 - loss: 353.1069 - re_lu_65_loss: 253.3882 - re_lu_121_loss: 49.4632 - re_lu_177_loss: 27.7101 - re_lu_233_loss: 22.5454 - re_lu_65_accuracy: 0.1168 - re_lu_121_accuracy: 0.2005 - re_lu_177_a - ETA: 1:41 - loss: 354.4490 - re_lu_65_loss: 254.4168 - re_lu_121_loss: 49.5885 - re_lu_177_loss: 27.7905 - re_lu_233_loss: 22 - ETA: 1:30 - loss: 353.8662 - re_lu_65_loss: 254.2009 - re_lu_121_loss: 49.3603 - re - ETA: 49s - loss: 348.3557 - re_lu_65_loss: 250.8119 - re_lu_121_loss: 48.1796 - re_lu_177_loss: 27.2397 - re_lu_233_loss: 22.1245 - r - ETA: 29s - loss: 351.0337 - re_lu_65_loss: 252.7739 - re_lu_121_loss: 48.6420 - re_lu_177_loss: 27.3738 - re_lu_233_loss: 22.2444 - ETA: 9s - loss: 350.6606 - re_lu_65_loss: 252.7926 - re_lu_121_loss: 48.3177 - re_lu_177_loss: 27.2859 - re_lu_233_loss: 22.2646 - re\n",
      "Epoch 00041: loss did not improve from 350.44705\n",
      "1000/1000 [==============================] - 187s 187ms/step - loss: 350.7483 - re_lu_65_loss: 253.0144 - re_lu_121_loss: 48.2136 - re_lu_177_loss: 27.2763 - re_lu_233_loss: 22.2442 - re_lu_65_accuracy: 0.1165 - re_lu_121_accuracy: 0.2024 - re_lu_177_accuracy: 0.4100 - re_lu_233_accuracy: 0.5218 - val_loss: 11704.8516 - val_re_lu_65_loss: 2723.8257 - val_re_lu_121_loss: 2893.5750 - val_re_lu_177_loss: 3029.0085 - val_re_lu_233_loss: 3058.4446 - val_re_lu_65_accuracy: 0.0940 - val_re_lu_121_accuracy: 0.1564 - val_re_lu_177_accuracy: 0.3609 - val_re_lu_233_accuracy: 0.3420\n",
      "Learning rate:  1e-05\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 349.9382 - re_lu_65_loss: 252.8322 - re_lu_121_loss: 47.7332 - re_lu_177_loss: 27.1439 - re_lu_233_loss: 22.2286 - re_lu_65_accuracy: 0.1165 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.4092 - re_lu_233_accuracy: 0.5255   ETA: 1:40 - loss: 341.4560 - re_lu_65_loss: 246.9745 - re_lu_121_loss: 46.2592 - re_lu_177_loss: 26.3663 - re_lu_233_loss: 21.8556 - re_l - ETA: 1:31 - loss: 345.6992 - re_lu_65_loss: 250.0367 - re_lu_121_loss: 46.6591 - re_lu_177_loss: 26.8025 - re_lu_233_loss: 22.20 - ETA: 58s - loss: 347.7125 - re_lu_65_loss: 251.4268 - re_lu_121_loss: 47.4629 - re_lu_177_loss: 26.8436 \n",
      "Epoch 00042: loss improved from 350.44705 to 349.93817, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 349.9382 - re_lu_65_loss: 252.8322 - re_lu_121_loss: 47.7332 - re_lu_177_loss: 27.1439 - re_lu_233_loss: 22.2286 - re_lu_65_accuracy: 0.1165 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.4092 - re_lu_233_accuracy: 0.5255 - val_loss: 11710.7920 - val_re_lu_65_loss: 2724.7283 - val_re_lu_121_loss: 2895.0200 - val_re_lu_177_loss: 3031.3213 - val_re_lu_233_loss: 3059.7244 - val_re_lu_65_accuracy: 0.0945 - val_re_lu_121_accuracy: 0.1546 - val_re_lu_177_accuracy: 0.3671 - val_re_lu_233_accuracy: 0.3415\n",
      "Learning rate:  1e-05\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 347.5684 - re_lu_65_loss: 251.6387 - re_lu_121_loss: 47.3781 - re_lu_177_loss: 26.7544 - re_lu_233_loss: 21.7971 - re_lu_65_accuracy: 0.1156 - re_lu_121_accuracy: 0.2015 - re_lu_177_accuracy: 0.4106 - re_lu_233_accuracy: 0.5252 - ETA: 54s - loss: 344.7639 - re_lu_65_loss: 250.9411 - re_lu_121_loss: 46.3752 - re_lu_177_loss: 26.1425 - re_lu_233_loss: 21.3050 - re_lu_65_accurac - ETA: 37s - loss: 344.5835 - re_lu_65_loss: 250.2784 - re_lu_121_loss: 46.4448 - re_lu_177_loss: 26.357 - ETA: 12s - loss: 347.9970 - re_lu_65_loss: 252.3891 - re_lu_121_loss: 47.1779 - re_lu_177_loss: 26.6834 - re_lu_233_loss\n",
      "Epoch 00043: loss improved from 349.93817 to 347.56842, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 347.5684 - re_lu_65_loss: 251.6387 - re_lu_121_loss: 47.3781 - re_lu_177_loss: 26.7544 - re_lu_233_loss: 21.7971 - re_lu_65_accuracy: 0.1156 - re_lu_121_accuracy: 0.2015 - re_lu_177_accuracy: 0.4106 - re_lu_233_accuracy: 0.5252 - val_loss: 11720.3564 - val_re_lu_65_loss: 2726.5466 - val_re_lu_121_loss: 2898.1599 - val_re_lu_177_loss: 3032.9600 - val_re_lu_233_loss: 3062.6899 - val_re_lu_65_accuracy: 0.0928 - val_re_lu_121_accuracy: 0.1549 - val_re_lu_177_accuracy: 0.3680 - val_re_lu_233_accuracy: 0.3440\n",
      "Learning rate:  1e-05\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 348.5407 - re_lu_65_loss: 251.6335 - re_lu_121_loss: 47.6686 - re_lu_177_loss: 27.0506 - re_lu_233_loss: 22.1883 - re_lu_65_accuracy: 0.1157 - re_lu_121_accuracy: 0.2020 - re_lu_177_accuracy: 0.4122 - re_lu_233_accuracy: 0.5293   ETA: 1:24 - loss: 346.5449 - re_lu_65_loss: 249.9466 - re_lu_121_loss: 47.6276 - re_lu_177_loss: 26.8699 - re_lu_233_loss: 22.1009 - re_lu_65_accuracy: 0.1162 - re_lu_121_accuracy: 0.2042 - ETA: 55s - loss: 349.6281 - re_lu_65_loss: 252.7601 - re_lu_121_loss: 47.7640 - re_lu_177_loss: 27.0376 - re_lu_233_loss: 22.0666 - re_lu_65_accuracy:  - ETA: 39s - loss: 348.0147 - r - ETA: 5s - loss: 348.1538 - re_lu_65_loss: 251.4922 - re_lu_121_loss: 47.6170 - re_lu_177_loss: 26.9660 - re_lu_233_loss: 22.0788 - re_lu_65_accuracy: 0.1157 - re_lu_121_accuracy: \n",
      "Epoch 00044: loss did not improve from 347.56842\n",
      "1000/1000 [==============================] - 188s 188ms/step - loss: 348.5407 - re_lu_65_loss: 251.6335 - re_lu_121_loss: 47.6686 - re_lu_177_loss: 27.0506 - re_lu_233_loss: 22.1883 - re_lu_65_accuracy: 0.1157 - re_lu_121_accuracy: 0.2020 - re_lu_177_accuracy: 0.4122 - re_lu_233_accuracy: 0.5293 - val_loss: 11713.3574 - val_re_lu_65_loss: 2726.9475 - val_re_lu_121_loss: 2895.8164 - val_re_lu_177_loss: 3030.8545 - val_re_lu_233_loss: 3059.7371 - val_re_lu_65_accuracy: 0.0921 - val_re_lu_121_accuracy: 0.1560 - val_re_lu_177_accuracy: 0.3625 - val_re_lu_233_accuracy: 0.3434\n",
      "Learning rate:  1e-05\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 346.1513 - re_lu_65_loss: 250.4990 - re_lu_121_loss: 47.2523 - re_lu_177_loss: 26.6243 - re_lu_233_loss: 21.7755 - re_lu_65_accuracy: 0.1154 - re_lu_121_accuracy: 0.2022 - re_lu_177_accuracy: 0.4117 - re_lu_233_accuracy: 0.5321 ETA: 1s - loss: 346.2896 - re_lu_65_loss: 250.6266 - re_lu_121_loss: 47.2502 - re_lu_177_loss: 26.6313 - re_lu_233_loss: 21.7814 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2021 - re_lu_177_accuracy: 0.4117 - re_lu_\n",
      "Epoch 00045: loss improved from 347.56842 to 346.15134, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 198s 198ms/step - loss: 346.1513 - re_lu_65_loss: 250.4990 - re_lu_121_loss: 47.2523 - re_lu_177_loss: 26.6243 - re_lu_233_loss: 21.7755 - re_lu_65_accuracy: 0.1154 - re_lu_121_accuracy: 0.2022 - re_lu_177_accuracy: 0.4117 - re_lu_233_accuracy: 0.5321 - val_loss: 11722.0146 - val_re_lu_65_loss: 2726.9028 - val_re_lu_121_loss: 2898.3975 - val_re_lu_177_loss: 3033.7822 - val_re_lu_233_loss: 3062.9417 - val_re_lu_65_accuracy: 0.0926 - val_re_lu_121_accuracy: 0.1567 - val_re_lu_177_accuracy: 0.3679 - val_re_lu_233_accuracy: 0.3463\n",
      "Learning rate:  1e-05\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 346.8918 - re_lu_65_loss: 250.8943 - re_lu_121_loss: 47.2413 - re_lu_177_loss: 26.8657 - re_lu_233_loss: 21.8904 - re_lu_65_accuracy: 0.1155 - re_lu_121_accuracy: 0.2023 - re_lu_177_accuracy: 0.4130 - re_lu_233_accuracy: 0.5305   ETA: 1:43 - loss: 347.8808 - re_lu_65_loss: 251.8623 - re_lu_121_loss: 47.2641 - re_lu_17 - ETA: 1:30 - loss: 346.9797 - re_lu_65_loss: 251.0873 - re_lu_121_loss: 47.3827 - re_lu_17 - ETA: 1:16 - loss:  - ETA: 53s - loss: 349.4063 - re_lu_65_loss: 252.6526 - re_lu_121_loss: 47.6864 - re_lu_177_loss: 27.0672 - re_lu_233_loss: 22.0001 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2025 - re_lu_177_accuracy: 0.4146 - re_lu_233_accurac - ETA: 51s - loss: 350.0655 - re_lu_65_loss: 253.2139 - re_lu_121_loss: 47.7017 - re_lu_177_loss: 27.1056 - re_lu_233_loss: 22.0442 - re_lu_65_accuracy: 0.1153 - re_lu_121_accuracy: 0.2026 - re_lu_177_accuracy: 0.4144 - re_lu_233_accu - ETA: 49s - loss: 349.5014 - re_lu_65_loss: 252.9417 - re_lu_121_loss: 47.5406 - re_lu_177_loss: 27.0337 - re_lu_233_loss: 21.9854 - re_lu_65_accuracy: 0.115 - ETA: 34s - loss: 349.3282 - re_lu_65_loss: 252.4865 - re_lu_121_loss: 47.6161 - re_lu_177_loss: 27.1093 - re_lu_233_loss: 22.1163 - re_lu_65_accuracy: 0.1152 - re_lu_121_accuracy: 0.2024 - re_lu_17 - ETA: 26s - loss: 350.2442 - re_lu_65_loss: 253.4109 - re_lu_121_loss: 47.7123 - re_lu_177_loss: 27.0664 - re_lu_233_loss: 22.0545 - re_lu_65_accuracy: 0.1152 - re_lu_121_accuracy: 0.2023 - r - ETA: 16s - loss: 349.3011 - re_lu_65_loss: 252.7767 - re_lu_121_loss: 47.5793 - re_lu_177_loss: 26.9795 - re_lu_233_loss: 21.9655 - re_lu_65_accuracy: 0.1154 - re_lu_ - ETA: 6s - loss: 347.2842 - re_lu_65_loss: 251.1001 - re_lu_121_loss: 47.3420 - re_lu_177_loss: 26.8933 - re_lu_233_loss: 21.9487 - re_lu_65_accuracy: 0.1155 - re_lu_121_ac\n",
      "Epoch 00046: loss did not improve from 346.15134\n",
      "1000/1000 [==============================] - 187s 187ms/step - loss: 346.8918 - re_lu_65_loss: 250.8943 - re_lu_121_loss: 47.2413 - re_lu_177_loss: 26.8657 - re_lu_233_loss: 21.8904 - re_lu_65_accuracy: 0.1155 - re_lu_121_accuracy: 0.2023 - re_lu_177_accuracy: 0.4130 - re_lu_233_accuracy: 0.5305 - val_loss: 11717.4121 - val_re_lu_65_loss: 2727.5320 - val_re_lu_121_loss: 2897.7410 - val_re_lu_177_loss: 3032.1069 - val_re_lu_233_loss: 3060.0325 - val_re_lu_65_accuracy: 0.0944 - val_re_lu_121_accuracy: 0.1558 - val_re_lu_177_accuracy: 0.3627 - val_re_lu_233_accuracy: 0.3443\n",
      "Learning rate:  1e-05\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 343.4117 - re_lu_65_loss: 249.4121 - re_lu_121_loss: 46.4825 - re_lu_177_loss: 26.1900 - re_lu_233_loss: 21.3269 - re_lu_65_accuracy: 0.1156 - re_lu_121_accuracy: 0.2026 - re_lu_177_accuracy: 0.4135 - re_lu_233_accuracy: 0.5319   ETA: 1:30 - loss: 342.0675 - re_lu_65_loss: 249.1601 - re_lu_121_loss: 45.6171 - re_lu_177_loss: 25.9796 - re_lu_233_loss: 21.3108 - re_lu_65_accuracy: 0.1155 - re_lu_121_accuracy - ETA: 1:24 - loss: 342.6285 - re_lu_65_loss: 249.6057 - re_lu_121_loss: 45.6725 - re_lu_177_loss: 26.0364 - re_lu_233_loss: 21.3139  - ETA: 1:14 - loss: 341.9916 -  - ETA: 8s - loss: 344.3319 - re_lu_65_loss: 250.3248 - re_lu_121_loss: 46.4584 - re_lu_177_loss: 26.2119 - re_lu_233_loss: 21.3366 - re_lu_65_accurac\n",
      "Epoch 00047: loss improved from 346.15134 to 343.41165, saving model to single_person_modelv5.h5\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 343.4117 - re_lu_65_loss: 249.4121 - re_lu_121_loss: 46.4825 - re_lu_177_loss: 26.1900 - re_lu_233_loss: 21.3269 - re_lu_65_accuracy: 0.1156 - re_lu_121_accuracy: 0.2026 - re_lu_177_accuracy: 0.4135 - re_lu_233_accuracy: 0.5319 - val_loss: 11719.6914 - val_re_lu_65_loss: 2726.9990 - val_re_lu_121_loss: 2897.5176 - val_re_lu_177_loss: 3033.3044 - val_re_lu_233_loss: 3061.8679 - val_re_lu_65_accuracy: 0.0946 - val_re_lu_121_accuracy: 0.1590 - val_re_lu_177_accuracy: 0.3644 - val_re_lu_233_accuracy: 0.3425\n",
      "Learning rate:  1e-05\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 343.9687 - re_lu_65_loss: 249.6652 - re_lu_121_loss: 46.6065 - re_lu_177_loss: 26.2369 - re_lu_233_loss: 21.4601 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.4150 - re_lu_233_accuracy: 0.5300 - ETA: 58s - loss: 342.9712 - re_lu_65_loss: 248.7649 - re_lu_121_loss: 46.4161 - re_lu_177_loss: 26.3051 \n",
      "Epoch 00048: loss did not improve from 343.41165\n",
      "1000/1000 [==============================] - 188s 188ms/step - loss: 343.9687 - re_lu_65_loss: 249.6652 - re_lu_121_loss: 46.6065 - re_lu_177_loss: 26.2369 - re_lu_233_loss: 21.4601 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.2012 - re_lu_177_accuracy: 0.4150 - re_lu_233_accuracy: 0.5300 - val_loss: 11729.0469 - val_re_lu_65_loss: 2728.0815 - val_re_lu_121_loss: 2900.9597 - val_re_lu_177_loss: 3036.1304 - val_re_lu_233_loss: 3063.8733 - val_re_lu_65_accuracy: 0.0945 - val_re_lu_121_accuracy: 0.1583 - val_re_lu_177_accuracy: 0.3718 - val_re_lu_233_accuracy: 0.3512\n",
      "Learning rate:  1e-05\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 343.6663 - re_lu_65_loss: 249.1152 - re_lu_121_loss: 46.6083 - re_lu_177_loss: 26.3813 - re_lu_233_loss: 21.5615 - re_lu_65_accuracy: 0.1162 - re_lu_121_accuracy: 0.2030 - re_lu_177_accuracy: 0.4165 - re_lu_233_accuracy: 0.5328   ETA: 2:02 - loss: 350.0397 - re_lu_65_loss: 255.4192 - re_lu_121_loss: 46.8426 - re_lu_177_loss: 26.2794 - re_lu_233_loss: 21.4984 - re_lu_65_accuracy: 0.1158 - re_l - ETA: 1:32 - loss: 346.0752 - re_lu_65_loss: 251.9419 - re_lu_121_loss:  - ETA: 1:16 - loss: 341.1270 - re_lu_65_loss: 248.2731 - re_lu_121_loss: 45.8067 - re_lu_177_loss: 25.8246 - re_lu_233_loss: 21.2227 - re_lu_65_accuracy: 0.1166 - re_lu_121_accuracy: 0.2038 - re_lu_177_accuracy: 0.4159 - re_lu_233_accura - ETA: 1:15 - loss: 340.3237 - re_lu_65_loss: 247.5954 - re_lu_121_loss: 45.7413 - re_lu_177_loss: 25.7919 - re_lu_233_loss: 21.1952 - re_lu_65_accuracy: 0.1167 - re_lu_121_accuracy: 0. - ETA: 1:09 - loss: 342.3406 - re_lu_65_loss: 248.7927 - re_lu_121_loss: 46.1516 - re_lu_177_loss: 26.0849 - re_lu_233_loss: 21.3116 - re_lu_65_accuracy: 0.1165 - re_lu_121_accuracy: 0.2033 - re_lu_177_accuracy: 0.4163 -  - ETA: 1:06 - loss: 341.3605 - re_lu_65_loss: 247.9104 - re_lu_121_loss: 46.0797 - re_lu_177_loss: 26.0618 - re_lu_233_loss: 21.3086 - re_lu_65_accura - ETA: 55s - loss: 339.6062 - re_lu_65_loss: 246.3847 - re_lu_121_loss: 45.8927 - re_lu_177_loss: 26.0216 - re_lu_233_loss: 21.3073 - re_lu_65_accuracy: 0.1165 - re_lu_121_accuracy: 0.2027 - re_ - ETA: 46s - loss: 340.3747 - re_lu_65_loss: 246.8663 - re_lu_121_loss: 45.9897 - re_ - ETA: 16s - loss: 343.6181 - re_lu_65_loss: 248.9152 - re_lu_121_loss: 46.7211 - re_lu_177_loss: 26.4269 - re_lu_233_loss: 21.5553 - re_lu_65_accuracy: 0.1162 - re_lu_121_accuracy: 0.2029 - re_lu_177_accuracy: 0.4163 - re_lu_233_accuracy: 0.5 - ETA: 16s - loss: 343.8610 - re_lu_65_loss: 249.1244 - re_lu_121_loss: 46.7681 - re_lu_177_loss: 26.\n",
      "Epoch 00049: loss did not improve from 343.41165\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 343.6663 - re_lu_65_loss: 249.1152 - re_lu_121_loss: 46.6083 - re_lu_177_loss: 26.3813 - re_lu_233_loss: 21.5615 - re_lu_65_accuracy: 0.1162 - re_lu_121_accuracy: 0.2030 - re_lu_177_accuracy: 0.4165 - re_lu_233_accuracy: 0.5328 - val_loss: 11734.1094 - val_re_lu_65_loss: 2728.8259 - val_re_lu_121_loss: 2902.3889 - val_re_lu_177_loss: 3037.8235 - val_re_lu_233_loss: 3065.0686 - val_re_lu_65_accuracy: 0.0941 - val_re_lu_121_accuracy: 0.1583 - val_re_lu_177_accuracy: 0.3723 - val_re_lu_233_accuracy: 0.3446\n",
      "Learning rate:  1e-05\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 343.0173 - re_lu_65_loss: 248.5688 - re_lu_121_loss: 46.5137 - re_lu_177_loss: 26.3799 - re_lu_233_loss: 21.5551 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.2040 - re_lu_177_accuracy: 0.4163 - re_lu_233_accuracy: 0.5347   ETA: 1:26 - loss: 344.3216 - re_lu_65_loss: 248.8022 - re_lu_121_loss: 46.7366 - re_lu_177_loss: 26.8476 - re_lu_233_loss: 21.9355 - re_lu_65_accuracy: 0.1163 - re_lu_121_accuracy: 0.2053 - re_lu_177_accuracy: 0.4187 - re_lu_233_ - ETA: 1: - ETA: 1:04 - loss: 341.5593 - re_lu_65_loss: 246.9610 - re_lu_121_loss: 46.3212 - re_lu_177_loss: 26.5488 - re_lu_233_loss: 21.7283 - re_lu_65_accuracy: 0.1166 - re_lu_121_accuracy: 0.2058 - re_lu_177_accuracy: - ETA: 1:01 - loss: 340.6393 - re_lu_65_loss: 246.4111 - re_lu_121_loss: 46.1173 - re_lu_177_loss: 26.4488 - re_lu_233_loss: 21.6622 - re_lu_65_accur - ETA: 5s - loss: 343.5378 - re_lu_65_loss: 248.8324 - re_lu_121_loss: 46.6701 - re_lu_177_loss: 26.4450 - re_lu_233_loss: 21.5905 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.20\n",
      "Epoch 00050: loss improved from 343.41165 to 343.01730, saving model to single_person_modelv5.h5\n",
      "1000/1000 [==============================] - 197s 197ms/step - loss: 343.0173 - re_lu_65_loss: 248.5688 - re_lu_121_loss: 46.5137 - re_lu_177_loss: 26.3799 - re_lu_233_loss: 21.5551 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.2040 - re_lu_177_accuracy: 0.4163 - re_lu_233_accuracy: 0.5347 - val_loss: 11727.3428 - val_re_lu_65_loss: 2728.4976 - val_re_lu_121_loss: 2900.8230 - val_re_lu_177_loss: 3035.5327 - val_re_lu_233_loss: 3062.4937 - val_re_lu_65_accuracy: 0.0931 - val_re_lu_121_accuracy: 0.1554 - val_re_lu_177_accuracy: 0.3601 - val_re_lu_233_accuracy: 0.3425\n",
      "Learning rate:  1e-05\n",
      "Epoch 51/100\n",
      " 138/1000 [===>..........................] - ETA: 2:33 - loss: 334.2052 - re_lu_65_loss: 240.7747 - re_lu_121_loss: 45.6668 - re_lu_177_loss: 26.3442 - re_lu_233_loss: 21.4195 - re_lu_65_accuracy: 0.1152 - re_lu_121_accuracy: 0.2007 - re_lu_177_accuracy: 0.4143 - re_lu_233_accuracy: 0.5320TA: 1:30 - loss: 312.2258 - re_lu_65_loss: 224.9483 - re_lu_121_loss: 41.9236 - re_lu_177_loss: 25.0110 - re_lu_233_loss: 20.3429 - re_lu_65_accuracy: 0.1192 - re_lu_121_accuracy: 0.2094 - re_lu_177_accuracy: 0.3837 -  - ETA: 2:44 - loss: 290.0652 - re_lu_65_loss: 200.0280 - re_lu_121_loss: 44.4064 - re_lu_177_loss: 24.8681 - re_lu_233_loss: 20.7627 - re_lu_65_accuracy: 0.1152 - re_lu_121_accuracy: 0.1946 - re_lu_177_accuracy: 0.4022 - re_lu_233_accuracy - ETA: 2:46 - loss: 298.4145 - re_lu_65_loss: 206.4412 - re_lu_121_loss: 46.9493 - re_lu_177_loss: 24.5295 - re_lu_233_loss: 20.4946 - re_lu_65_accuracy: 0.1161 - re_lu_121_accuracy: 0.1951 - - ETA: 2:46 - loss: 350.0734 - re_lu_65_loss: 253.2031 - re_lu_121_loss: 48.4324 - re_lu_177_loss: 26.5213 - re_lu_233_loss: 21.9165 - re_lu_65_accuracy: 0.1141 - re_lu_121_accuracy: 0.1943 - re_lu_177_accuracy: 0.4110 - re_lu_233_accura - ETA: 2:46 - loss: 342.3998 - re_lu_65_loss: 246.4957 - re_lu_121_loss: 47.5804 - re_lu_177_loss: 26.4571 - re_lu_233_loss: 21.8 - ETA: 2:37 - loss: 331.3062 - re_lu_65_loss: 237.2329 - re_lu_121_loss: 45.8598 - re_lu_177_loss: 26.6202 - re_lu_233_loss: 21.5932 - re_lu_65_accuracy: 0.1152 - re_lu_121_accuracy: 0.1994 - re_lu_177_accuracy: 0.4132 - re_lu_ - ETA: 2:35 - loss: 335.1855 - re_lu_65_loss: 241.0320 - re_lu_121_loss: 45.9612 - re_lu_177_loss: 26.5790 - re_lu_233_loss: 21.6132 - re_lu_65_accuracy: 0.1147 - re_lu_121_accuracy: 0.1994 - re_lu_177_accuracy: 0.4141 - re_lu_233_accuracy: 0. - ETA: 2:35 - loss: 336.5284 - re_lu_65_loss: 241.8260 - re_lu_121_loss: 46.3476 - re_lu_177_loss: 26.6802 - re_lu_233_loss: 21.6746 - re_lu_65_accuracy: 0.1146 - re_lu_121_accuracy: 0.1991 - re_lu_177_accuracy: 0.414"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e0b1df08d61f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=4, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lista_de_joints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-60eb95ed369b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlista_de_joints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lista_de_joints' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
