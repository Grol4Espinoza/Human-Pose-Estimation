{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!python\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from operator import itemgetter\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import (\n",
    "                                    Dense,\n",
    "                                    Conv2D, \n",
    "                                    BatchNormalization, \n",
    "                                    ReLU, \n",
    "                                    Add,\n",
    "                                    Input,\n",
    "                                    MaxPooling2D,\n",
    "                                    UpSampling2D,\n",
    "                                    )\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from math import exp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de Datos/Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_MIN_OF_IMGS_FOR_TRAINING = 0\n",
    "NUMBER_MAX_OF_IMGS_FOR_TRAINING = 11400\n",
    "########################################################################################################################################################\n",
    "def generate_dataset_obj(obj):\n",
    "    if type(obj) == np.ndarray:\n",
    "        dim = obj.shape[0]\n",
    "        if dim == 1:\n",
    "            ret = generate_dataset_obj(obj[0])             \n",
    "        else:\n",
    "            ret = []\n",
    "            for i in range(dim):\n",
    "                ret.append(generate_dataset_obj(obj[i]))                \n",
    "\n",
    "    elif type(obj) == scipy.io.matlab.mio5_params.mat_struct:\n",
    "        ret = {}\n",
    "        for field_name in obj._fieldnames:            \n",
    "            field = generate_dataset_obj(obj.__dict__[field_name])\n",
    "            if field_name in must_be_list_fields:\n",
    "                field = [field]\n",
    "                ret[field_name] = field\n",
    "\n",
    "    else:\n",
    "        ret = obj\n",
    "\n",
    "    return ret\n",
    "########################################################################################################################################################\n",
    "def generate_dataset_obj(obj):\n",
    "    if type(obj) == np.ndarray:\n",
    "        dim = obj.shape[0]\n",
    "        if dim == 1:\n",
    "            ret = generate_dataset_obj(obj[0])             \n",
    "        else:\n",
    "            ret = []\n",
    "            for i in range(dim):\n",
    "                ret.append(generate_dataset_obj(obj[i]))                \n",
    "\n",
    "    elif type(obj) == scipy.io.matlab.mio5_params.mat_struct:\n",
    "        ret = {}\n",
    "        for field_name in obj._fieldnames:            \n",
    "            field = generate_dataset_obj(obj.__dict__[field_name])\n",
    "            if field_name in must_be_list_fields:\n",
    "                field = [field]\n",
    "                ret[field_name] = field\n",
    "\n",
    "    else:\n",
    "        ret = obj\n",
    "\n",
    "    return ret\n",
    "\n",
    "########################################################################################################################################################\n",
    "def print_dataset_obj(obj, depth = 0, maxIterInArray = 20):\n",
    "    prefix = \"  \"*depth\n",
    "    if type(obj) == dict:\n",
    "        for key in obj.keys():\n",
    "            print(\"{}{}\".format(prefix, key))\n",
    "            print_dataset_obj(obj[key], depth + 1)\n",
    "    elif type(obj) == list:\n",
    "        for i, value in enumerate(obj):\n",
    "            if i >= maxIterInArray:\n",
    "                break\n",
    "            print(\"{}{}\".format(prefix, i))\n",
    "            print_dataset_obj(value, depth + 1)\n",
    "    else:\n",
    "        print(\"{}{}\".format(prefix, obj))\n",
    "########################################################################################################################################################\n",
    "def return_image_joints(name,data):\n",
    "    for item in data: # guardar coordenadas de los joints\n",
    "        if item[0] == name:\n",
    "            #print(item[1]) \n",
    "            return item[1]\n",
    "########################################################################################################################################################\n",
    "rightconnections = [\n",
    "                    (0,1),(1,2),(3,4),(4,5),(2,6),\n",
    "                    (3,6),(6,7),(7,8),(8,9),(10,11),\n",
    "                    (11,12),(12,7),(13,7),(13,14),(14,15)\n",
    "                   ]\n",
    "size_img_x = 256\n",
    "size_img_y = 256\n",
    "def draw_img_joints(file_name, data, resize = False ):    \n",
    "    # Load image\n",
    "    #img = cv2.imread(Path_To_Single_Person_Images + \"/\" + file_name,1)  \n",
    "    img = image.load_img(Path_To_Single_Person_Images + \"/\" + file_name)\n",
    "    img = image.img_to_array(img) \n",
    "    img = img/255\n",
    "    if resize:\n",
    "        img = np.float32(tf.image.resize(img,(size_img_x, size_img_y)))  \n",
    "    pts = return_image_joints(file_name, data)        \n",
    "    #plt.imshow(img)  \n",
    "    X = [x[0] for x in pts]\n",
    "    Y = [y[1] for y in pts]\n",
    "    X = [int(x) for x in X]\n",
    "    Y = [int(y) for y in Y]\n",
    "    \n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if (i,j) in rightconnections:\n",
    "                if X[i]>0 and X[j]>0 and Y[i]>0 and Y[j]>0:\n",
    "                    img = cv2.line(img,(X[i],Y[i]),(X[j],Y[j]),(1,0,0),5)\n",
    "                    plt.scatter(X[i], Y[i], marker=\"o\", color=\"red\", s=20)\n",
    "                    plt.scatter(X[j], Y[j], marker=\"o\", color=\"red\", s=20)\n",
    "                    \n",
    "    plt.imshow(img)\n",
    "########################################################################################################################################################\n",
    "def crop_resize(imagen, joints, scale, margin = 0.2):\n",
    "    # CROP PART\n",
    "    xmin = 9999\n",
    "    ymin = 9999\n",
    "    xmax = -1\n",
    "    ymax = -1\n",
    "    body_height_margin = scale * 200 * margin\n",
    "    img_height = imagen.shape[0]\n",
    "    img_width = imagen.shape[1]\n",
    "    for item in joints:\n",
    "        if item[0] >= 0 and item[0] < xmin : xmin = item[0]\n",
    "        if item[1] >= 0 and item[1] < ymin : ymin = item[1] \n",
    "        if item[0] >= 0 and item[0] > xmax : xmax = item[0]\n",
    "        if item[1] >= 0 and item[1] > ymax : ymax = item[1]    \n",
    "    xmin = int(xmin - body_height_margin)\n",
    "    ymin = int(ymin - body_height_margin)\n",
    "    xmax = int(xmax + body_height_margin)\n",
    "    ymax = int(ymax + body_height_margin)\n",
    "    if xmin < 0: xmin = 0\n",
    "    if ymin < 0: ymin = 0\n",
    "    if xmax > img_width: xmax = img_width\n",
    "    if ymax > img_height: ymax = img_height\n",
    "    imagen = imagen[ymin:ymax, xmin:xmax, :]\n",
    "    #print(\"xmin:\",xmin,\", ymin: \",ymin,\", xmax: \",xmax,\", ymax: \",ymax)\n",
    "    #RESIZE PART\n",
    "    img_new_height = imagen.shape[0]\n",
    "    img_new_width = imagen.shape[1]\n",
    "    scala_x = img_new_width / size_img_x\n",
    "    scala_y = img_new_height / size_img_y\n",
    "    for i in range(16): # escala los puntos clave\n",
    "        joints[i] = np.array([(joints[i][0] - xmin) / scala_x, (joints[i][1] - ymin) / scala_y]) \n",
    "        #print(\"x:\",joints[i][0],\", y: \",joints[i][1])\n",
    "    imagen = tf.image.resize(imagen,(size_img_x, size_img_y))       \n",
    "    imagen = imagen/255\n",
    "    \n",
    "    return imagen\n",
    "########################################################################################################################################################    \n",
    "def load_image(train_data, a, b):\n",
    "    train = np.asarray(train_data[a:b])\n",
    "    train_image = np.zeros((b-a,size_img_x,size_img_y,3))\n",
    "    #print(train[2])\n",
    "    for i in tqdm(range(a,b)):\n",
    "        name_img = train[i][0]\n",
    "        img = image.load_img(Path_To_Single_Person_Images + '/' + name_img)\n",
    "        img = image.img_to_array(img) \n",
    "        #crop and resize\n",
    "        train_image[i] = crop_resize(img, train[i][1], train[i][2])\n",
    "    return train_image, train\n",
    "########################################################################################################################################################\n",
    "def MakeHeatmap(x, y, width, height, show = False):\n",
    "    # Probability as a function of distance from the center derived\n",
    "    # from a gaussian distribution with mean = 0 and stdv = 1\n",
    "    scaledGaussian = lambda x : exp(-(1/2)*(x**2))\n",
    "\n",
    "    imgSize = (height, width)\n",
    "    center_x = int(round(x)) #redondeamos\n",
    "    center_y = int(round(y))\n",
    "\n",
    "    isotropicGrayscaleImage = np.zeros((imgSize[0],imgSize[1]),np.uint8)\n",
    "    \n",
    "    if center_x > 0 and center_y > 0 :\n",
    "        for i in np.unique(np.clip(np.array(range(center_y-3,center_y+4,1)),0,height-1)): #solo queremos calcular un parche de 7x7, ademas debemos evitar valores fuera de la matriz, finalmente quitamos valores repetidos\n",
    "            for j in np.unique(np.clip(np.array(range(center_x-3,center_x+4,1)),0,width-1)):\n",
    "\n",
    "                # find euclidian distance from center of image (x,y) \n",
    "                # and scale it to range of 0 to 2.5 as scaled Gaussian\n",
    "                # returns highest probability for x=0 and approximately\n",
    "                # zero probability for x > 2.5\n",
    "\n",
    "                distanceFromCenter = np.linalg.norm(np.array([i-center_y,j-center_x]))\n",
    "                #distanceFromCenter = 18*distanceFromCenter/(imgSize/2)\n",
    "                scaledGaussianProb = scaledGaussian(distanceFromCenter)                \n",
    "                isotropicGrayscaleImage[i,j] = np.clip(scaledGaussianProb*255,0,255) \n",
    "                \n",
    "        return isotropicGrayscaleImage\n",
    "    else: \n",
    "        return isotropicGrayscaleImage\n",
    "########################################################################################################################################################    \n",
    "def Joints_heatmaps(lista_de_joints, heatmap_size_x, heatmap_size_y, num_heatmaps = 16, show = False):\n",
    "    heatmaps = np.zeros((16,64,64))\n",
    "    for i in range(num_heatmaps):\n",
    "        x, y = lista_de_joints[i] \n",
    "        x = x / 4 # entre 4 por que el array es de 256x256\n",
    "        y = y / 4 # entre 4 por que el array es de 256x256\n",
    "        heatmaps[i] = MakeHeatmap(x, y, heatmap_size_x, heatmap_size_y)\n",
    "    if show:\n",
    "        plotImages(heatmaps, num_heatmaps)\n",
    "    return heatmaps\n",
    "########################################################################################################################################################        \n",
    "def plotImages(images_arr, num_images):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(60,60))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "########################################################################################################################################################    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos, Generación de heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divimos la data para ingresarla al modelo,\n",
    "if os.path.isfile('X_train.npy') and os.path.isfile('X_test.npy') and os.path.isfile('y_train.npy') and os.path.isfile('y_test.npy'):    \n",
    "    #Primero comprobamos si existen ya datos para usar en el modelo, si hay los mapeamos, no se cargan a la ram, se leen desde disco \n",
    "    X_train = np.load('X_train.npy', mmap_mode='r')\n",
    "    X_test = np.load('X_test.npy', mmap_mode='r')\n",
    "    y_train = np.load('y_train.npy', mmap_mode='r')\n",
    "    y_test = np.load('y_test.npy', mmap_mode='r')  \n",
    "else:      \n",
    "    # si no existen entonces iniciamos el preprocesado:   \n",
    "    ########################################################################################################################################################\n",
    "    if os.path.isfile('lista_de_imagenes.npy') and os.path.isfile('lista_de_heatmaps.npy'):    \n",
    "        #Ahora cargamos las imagenes y sus heatmaps\n",
    "        lista_de_heatmaps = np.load('lista_de_heatmaps.npy', mmap_mode='r')  \n",
    "        lista_de_imagenes = np.load('lista_de_imagenes.npy', mmap_mode='r')    \n",
    "    else: \n",
    "        ########################################################################################################################################################\n",
    "        #darle formato de diccionario\n",
    "        matph = './mpii.mat'\n",
    "        decoded1 = loadmat(matph, struct_as_record=False)[\"RELEASE\"]\n",
    "        must_be_list_fields = [\"annolist\",\"image\",\"name\", \"annorect\", \"scale\", \"x\", \"y\", \"annopoints\", \"point\", \"id\"]\n",
    "        # Convert to dict\n",
    "        dataset_obj = generate_dataset_obj(decoded1)\n",
    "        # Print it out\n",
    "        #print_dataset_obj(dataset_obj)\n",
    "        len(dataset_obj['annolist'][0])\n",
    "        #solo queremos la información en 'annolist'\n",
    "        dataset = dataset_obj['annolist'][0]\n",
    "        ########################################################################################################################################################\n",
    "        #guardamos solo informacion de las imagenes que tienen solo una persona\n",
    "        train_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            if \"annopoints\" in dataset[i]['annorect'][0]:     \n",
    "                name = dataset[i]['image'][0]['name'][0]\n",
    "                scale = dataset[i]['annorect'][0]['scale'][0]\n",
    "                tupla = np.full((16, 3), -1) #creo un prototipo de array de joints lleno de -1 si la articulación es visible se reemplaza el -1\n",
    "                for j in range(len(dataset[i]['annorect'][0]['annopoints'][0]['point'][0])):     #ordena los puntos de articulaciones del id = 0 al id = 15       \n",
    "                    try:\n",
    "                        x = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['x'][0]\n",
    "                    except:\n",
    "                        x = -1\n",
    "                    try:\n",
    "                        y = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['y'][0]\n",
    "                    except:\n",
    "                        y = -1\n",
    "                    try:\n",
    "                        joint_id = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['id'][0]\n",
    "                    except:\n",
    "                        joint_id = -1          \n",
    "                    tupla[joint_id] = np.array([x,y,joint_id]) # esto lo ordena\n",
    "                #tupla = sorted(tupla, key = itemgetter(2)) \n",
    "                #tupla = tupla[np.argsort(tupla[:, 2])] \n",
    "                tupla = np.delete(tupla, 2, 1)  #quita id de las tuplas,                    \n",
    "                #pasa de tupla a array\n",
    "                tupla = np.asarray(tupla)        \n",
    "                train_data.append((name,tupla,scale))\n",
    "        #Creamos un array para guardar los nombres        \n",
    "        names = []\n",
    "        for item in train_data:#guardar nombres de las imagenes que voy a usar en \"name\"\n",
    "            names.append(item[0])\n",
    "        ########################################################################################################################################################\n",
    "        #Crear Carpeta para guardar imagenes del dataset\n",
    "        Path_To_Raw_Images = 'DataSet/mpii_human_pose_v1_images'\n",
    "        Path_To_Single_Person_Images = 'DataSet/mpii_human_pose_v1_images/SinglePersonImagesWithData'\n",
    "        os.chdir(Path_To_Raw_Images)\n",
    "\n",
    "        if os.path.isdir('SinglePersonImagesWithData') is False:\n",
    "            os.makedirs('SinglePersonImagesWithData')\n",
    "            for images in names:\n",
    "                shutil.move(images, 'SinglePersonImagesWithData')\n",
    "\n",
    "        os.chdir('../../')\n",
    "\n",
    "        #Demostración dibujar joints en imagenes con data\n",
    "        #draw_img_joints('060111501.jpg',train_data)\n",
    "        ########################################################################################################################################################\n",
    "        #Ahora cargamos las imagenes\n",
    "        lista_de_imagenes, lista_de_joints = load_image(train_data,NUMBER_MIN_OF_IMGS_FOR_TRAINING,NUMBER_MAX_OF_IMGS_FOR_TRAINING)\n",
    "        np.save('lista_de_imagenes', lista_de_imagenes)\n",
    "        ########################################################################################################################################################\n",
    "        #Ahora creamos los heatmaps para lista_de_imagenes:\n",
    "        heatmap_size_x = 64\n",
    "        heatmap_size_y = 64 \n",
    "        #dibujo_test_heatmaps = Joints_heatmaps(lista_de_joints[0][1], heatmap_size_x, heatmap_size_y, show = False)\n",
    "        #creamos los heatmaps de nuestra data\n",
    "        lista_de_heatmaps = np.zeros((NUMBER_MAX_OF_IMGS_FOR_TRAINING - NUMBER_MIN_OF_IMGS_FOR_TRAINING,heatmap_size_x,heatmap_size_y,16))\n",
    "        for i in tqdm(range(lista_de_joints.shape[0])):\n",
    "            joints = return_image_joints(lista_de_joints[i][0], lista_de_joints)\n",
    "            lista_de_heatmaps[i] = np.moveaxis(Joints_heatmaps(joints, heatmap_size_x, heatmap_size_y), 0, -1) # change shape from 16x64x64 to 64x64x16\n",
    "        #guardamos el array    \n",
    "        np.save('lista_de_heatmaps', lista_de_heatmaps)\n",
    "        #liberamos memoria cargando los archivos desde disco\n",
    "        lista_de_heatmaps = np.load('lista_de_heatmaps.npy', mmap_mode='r')  \n",
    "        lista_de_imagenes = np.load('lista_de_imagenes.npy', mmap_mode='r') \n",
    "        #plotImages(lista_de_heatmaps[67], 16)\n",
    "    ######################################################################################################################################################## \n",
    "    X_train, X_test, y_train, y_test = train_test_split(lista_de_imagenes, lista_de_heatmaps, random_state=7, test_size=0.2)\n",
    "    #guardamos en disco y liberamos ram\n",
    "    np.save('X_train', X_train)\n",
    "    X_train = np.load('X_train.npy', mmap_mode='r')\n",
    "    np.save('X_test', X_test)\n",
    "    X_test = np.load('X_test.npy', mmap_mode='r')\n",
    "    np.save('y_train', y_train)\n",
    "    y_train = np.load('y_train.npy', mmap_mode='r')\n",
    "    np.save('y_test', y_test)\n",
    "    y_test = np.load('y_test.npy', mmap_mode='r')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###test part\\nimgidtest = 9\\nprint(\"image name: \",lista_de_joints[imgidtest][0])\\nprint(\"joints locations: \\n\",lista_de_joints[imgidtest][1])\\nprint(\"scale: \",lista_de_joints[imgidtest][2])\\nplt.imshow(lista_de_imagenes[imgidtest])\\nplotImages(np.moveaxis(lista_de_heatmaps[imgidtest], -1, 0),16)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"###test part\n",
    "imgidtest = 9\n",
    "print(\"image name: \",lista_de_joints[imgidtest][0])\n",
    "print(\"joints locations: \\n\",lista_de_joints[imgidtest][1])\n",
    "print(\"scale: \",lista_de_joints[imgidtest][2])\n",
    "plt.imshow(lista_de_imagenes[imgidtest])\n",
    "plotImages(np.moveaxis(lista_de_heatmaps[imgidtest], -1, 0),16)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(inputs, \n",
    "           filters, \n",
    "           kernel_size = 1,\n",
    "           strides = 1,\n",
    "           padding = 'same',\n",
    "           kernel_initializer = 'he_normal',\n",
    "           activation = True,\n",
    "           batch_normalization = True,\n",
    "           name = \"conv\"):\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,\n",
    "            use_bias=False, kernel_initializer=kernel_initializer)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = ReLU()(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquitectura ResNetV2 de cuello de botella\n",
    "def ResNetV2(inputs, filters, strides = 1, lift_channels = False, name = 'bloque'):\n",
    "    \n",
    "    res = inputs\n",
    "    #incrementa el número de canales si es necesario\n",
    "    if lift_channels:\n",
    "        res = conv2D(\n",
    "            inputs,\n",
    "            filters,\n",
    "            activation = False,\n",
    "            batch_normalization = False)\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    #conv de tamaño 1x1\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters/2)\n",
    "    \n",
    "    #conv de tamaño 3x3\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters/2,\n",
    "        kernel_size = 3)\n",
    "    \n",
    "    #conv de tamaño 1x1\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters,\n",
    "        activation = False,\n",
    "        batch_normalization = False)\n",
    "    \n",
    "    x = Add()([res,x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassUnit(inputs, depth, filters, resnet_per_block, name = 'hourglass_'):    \n",
    "    \n",
    "    #Capas \"superiores\"\n",
    "    up_1 = ResNetV2(inputs,filters)\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        up_1 = ResNetV2(up_1, filters)\n",
    "    \n",
    "    #Capas \"inferiores\"\n",
    "    #Reducir resolución\n",
    "    low_1 = MaxPooling2D(pool_size = 2, strides = 2)(inputs)\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        low_1 = ResNetV2(low_1, filters)\n",
    "        \n",
    "    if depth > 1 : \n",
    "        low_2 = HourglassUnit(low_1, depth-1, filters, resnet_per_block)\n",
    "    else:\n",
    "        low_2 = low_1\n",
    "        for i in range(resnet_per_block):\n",
    "            low_2 = ResNetV2(low_2, filters)\n",
    "    \n",
    "    low_3 = low_2\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        low_3 = ResNetV2(low_3, filters)\n",
    "    \n",
    "    #Aumentar resolución\n",
    "    up_2 = UpSampling2D()(low_3)\n",
    "    \n",
    "    return Add()([up_1,up_2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassNetwork(input_shape = (256,256,3), stacks = 8, resnet_per_block = 3, heatmaps = 16):\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    #la data llega en formato 256x256x3, la pasamos a 64x64x256\n",
    "    #preprocessing\n",
    "    #amplia canales a 64\n",
    "    x = conv2D(\n",
    "        inputs,\n",
    "        filters = 64,\n",
    "        kernel_size = 7,\n",
    "        strides = 2)\n",
    "    #amplia canales de 64 a 128 \n",
    "    x = ResNetV2(x, filters = 128, lift_channels = True)\n",
    "    x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "    x = ResNetV2(x, filters = 128)\n",
    "    #amplia canales de 64 a 128\n",
    "    x = ResNetV2(x, filters = 256, lift_channels = True)\n",
    "    skip = x\n",
    "    y_heatmaps = []\n",
    "    \n",
    "    for i in range(stacks):\n",
    "        #x = HourglassUnit(skip, depth = 4, filters = 256, resnet_per_block = resnet_per_block)\n",
    "        x = HourglassUnit(x, depth = 4, filters = 256, resnet_per_block = resnet_per_block)\n",
    "        \n",
    "        for i in range(resnet_per_block):\n",
    "            x = ResNetV2(x, filters = 256)\n",
    "            \n",
    "        #prediccion de 256 canales \n",
    "        x = conv2D(x, filters = 256, padding = 'valid')\n",
    "        \n",
    "        #prediccion temporal de heatmaps\n",
    "        y = conv2D(x, filters = heatmaps)\n",
    "        #agregamos el resultado temportal al array de resultados para la supervision intermedia\n",
    "        y_heatmaps.append(y)\n",
    "        \n",
    "        #ahora regresamos el tensor y al orden de 256 canales si es que no es el ultimo output\n",
    "        if i < stacks - 1:\n",
    "            y_recovery1 = conv2D(x, filters = 256, activation = False, batch_normalization = False)\n",
    "            y_recovery2 = conv2D(y, filters = 256, activation = False, batch_normalization = False)\n",
    "            #skip = Add()([skip, y_recovery1, y_recovery2])\n",
    "            x = Add()([skip, y_recovery1, y_recovery2])\n",
    "    return Model(inputs = inputs, outputs = y_heatmaps, name = 'HourglassNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# tasa de decrecimiento del learning rate por numero de epoch\n",
    "def lr_schedule(epoch): #tome esto de resnet.ipynb\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-5\n",
    "    if epoch > 80:\n",
    "        lr *= 1e-4\n",
    "    elif epoch > 70:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 50:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 30:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr \n",
    "############################################################################\n",
    "# custom loss mean_squared_error function, sirve para magnificar la presencia de todos los pixeles > que 0 en los mapas de calor\n",
    "def custom_loss_mse_function(y_true, y_pred):\n",
    "    weights = tf.cast(y_true > 0, dtype=tf.float32) * 81 + 1\n",
    "    return tf.reduce_mean(tf.math.square(y_true - y_pred) * weights)\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('single_person_modelv6_new_model_structure.h5'):\n",
    "    # verificamos si hay algun punto de guardado del modelo\n",
    "    model = load_model('single_person_modelv6_new_model_structure.h5', custom_objects={'custom_loss_mse_function': custom_loss_mse_function})\n",
    "else:    \n",
    "    # si no lo hay creamos el modelo desde cero\n",
    "    model = HourglassNetwork(stacks = 4, resnet_per_block = 1)\n",
    "    rms = RMSprop(lr=lr_schedule(0))\n",
    "    model.compile(optimizer=rms, loss=custom_loss_mse_function, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_reducer = ReduceLROnPlateau(monitor = 'val_re_lu_233_loss',\\n                               factor = 0.1,\\n                               patience = 10,\\n                               min_lr = 0,\\n                              verbose = 1)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creamos puntos de guardado del modelo para que guarde solo la mejor version durante el entrenamiento:\n",
    "checkpoint = ModelCheckpoint('single_person_modelv6_new_model_structure.h5', monitor='re_lu_233_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# modificaciones al learning rate per epoch:\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "# modificaciones al learning rate por estancamiento:\n",
    "\"\"\"lr_reducer = ReduceLROnPlateau(monitor = 'val_re_lu_233_loss',\n",
    "                               factor = 0.1,\n",
    "                               patience = 10,\n",
    "                               min_lr = 0,\n",
    "                              verbose = 1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "#os.remove(\"./logs/\")\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%d-%m-%Y - %H-%M-%S\")\n",
    "log_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregamos todas las funciones al callback_list\n",
    "callbacks_list = [checkpoint, lr_scheduler, log_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-05\n",
      "Epoch 1/100\n",
      "   1/2280 [..............................] - ETA: 0s - loss: 888.0883 - re_lu_65_loss: 669.9551 - re_lu_121_loss: 165.9361 - re_lu_177_loss: 37.9856 - re_lu_233_loss: 14.2115 - re_lu_65_accuracy: 0.1261 - re_lu_121_accuracy: 0.1390 - re_lu_177_accuracy: 0.3819 - re_lu_233_accuracy: 0.6185WARNING:tensorflow:From c:\\users\\espin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/2280 [..............................] - ETA: 45:03 - loss: 766.6201 - re_lu_65_loss: 583.9988 - re_lu_121_loss: 136.9779 - re_lu_177_loss: 32.4190 - re_lu_233_loss: 13.2245 - re_lu_65_accuracy: 0.1176 - re_lu_121_accuracy: 0.1678 - re_lu_177_accuracy: 0.3860 - re_lu_233_accuracy: 0.6068WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3884s vs `on_train_batch_end` time: 1.7350s). Check your callbacks.\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 752.5010 - re_lu_65_loss: 566.1956 - re_lu_121_loss: 134.3503 - re_lu_177_loss: 37.1304 - re_lu_233_loss: 14.8252 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy: 0.3779 - re_lu_233_accuracy: 0.6101  - ETA: 1:07 - loss: 749.6348 - re_lu_65_loss: 564.7643 - re_lu_121_loss: 133.2783 - re_lu_177_loss: 36.8594 - re_lu_233_loss: 14.7333 - re_lu_65_accuracy: 0.1290 - re_lu_121_acc - ETA: 57s - loss: 749.8417 - re_lu_65_loss: 565.1292 - re_lu_121_loss: 133.2621 - re_lu_177_loss: 36.7764 - re_lu_233_loss: 14.6742 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy: 0.3776 - re_lu_ - ETA: 56s - loss: 750.4593 - re_lu_65_loss: 565.4147 - re_lu_121_loss: 133.4748 - re_lu_177_loss: 36.8447 - re_lu_233_loss: 14.7252 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1772 - - ETA: 51s - loss: 750.3895 - re_lu_65_loss: 565.4580 - re_lu_121_loss: 133.4048 - re_lu_177_loss: 36.8332 - re_lu_233_loss: 14.6935 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy: 0.3777 -  - ETA: 48s - loss: 750.3578 - re_lu_65_loss: 565.5214 - re_lu_121_loss: 133.3528 - re_lu_177_loss: 36.8060 - re_lu_233_loss: 14.6773 - re_lu_65_accurac - ETA: 40s - loss: 750.5375 - re_lu_65_loss: 565.6293 - re_lu_121_loss: 133.4820 - re_lu_177_loss: 36.7976 - re_lu_233_loss: 14.6284 - re_lu_65_accuracy: 0.128 - ETA: 32s - loss: 750.8433 - re_lu_65_loss: 565.6687 - re_lu_121_loss: 133.6790 - re_lu_177_loss: 36.8451 - re_lu_233_loss: 14.6506 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy:  - ETA: 27s - loss: 751.5093 - re_lu_65_loss: 5 - ETA: 9s - loss: 752.6675 - re_lu_65_loss: 566.4973 - re_lu_121_loss: 134.3561 - re_lu_177_loss: 37.0648 - re_lu_233_loss: 14.7499 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1771 -\n",
      "Epoch 00001: re_lu_233_loss improved from inf to 14.82525, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 494s 216ms/step - loss: 752.5010 - re_lu_65_loss: 566.1956 - re_lu_121_loss: 134.3503 - re_lu_177_loss: 37.1304 - re_lu_233_loss: 14.8252 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy: 0.3779 - re_lu_233_accuracy: 0.6101 - val_loss: 11384.5820 - val_re_lu_65_loss: 2646.8123 - val_re_lu_121_loss: 2782.9272 - val_re_lu_177_loss: 2925.8425 - val_re_lu_233_loss: 3028.9968 - val_re_lu_65_accuracy: 0.1153 - val_re_lu_121_accuracy: 0.1465 - val_re_lu_177_accuracy: 0.3213 - val_re_lu_233_accuracy: 0.5876\n",
      "Learning rate:  1e-05\n",
      "Epoch 2/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 749.0789 - re_lu_65_loss: 564.9267 - re_lu_121_loss: 133.3263 - re_lu_177_loss: 36.4563 - re_lu_233_loss: 14.3695 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy: 0.3796 - re_lu_233_accuracy: 0.6126  - ETA: 6:16 - loss: 786.1725 - re_lu_65_loss: 576.3331 - re_lu_121_loss: 146.8367 - re_lu_177_loss: 43.9061 - re_lu_233_loss: 19.0968 - re_lu_65 - ETA: 19s - loss: 745.7161 - re_lu_65_loss: 563.3150 - re_lu_121_loss: 132.2960 - re_lu_177_loss: 35.9825 - re_lu_233 - ETA: 6s - loss: 748.2173 - re_lu_65_loss: 564.6414 - re_lu_121_loss: 133.0220 - re_lu_177_loss: 36.3019 - re_lu_233_loss: 14.2520 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy\n",
      "Epoch 00002: re_lu_233_loss improved from 14.82525 to 14.36955, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 425s 187ms/step - loss: 749.0789 - re_lu_65_loss: 564.9267 - re_lu_121_loss: 133.3263 - re_lu_177_loss: 36.4563 - re_lu_233_loss: 14.3695 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1772 - re_lu_177_accuracy: 0.3796 - re_lu_233_accuracy: 0.6126 - val_loss: 11400.4082 - val_re_lu_65_loss: 2653.0374 - val_re_lu_121_loss: 2785.0510 - val_re_lu_177_loss: 2930.2727 - val_re_lu_233_loss: 3032.0432 - val_re_lu_65_accuracy: 0.1168 - val_re_lu_121_accuracy: 0.1474 - val_re_lu_177_accuracy: 0.3170 - val_re_lu_233_accuracy: 0.5791\n",
      "Learning rate:  1e-05\n",
      "Epoch 3/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 746.9184 - re_lu_65_loss: 564.0202 - re_lu_121_loss: 132.3540 - re_lu_177_loss: 36.3247 - re_lu_233_loss: 14.2214 - re_lu_65_accuracy: 0.1281 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.3804 - re_lu_233_accuracy: 0.6145  - ETA: 1:56 - loss: 746.9308 - re_lu_65_loss: 563.4979 - re_lu_121_loss: 132.3951 - re_lu_177_loss: 36.5973 - re_lu_233_loss: 14.4421 - re_lu_65_accuracy: 0.1279 - re_lu_121_accu - ETA: 1:44 - loss: 748.2023 - re_lu_65_loss: 564.7025 - re_lu_121_loss: 132.7570 - re_lu_177_loss: 36.4494 - re_lu_233_loss: 14.2946 - re_lu_65_accuracy: 0.1278 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.3801 - re_lu - ETA: 1:40 - loss: 747.0859 - re_lu_65_loss: 564.1553 - re_lu_121_loss: 132.4277 - re_lu_177_loss: 36.2781 - re_lu_233_loss: 14.2263 - re_lu_65 - ETA: 3s - loss: 746.5085 - re_lu_65_loss: 563.7211 - re_lu_121_loss: 132.2541 - re_lu_177_loss: 36.3174 - re_lu_233_loss: 14.2178 - re_lu_65_accuracy: 0.1281 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.3804 - re_\n",
      "Epoch 00003: re_lu_233_loss improved from 14.36955 to 14.22139, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 427s 187ms/step - loss: 746.9184 - re_lu_65_loss: 564.0202 - re_lu_121_loss: 132.3540 - re_lu_177_loss: 36.3247 - re_lu_233_loss: 14.2214 - re_lu_65_accuracy: 0.1281 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.3804 - re_lu_233_accuracy: 0.6145 - val_loss: 11398.9873 - val_re_lu_65_loss: 2649.9968 - val_re_lu_121_loss: 2785.2422 - val_re_lu_177_loss: 2929.6238 - val_re_lu_233_loss: 3034.1187 - val_re_lu_65_accuracy: 0.1164 - val_re_lu_121_accuracy: 0.1485 - val_re_lu_177_accuracy: 0.3196 - val_re_lu_233_accuracy: 0.5785\n",
      "Learning rate:  1e-05\n",
      "Epoch 4/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 745.4795 - re_lu_65_loss: 562.6309 - re_lu_121_loss: 132.1182 - re_lu_177_loss: 36.3078 - re_lu_233_loss: 14.4225 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3817 - re_lu_233_accuracy: 0.6144\n",
      "Epoch 00004: re_lu_233_loss did not improve from 14.22139\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 745.4795 - re_lu_65_loss: 562.6309 - re_lu_121_loss: 132.1182 - re_lu_177_loss: 36.3078 - re_lu_233_loss: 14.4225 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3817 - re_lu_233_accuracy: 0.6144 - val_loss: 11390.6592 - val_re_lu_65_loss: 2650.5957 - val_re_lu_121_loss: 2781.8884 - val_re_lu_177_loss: 2926.6326 - val_re_lu_233_loss: 3031.5444 - val_re_lu_65_accuracy: 0.1155 - val_re_lu_121_accuracy: 0.1436 - val_re_lu_177_accuracy: 0.3159 - val_re_lu_233_accuracy: 0.5817\n",
      "Learning rate:  1e-05\n",
      "Epoch 5/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 741.3580 - re_lu_65_loss: 560.5724 - re_lu_121_loss: 131.1549 - re_lu_177_loss: 35.5931 - re_lu_233_loss: 14.0373 - re_lu_65_accuracy: 0.1281 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.3822 - re_lu_233_accuracy: 0.6155- ETA: 4s - loss: 742.0048 - re_lu_65_loss: 561.0754 - re_lu_121_loss: 131.2595 - re_lu_177_loss: 35.6209 - re_lu_233_loss: 14.0489 - re_lu_65_accuracy: 0.1282 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.3822 -\n",
      "Epoch 00005: re_lu_233_loss improved from 14.22139 to 14.03734, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 426s 187ms/step - loss: 741.3580 - re_lu_65_loss: 560.5724 - re_lu_121_loss: 131.1549 - re_lu_177_loss: 35.5931 - re_lu_233_loss: 14.0373 - re_lu_65_accuracy: 0.1281 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.3822 - re_lu_233_accuracy: 0.6155 - val_loss: 11397.7656 - val_re_lu_65_loss: 2647.6443 - val_re_lu_121_loss: 2786.2759 - val_re_lu_177_loss: 2929.4829 - val_re_lu_233_loss: 3034.3606 - val_re_lu_65_accuracy: 0.1151 - val_re_lu_121_accuracy: 0.1401 - val_re_lu_177_accuracy: 0.3221 - val_re_lu_233_accuracy: 0.5940\n",
      "Learning rate:  1e-05\n",
      "Epoch 6/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 742.2481 - re_lu_65_loss: 561.2850 - re_lu_121_loss: 130.9153 - re_lu_177_loss: 35.7565 - re_lu_233_loss: 14.2909 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1761 - re_lu_177_accuracy: 0.3830 - re_lu_233_accuracy: 0.6195  - ETA: 4:56 - loss: 746.6849 - re_lu_65_loss: 563.5807 - re_lu_121_loss: 132.0629 - re_lu_177_loss: 36.5170 - re_lu_233_loss: 14.5242 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1747 - re_lu_177_ac - ETA: 4:49 - loss: 747.6222 - re_lu_65_loss: 564.7606 - re_lu_121_loss: 131.9098 - re_lu_177_loss: 36.5004 - re_lu_233_loss: 14.4517 - re_lu_65_accuracy: 0.1286 - re_lu_121_accuracy: 0.1 - ETA: 4:38 - loss: 743.0238 - re_lu_65_loss: 561. - ETA: 3:22 - loss: 736.0225 \n",
      "Epoch 00006: re_lu_233_loss did not improve from 14.03734\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 742.2481 - re_lu_65_loss: 561.2850 - re_lu_121_loss: 130.9153 - re_lu_177_loss: 35.7565 - re_lu_233_loss: 14.2909 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1761 - re_lu_177_accuracy: 0.3830 - re_lu_233_accuracy: 0.6195 - val_loss: 11403.1484 - val_re_lu_65_loss: 2651.2942 - val_re_lu_121_loss: 2787.4392 - val_re_lu_177_loss: 2930.9497 - val_re_lu_233_loss: 3033.4690 - val_re_lu_65_accuracy: 0.1148 - val_re_lu_121_accuracy: 0.1426 - val_re_lu_177_accuracy: 0.3208 - val_re_lu_233_accuracy: 0.5893\n",
      "Learning rate:  1e-05\n",
      "Epoch 7/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 737.9612 - re_lu_65_loss: 558.7630 - re_lu_121_loss: 130.0543 - re_lu_177_loss: 35.2871 - re_lu_233_loss: 13.8567 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3852 - re_lu_233_accuracy: 0.6188  - ETA: 1:51 - loss: 734.8488 - re_lu_65_loss: 556.4216 - re_lu_121_loss: 129.1054 - re_lu_177_loss: 35.2412 - re_lu_233_loss: 14.0796 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3850 - re_lu_233_accuracy: 0.617 - ETA: 1:51 - loss: 734.7850 - re_lu_65_loss: 556.3716 - re_lu_121_loss: 129.1034 - re_lu_177_loss: 35.2351 - re_l - ETA: 31s - loss: 737.6370 - re_lu_65_loss: 558.3183 - re_lu_121_loss: 130.0379 - re_lu_177_loss: 35.3051 - re_lu_233_loss: 13.9751 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0. - ETA\n",
      "Epoch 00007: re_lu_233_loss improved from 14.03734 to 13.85668, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 427s 187ms/step - loss: 737.9612 - re_lu_65_loss: 558.7630 - re_lu_121_loss: 130.0543 - re_lu_177_loss: 35.2871 - re_lu_233_loss: 13.8567 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3852 - re_lu_233_accuracy: 0.6188 - val_loss: 11405.6455 - val_re_lu_65_loss: 2651.9885 - val_re_lu_121_loss: 2788.7212 - val_re_lu_177_loss: 2930.1025 - val_re_lu_233_loss: 3034.8416 - val_re_lu_65_accuracy: 0.1169 - val_re_lu_121_accuracy: 0.1454 - val_re_lu_177_accuracy: 0.3231 - val_re_lu_233_accuracy: 0.5923\n",
      "Learning rate:  1e-05\n",
      "Epoch 8/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 737.9456 - re_lu_65_loss: 558.3380 - re_lu_121_loss: 129.9056 - re_lu_177_loss: 35.4108 - re_lu_233_loss: 14.2916 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1761 - re_lu_177_accuracy: 0.3854 - re_lu_233_accuracy: 0.6226  - ETA: 1:55 - loss: 738.9863 - re_\n",
      "Epoch 00008: re_lu_233_loss did not improve from 13.85668\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 737.9456 - re_lu_65_loss: 558.3380 - re_lu_121_loss: 129.9056 - re_lu_177_loss: 35.4108 - re_lu_233_loss: 14.2916 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1761 - re_lu_177_accuracy: 0.3854 - re_lu_233_accuracy: 0.6226 - val_loss: 11406.1230 - val_re_lu_65_loss: 2651.5032 - val_re_lu_121_loss: 2788.4077 - val_re_lu_177_loss: 2931.6624 - val_re_lu_233_loss: 3034.5476 - val_re_lu_65_accuracy: 0.1169 - val_re_lu_121_accuracy: 0.1463 - val_re_lu_177_accuracy: 0.3197 - val_re_lu_233_accuracy: 0.5949\n",
      "Learning rate:  1e-05\n",
      "Epoch 9/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 735.4668 - re_lu_65_loss: 557.0986 - re_lu_121_loss: 128.8528 - re_lu_177_loss: 35.2969 - re_lu_233_loss: 14.2177 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1770 - re_lu_177_accuracy: 0.3878 - re_lu_233_accuracy: 0.6230\n",
      "Epoch 00009: re_lu_233_loss did not improve from 13.85668\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 735.4668 - re_lu_65_loss: 557.0986 - re_lu_121_loss: 128.8528 - re_lu_177_loss: 35.2969 - re_lu_233_loss: 14.2177 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1770 - re_lu_177_accuracy: 0.3878 - re_lu_233_accuracy: 0.6230 - val_loss: 11409.3652 - val_re_lu_65_loss: 2652.2947 - val_re_lu_121_loss: 2788.9788 - val_re_lu_177_loss: 2931.8533 - val_re_lu_233_loss: 3036.2383 - val_re_lu_65_accuracy: 0.1160 - val_re_lu_121_accuracy: 0.1431 - val_re_lu_177_accuracy: 0.3252 - val_re_lu_233_accuracy: 0.6021\n",
      "Learning rate:  1e-05\n",
      "Epoch 10/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 734.0804 - re_lu_65_loss: 556.7756 - re_lu_121_loss: 128.4034 - re_lu_177_loss: 34.9956 - re_lu_233_loss: 13.9055 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3886 - re_lu_233_accuracy: 0.6260  ETA:\n",
      "Epoch 00010: re_lu_233_loss did not improve from 13.85668\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 734.0804 - re_lu_65_loss: 556.7756 - re_lu_121_loss: 128.4034 - re_lu_177_loss: 34.9956 - re_lu_233_loss: 13.9055 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.3886 - re_lu_233_accuracy: 0.6260 - val_loss: 11415.8643 - val_re_lu_65_loss: 2655.3184 - val_re_lu_121_loss: 2791.1692 - val_re_lu_177_loss: 2933.1929 - val_re_lu_233_loss: 3036.1726 - val_re_lu_65_accuracy: 0.1166 - val_re_lu_121_accuracy: 0.1470 - val_re_lu_177_accuracy: 0.3204 - val_re_lu_233_accuracy: 0.5953\n",
      "Learning rate:  1e-05\n",
      "Epoch 11/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 730.8479 - re_lu_65_loss: 554.9488 - re_lu_121_loss: 127.4840 - re_lu_177_loss: 34.7257 - re_lu_233_loss: 13.6899 - re_lu_65_accuracy: 0.1287 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.3887 - re_lu_233_accuracy: 0.6259  ETA: 38s - loss: 732.7952 - re_lu_65_loss: 556.1935 - re_lu_121_loss: 128.2911 - re_lu_177_loss: 34.6757 - re\n",
      "Epoch 00011: re_lu_233_loss improved from 13.85668 to 13.68991, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 430s 189ms/step - loss: 730.8479 - re_lu_65_loss: 554.9488 - re_lu_121_loss: 127.4840 - re_lu_177_loss: 34.7257 - re_lu_233_loss: 13.6899 - re_lu_65_accuracy: 0.1287 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.3887 - re_lu_233_accuracy: 0.6259 - val_loss: 11412.6455 - val_re_lu_65_loss: 2652.5383 - val_re_lu_121_loss: 2789.7039 - val_re_lu_177_loss: 2934.0049 - val_re_lu_233_loss: 3036.4019 - val_re_lu_65_accuracy: 0.1174 - val_re_lu_121_accuracy: 0.1483 - val_re_lu_177_accuracy: 0.3243 - val_re_lu_233_accuracy: 0.5907\n",
      "Learning rate:  1e-05\n",
      "Epoch 12/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 729.9998 - re_lu_65_loss: 554.7899 - re_lu_121_loss: 127.1293 - re_lu_177_loss: 34.5468 - re_lu_233_loss: 13.5340 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1786 - re_lu_177_accuracy: 0.3898 - re_lu_233_accuracy: 0.6259\n",
      "Epoch 00012: re_lu_233_loss improved from 13.68991 to 13.53401, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 427s 187ms/step - loss: 729.9998 - re_lu_65_loss: 554.7899 - re_lu_121_loss: 127.1293 - re_lu_177_loss: 34.5468 - re_lu_233_loss: 13.5340 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1786 - re_lu_177_accuracy: 0.3898 - re_lu_233_accuracy: 0.6259 - val_loss: 11424.9531 - val_re_lu_65_loss: 2655.5498 - val_re_lu_121_loss: 2794.3696 - val_re_lu_177_loss: 2935.8076 - val_re_lu_233_loss: 3039.2393 - val_re_lu_65_accuracy: 0.1187 - val_re_lu_121_accuracy: 0.1464 - val_re_lu_177_accuracy: 0.3309 - val_re_lu_233_accuracy: 0.5963\n",
      "Learning rate:  1e-05\n",
      "Epoch 13/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 726.8931 - re_lu_65_loss: 552.3088 - re_lu_121_loss: 126.4965 - re_lu_177_loss: 34.4500 - re_lu_233_loss: 13.6395 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1769 - re_lu_177_accuracy: 0.3922 - re_lu_233_accuracy: 0.6255\n",
      "Epoch 00013: re_lu_233_loss did not improve from 13.53401\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 726.8931 - re_lu_65_loss: 552.3088 - re_lu_121_loss: 126.4965 - re_lu_177_loss: 34.4500 - re_lu_233_loss: 13.6395 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1769 - re_lu_177_accuracy: 0.3922 - re_lu_233_accuracy: 0.6255 - val_loss: 11420.7900 - val_re_lu_65_loss: 2655.2764 - val_re_lu_121_loss: 2793.1709 - val_re_lu_177_loss: 2934.9475 - val_re_lu_233_loss: 3037.3989 - val_re_lu_65_accuracy: 0.1165 - val_re_lu_121_accuracy: 0.1419 - val_re_lu_177_accuracy: 0.3328 - val_re_lu_233_accuracy: 0.6049\n",
      "Learning rate:  1e-05\n",
      "Epoch 14/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 725.2177 - re_lu_65_loss: 552.6616 - re_lu_121_loss: 125.4853 - re_lu_177_loss: 33.9302 - re_lu_233_loss: 13.1400 - re_lu_65_accuracy: 0.1286 - re_lu_121_accuracy: 0.1771 - re_lu_177_accuracy: 0.3935 - re_lu_233_accuracy: 0.6271- ETA: 9s - loss: 725.1289 - re_lu_65_loss: 552.6793 - re_lu_121_loss: 125.3750 - re_lu_177_loss: 33.9614 - re_lu_233_loss: 13.1124 - re_lu_65_accuracy: 0.1286 - re_lu_121_accuracy: 0.1769 - re_lu_177_accuracy: 0.3936 - re_lu - ETA: 5s - loss: 724.9949 - re_lu_65_loss: 552.6180 - re_lu_121_loss: 125.4004 - re_lu_177_loss: 33.8920 - re_lu_233_loss: 13.0837 - re_lu_65_accuracy: 0.1286 - re_lu_121_accuracy: 0.1770 - re_lu_177_accuracy: 0.3934 - re_lu_233_ - ETA: 2s - loss: 725.4615 - re_lu_65_loss: 552.8226 - re_lu_121_loss: 125.5630 - re_lu_177_loss: 33.9532 - re_lu_233_loss: 13.1221 - re_lu_65_accuracy: 0.1286 - re_lu_121_accuracy: 0.1770 - re_lu_177_accuracy: 0.3935 - re_lu_233\n",
      "Epoch 00014: re_lu_233_loss improved from 13.53401 to 13.14000, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 427s 187ms/step - loss: 725.2177 - re_lu_65_loss: 552.6616 - re_lu_121_loss: 125.4853 - re_lu_177_loss: 33.9302 - re_lu_233_loss: 13.1400 - re_lu_65_accuracy: 0.1286 - re_lu_121_accuracy: 0.1771 - re_lu_177_accuracy: 0.3935 - re_lu_233_accuracy: 0.6271 - val_loss: 11430.5273 - val_re_lu_65_loss: 2655.4155 - val_re_lu_121_loss: 2795.5322 - val_re_lu_177_loss: 2938.0791 - val_re_lu_233_loss: 3041.4893 - val_re_lu_65_accuracy: 0.1170 - val_re_lu_121_accuracy: 0.1493 - val_re_lu_177_accuracy: 0.3296 - val_re_lu_233_accuracy: 0.5888\n",
      "Learning rate:  1e-05\n",
      "Epoch 15/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 724.7381 - re_lu_65_loss: 551.7676 - re_lu_121_loss: 125.2328 - re_lu_177_loss: 34.1163 - re_lu_233_loss: 13.6218 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1776 - re_lu_177_accuracy: 0.3934 - re_lu_233_accuracy: 0.6277  - ETA: 3:36 - loss: 730.1190 - re_lu_65_loss: 554.2458 - re_lu_121_loss: 126.8817 - re_lu_177_loss: 35.0490 - re_lu - ETA: 3:13 - loss: 731.4787 - re_lu_65_loss: 555.7282 - ETA: 2:40 - loss: 732.5999 - re_lu_65_loss: 556.3029 - re_lu_121_loss: 127.2545 - re_lu_177_loss: 35.0782 - re_lu_233_loss: 13.9646 - re_lu_65_accuracy: 0.1287 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.3929 - re_l - ETA: 2:36 - loss: 733.8487 - re_lu_65_loss: 557.0551 - re_lu_121_loss: 127.5553  - ETA: 6s - loss: 725.7200 - re_lu_65_loss: 552.2093 - re_lu_121_loss: 125.5946 - re_lu_177_loss: 34.2482 - re_lu_233_loss: 13.6685 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1777 - re_lu_177_accuracy: \n",
      "Epoch 00015: re_lu_233_loss did not improve from 13.14000\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 724.7381 - re_lu_65_loss: 551.7676 - re_lu_121_loss: 125.2328 - re_lu_177_loss: 34.1163 - re_lu_233_loss: 13.6218 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1776 - re_lu_177_accuracy: 0.3934 - re_lu_233_accuracy: 0.6277 - val_loss: 11426.2627 - val_re_lu_65_loss: 2655.0366 - val_re_lu_121_loss: 2795.4187 - val_re_lu_177_loss: 2936.0583 - val_re_lu_233_loss: 3039.7529 - val_re_lu_65_accuracy: 0.1159 - val_re_lu_121_accuracy: 0.1423 - val_re_lu_177_accuracy: 0.3294 - val_re_lu_233_accuracy: 0.6053\n",
      "Learning rate:  1e-05\n",
      "Epoch 16/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 721.6390 - re_lu_65_loss: 550.7466 - re_lu_121_loss: 124.3192 - re_lu_177_loss: 33.5501 - re_lu_233_loss: 13.0227 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.3957 - re_lu_233_accuracy: 0.6303  - ETA: 4:42 - loss: 716.2431 - re_lu_65_loss: 549.1699 - re_lu\n",
      "Epoch 00016: re_lu_233_loss improved from 13.14000 to 13.02268, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 428s 188ms/step - loss: 721.6390 - re_lu_65_loss: 550.7466 - re_lu_121_loss: 124.3192 - re_lu_177_loss: 33.5501 - re_lu_233_loss: 13.0227 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.3957 - re_lu_233_accuracy: 0.6303 - val_loss: 11433.3770 - val_re_lu_65_loss: 2656.5505 - val_re_lu_121_loss: 2797.0676 - val_re_lu_177_loss: 2938.0093 - val_re_lu_233_loss: 3041.7549 - val_re_lu_65_accuracy: 0.1161 - val_re_lu_121_accuracy: 0.1442 - val_re_lu_177_accuracy: 0.3323 - val_re_lu_233_accuracy: 0.6136\n",
      "Learning rate:  1e-05\n",
      "Epoch 17/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 720.4781 - re_lu_65_loss: 549.6359 - re_lu_121_loss: 123.9414 - re_lu_177_loss: 33.5882 - re_lu_233_loss: 13.3126 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1774 - re_lu_177_accuracy: 0.3970 - re_lu_233_accuracy: 0.6314  - ETA: 3:52 - loss: 727.9622 - re_lu_65_loss: 555.6255 - re_lu_121_loss: 125.0779 - re_lu_177_loss: 33.8510 - ETA: 3:28 - loss: 726.8719 - re_lu_65_loss: 555.1577 - re_lu_121_loss: 125.0268 - re_lu_177_loss: 33.519 - ETA: 3:04 - loss: 724.7243 - re_l - ETA: 2:27 - loss: 722.5523 - re_lu_65_loss: 551.6356 - re_lu_121_loss: 124.2966 - re_lu_177_loss: 33.4147 - re_lu_233_loss: 13.2053 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1767 - re_lu_177_accuracy: 0.39 - ETA: 2:22 - loss: 722.0177 - re_lu_65_loss: 551.0560 - re_lu_121_loss:  - ETA: 1:51 - loss: 720.2581 - - ETA: 1:14 - loss: 719.1835 - re_lu_65_ - ETA: 49s - loss:  - ETA: 6s - loss: 720.9263 - re_lu_65_loss: 549.9757 - re_lu_121_loss: 124.0241 - re_lu_177_loss: 33.5938 - re_lu_233_loss: 13.3328 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1773 - re_lu_177_accurac\n",
      "Epoch 00017: re_lu_233_loss did not improve from 13.02268\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 720.4781 - re_lu_65_loss: 549.6359 - re_lu_121_loss: 123.9414 - re_lu_177_loss: 33.5882 - re_lu_233_loss: 13.3126 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1774 - re_lu_177_accuracy: 0.3970 - re_lu_233_accuracy: 0.6314 - val_loss: 11428.2754 - val_re_lu_65_loss: 2656.8354 - val_re_lu_121_loss: 2795.0376 - val_re_lu_177_loss: 2936.6196 - val_re_lu_233_loss: 3039.7830 - val_re_lu_65_accuracy: 0.1171 - val_re_lu_121_accuracy: 0.1464 - val_re_lu_177_accuracy: 0.3365 - val_re_lu_233_accuracy: 0.5999\n",
      "Learning rate:  1e-05\n",
      "Epoch 18/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 717.8209 - re_lu_65_loss: 548.0057 - re_lu_121_loss: 123.0472 - re_lu_177_loss: 33.4309 - re_lu_233_loss: 13.3367 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.3973 - re_lu_233_accuracy: 0.6332  - ETA: 3:05 - loss: 717.0828 - re_lu_65_loss: 547.2952 - re_lu_121_los - ETA: 21s - loss: 718.0319 - re_lu_65_loss: 548.2247 - r\n",
      "Epoch 00018: re_lu_233_loss did not improve from 13.02268\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 717.8209 - re_lu_65_loss: 548.0057 - re_lu_121_loss: 123.0472 - re_lu_177_loss: 33.4309 - re_lu_233_loss: 13.3367 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.3973 - re_lu_233_accuracy: 0.6332 - val_loss: 11438.0049 - val_re_lu_65_loss: 2658.7532 - val_re_lu_121_loss: 2798.3687 - val_re_lu_177_loss: 2939.0444 - val_re_lu_233_loss: 3041.8403 - val_re_lu_65_accuracy: 0.1151 - val_re_lu_121_accuracy: 0.1420 - val_re_lu_177_accuracy: 0.3342 - val_re_lu_233_accuracy: 0.6098\n",
      "Learning rate:  1e-05\n",
      "Epoch 19/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 717.7689 - re_lu_65_loss: 547.8310 - re_lu_121_loss: 122.9987 - re_lu_177_loss: 33.5440 - re_lu_233_loss: 13.3953 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1769 - re_lu_177_accuracy: 0.3996 - re_lu_233_accuracy: 0.6353  - ETA: 5:43 - loss: 726.6785 - re_lu_65_loss: 551.1306 - re_lu_121_loss: 125.7470 - re_lu_177_loss: 35.2741 - re_lu_233_loss: 14.5265 - re_lu_65_accuracy: 0.1277 - re_lu_121_accuracy: 0.1769 - re_lu_17 - ETA: 5:35 - loss: 732.2303 - re_lu_65_loss: 554.6872 - re_lu_121_loss: 126.2724 - re_lu_177_loss: 36.2063 - re_lu_233_loss: 15.0639 - re_lu_65_accuracy: 0.1280 - re_lu_121_accuracy: 0.1767 - re_lu_177_accuracy: 0.3973 - re_lu_233_accuracy: 0.630 - ETA: 5:35 - loss: 732.1382 - re_lu_65_loss: 554.6065 - re_lu_121_loss: 126.3070 - re_lu_177_loss: 36.1847 - re_lu_233_loss: 15.0395 - re_lu_65_accuracy: 0.1280 - re_lu_12 - ETA: 5:22 - loss: 723.5919 - re_lu_65_loss: 550.1576 - re_lu_121_loss: 124.1569 - re_lu_177_loss: 34.9116 - re_lu_233_loss: 14.3652 - re_lu_65_accuracy: 0.1283 - re_lu_121_accuracy: 0.1770 - re_ - ETA: 5:13 - loss: 722.1313 - re_lu_65_loss: 549.3350 - re_lu_121_loss: 123.8456 - re_lu_177_loss: 34.6102 - re_lu_233 - ETA: 4:51 - loss: 710.3046 - re_lu_65_loss: 542.7794 - re_lu_121_loss: 121.0029 - re_lu_177_loss: 33.2166 - re_lu_233_loss: 13.3050 - re_lu_65_accuracy: 0.1283 - re_lu_121_accuracy: 0.1763 -  - ETA: 4:41 - loss: 707.0888 - re_lu_65_loss: 541.0819 - re_lu_121_loss: 120.0800 - re_lu_177_loss: 32.8671 - re_lu_233_loss: 13.0589 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1766 - re_lu_177_accuracy: 0.3972 - re_lu_233_accuracy: 0.630 - ETA: 4:41 - loss: 707.1112 - re_lu_65_loss: 541.1044 - re_lu_121_loss: 120.1035 - re_lu_177_loss: 32.8553 - re_lu_233_loss: 13.0472 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1765 - re_lu_177_accura - ETA: 4:34 - loss: 706.4288 - re_lu_65_loss: 540.6089 - re_lu_121_loss: 119.7756 - re_lu_177_loss: 32.8890 - re_lu_233_loss: 13.1545 - re_lu_65_accuracy: 0.1288 -  - ETA: 4:20 - loss: 706.6312 - re_lu_65_loss: 540.4498 - re_lu_121_loss: 120.2754 - re_lu_177_loss: 32.8394 - re_lu_233_loss: 13.0661 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0. - ETA: 4:09 - loss: 705.8527 - re_lu_65_loss: 539.7112 - re_lu_121_loss: 119 - ETA: 3:40 - loss: 707.7685 - re_lu_65_lo - ETA: 3:04 - loss: 706.9828 - re_lu_65_loss: 540.2903 - re_lu_121_loss: 120.2635 - re_lu_177_loss: 33.0803 - re_lu_233_loss: 13.3485 -  - ETA: 0s - loss: 718.1190 - re_lu_65_loss: 548.0979 - re_lu_121_loss: 123.0690 - re_lu_177_loss: 33.5577 - re_lu_233_loss: 13.3943 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1769 - re_lu_177_accuracy: 0.3996 - re_lu_233_accuracy: 0.6\n",
      "Epoch 00019: re_lu_233_loss did not improve from 13.02268\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 717.7689 - re_lu_65_loss: 547.8310 - re_lu_121_loss: 122.9987 - re_lu_177_loss: 33.5440 - re_lu_233_loss: 13.3953 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1769 - re_lu_177_accuracy: 0.3996 - re_lu_233_accuracy: 0.6353 - val_loss: 11433.7080 - val_re_lu_65_loss: 2656.6128 - val_re_lu_121_loss: 2798.0005 - val_re_lu_177_loss: 2937.7625 - val_re_lu_233_loss: 3041.3284 - val_re_lu_65_accuracy: 0.1161 - val_re_lu_121_accuracy: 0.1464 - val_re_lu_177_accuracy: 0.3361 - val_re_lu_233_accuracy: 0.6038\n",
      "Learning rate:  1e-05\n",
      "Epoch 20/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 713.9874 - re_lu_65_loss: 546.1272 - re_lu_121_loss: 121.8557 - re_lu_177_loss: 32.9508 - re_lu_233_loss: 13.0533 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1774 - re_lu_177_accuracy: 0.4006 - re_lu_233_accuracy: 0.6360- ETA: 3s - loss: 714.5268 - re_lu_65_loss: 546.4720 - re_lu_121_loss: 121.9551 - re_lu_177_loss: 33.0055 - re_lu_233_loss: 13.0940 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.4006 - re_lu_\n",
      "Epoch 00020: re_lu_233_loss did not improve from 13.02268\n",
      "2280/2280 [==============================] - 420s 184ms/step - loss: 713.9874 - re_lu_65_loss: 546.1272 - re_lu_121_loss: 121.8557 - re_lu_177_loss: 32.9508 - re_lu_233_loss: 13.0533 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1774 - re_lu_177_accuracy: 0.4006 - re_lu_233_accuracy: 0.6360 - val_loss: 11434.6602 - val_re_lu_65_loss: 2655.1826 - val_re_lu_121_loss: 2798.5264 - val_re_lu_177_loss: 2939.2644 - val_re_lu_233_loss: 3041.6863 - val_re_lu_65_accuracy: 0.1167 - val_re_lu_121_accuracy: 0.1463 - val_re_lu_177_accuracy: 0.3407 - val_re_lu_233_accuracy: 0.6106\n",
      "Learning rate:  1e-05\n",
      "Epoch 21/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 712.6016 - re_lu_65_loss: 545.3324 - re_lu_121_loss: 121.5619 - re_lu_177_loss: 32.8450 - re_lu_233_loss: 12.8630 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1760 - re_lu_177_accuracy: 0.4018 - re_lu_233_accuracy: 0.6386  ETA: 14s - loss: 711.3213 - re_lu_65_loss: 544.8171 - re_lu_121_loss: 121.1115 - re_lu_177_loss: 32.5906 - re_lu_233_loss: 12.8030\n",
      "Epoch 00021: re_lu_233_loss improved from 13.02268 to 12.86297, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 431s 189ms/step - loss: 712.6016 - re_lu_65_loss: 545.3324 - re_lu_121_loss: 121.5619 - re_lu_177_loss: 32.8450 - re_lu_233_loss: 12.8630 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1760 - re_lu_177_accuracy: 0.4018 - re_lu_233_accuracy: 0.6386 - val_loss: 11437.5947 - val_re_lu_65_loss: 2659.0237 - val_re_lu_121_loss: 2799.0630 - val_re_lu_177_loss: 2939.4514 - val_re_lu_233_loss: 3040.0488 - val_re_lu_65_accuracy: 0.1177 - val_re_lu_121_accuracy: 0.1449 - val_re_lu_177_accuracy: 0.3385 - val_re_lu_233_accuracy: 0.6144\n",
      "Learning rate:  1e-05\n",
      "Epoch 22/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 711.3651 - re_lu_65_loss: 544.7198 - re_lu_121_loss: 121.0772 - re_lu_177_loss: 32.6340 - re_lu_233_loss: 12.9350 - re_lu_65_accuracy: 0.1287 - re_lu_121_accuracy: 0.1768 - re_lu_177_accuracy: 0.4027 - re_lu_233_accuracy: 0.6399  - ETA: 6:01 - loss: 719.8469 - re_lu_65_loss: 553.7428 - re_lu_121_loss: 122.6254 - re_lu_177_loss: 31.6718 - re_lu_233_loss: 11.8069 - re_lu_65_accuracy: - ETA: 3:39 - loss: 712.5656 - re_lu_65_loss: 546.1039 - re_lu_121_loss: 121.2527 - re_lu_177_loss: 32.3743 - re_lu_233_loss: 12.8346 - re_lu_65_accuracy: 0.1281 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4016 - re_lu_233_ - ETA: 3:37 - loss: 713.4437 - re_lu_65_loss: 546.4788 - re_lu_121_loss: 121.5139 - re_lu_177_loss: 32.5306 - re_lu_233_ - ETA: 3:15 - loss: 711.9401 - re_lu_65_loss: 545.0388 - re_lu_121_loss: 121.4987 - re_lu_177_lo - ETA: 5s - loss: 711.0908 - re_lu_65_loss: 544.4889 - re_lu_121_loss: 121.0262 - re_lu_177_loss: 32.6377 - re_lu_233_loss: 12.9391 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1767 - re_lu_177_accuracy: 0.4026 - re_lu_233_accuracy: 0.639 - ETA: 4s - loss: 710.9860 - re_lu_65_loss: 544.4269 - re_lu_121_loss: 120.9956 - re_lu_177_loss: 32.6290 - re_lu_233_loss: 12.9355 - re_lu_65_accuracy: 0.1288 - re_lu_121_accuracy: 0.1767 - re_lu_177_accuracy: 0.4026 \n",
      "Epoch 00022: re_lu_233_loss did not improve from 12.86297\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 711.3651 - re_lu_65_loss: 544.7198 - re_lu_121_loss: 121.0772 - re_lu_177_loss: 32.6340 - re_lu_233_loss: 12.9350 - re_lu_65_accuracy: 0.1287 - re_lu_121_accuracy: 0.1768 - re_lu_177_accuracy: 0.4027 - re_lu_233_accuracy: 0.6399 - val_loss: 11443.7002 - val_re_lu_65_loss: 2657.9172 - val_re_lu_121_loss: 2801.0745 - val_re_lu_177_loss: 2941.4558 - val_re_lu_233_loss: 3043.2476 - val_re_lu_65_accuracy: 0.1146 - val_re_lu_121_accuracy: 0.1432 - val_re_lu_177_accuracy: 0.3448 - val_re_lu_233_accuracy: 0.6255\n",
      "Learning rate:  1e-05\n",
      "Epoch 23/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 710.9768 - re_lu_65_loss: 544.3111 - re_lu_121_loss: 120.9522 - re_lu_177_loss: 32.7530 - re_lu_233_loss: 12.9614 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1776 - re_lu_177_accuracy: 0.4039 - re_lu_233_accuracy: 0.6404  - ETA: 4:18 - loss: 707.9598 - re_lu_65_loss: 541.7534 - re_lu_121_loss: 120.4784 - re_lu_177_loss: 32.8102 - re_lu_233_loss: 12.9175 - re_lu_65_accuracy: 0.1282 - re - ETA: 4:04 - loss: 710.4667 - re_lu_65_loss: 543.1003 - re_lu_121_loss: 12 - ETA: 3:34 - loss: 708.4604 - re_lu_65_loss: 542.2068 - re_lu_121_loss: 120.3937 - re_lu_177_loss: 32.8347 - re_lu_233_loss: 13.0255 - re_lu_65_accuracy: 0.1283 - re_lu_121_accuracy: 0.1771 - re_lu_177_accuracy: 0.4032 - re_lu_233_accuracy: 0.637 - ETA: 3:34 - loss: 708.3527 - re_lu_65_loss: 542.1594 - re_lu_121_loss: 120.3568 - re_lu_177_loss: 32.8196 - re_lu_233_loss: 13.0171 - re_lu_65_accuracy: 0.1283 - re - ETA: 3:20 - loss: 709.7322 - re_lu_65_loss: 542.7380 - - ETA: 2:04 - loss: 713.8275 - re_lu_65_loss: 545.1183 - re_lu_121_loss: 122.6360 - re_lu_177_los - ETA: 1:38 - loss: 714.0156 - re_lu_65_loss: 546.2898 - re_lu_121_loss: 122.1789 - re_lu_177_loss: 32.8217 - re_lu_233_loss:  - ETA: 1:16 - loss: - ETA: 1s - loss: 711.0424 - re_lu_65_loss: 544.4305 - re_lu_121_loss: 120.9737 - re_lu_177_loss: 32.7318 - re_lu_233_loss: 12.9073 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1776 - re_lu_177_accuracy: 0.4038 - re_lu_233_accura\n",
      "Epoch 00023: re_lu_233_loss did not improve from 12.86297\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 710.9768 - re_lu_65_loss: 544.3111 - re_lu_121_loss: 120.9522 - re_lu_177_loss: 32.7530 - re_lu_233_loss: 12.9614 - re_lu_65_accuracy: 0.1285 - re_lu_121_accuracy: 0.1776 - re_lu_177_accuracy: 0.4039 - re_lu_233_accuracy: 0.6404 - val_loss: 11441.0166 - val_re_lu_65_loss: 2657.4109 - val_re_lu_121_loss: 2800.0452 - val_re_lu_177_loss: 2940.6292 - val_re_lu_233_loss: 3042.9255 - val_re_lu_65_accuracy: 0.1178 - val_re_lu_121_accuracy: 0.1460 - val_re_lu_177_accuracy: 0.3449 - val_re_lu_233_accuracy: 0.6168\n",
      "Learning rate:  1e-05\n",
      "Epoch 24/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 706.1425 - re_lu_65_loss: 541.7855 - re_lu_121_loss: 119.7100 - re_lu_177_loss: 32.1551 - re_lu_233_loss: 12.4918 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.4056 - re_lu_233_accuracy: 0.6421\n",
      "Epoch 00024: re_lu_233_loss improved from 12.86297 to 12.49181, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 428s 188ms/step - loss: 706.1425 - re_lu_65_loss: 541.7855 - re_lu_121_loss: 119.7100 - re_lu_177_loss: 32.1551 - re_lu_233_loss: 12.4918 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1773 - re_lu_177_accuracy: 0.4056 - re_lu_233_accuracy: 0.6421 - val_loss: 11440.4795 - val_re_lu_65_loss: 2656.9133 - val_re_lu_121_loss: 2800.9998 - val_re_lu_177_loss: 2939.9741 - val_re_lu_233_loss: 3042.5986 - val_re_lu_65_accuracy: 0.1184 - val_re_lu_121_accuracy: 0.1467 - val_re_lu_177_accuracy: 0.3404 - val_re_lu_233_accuracy: 0.6120\n",
      "Learning rate:  1e-05\n",
      "Epoch 25/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 706.0755 - re_lu_65_loss: 541.4799 - re_lu_121_loss: 119.6504 - re_lu_177_loss: 32.2196 - re_lu_233_loss: 12.7254 - re_lu_65_accuracy: 0.1298 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.4068 - re_lu_233_accuracy: 0.6417  ETA: 12s - loss: 706.2897 - re_lu_65_loss: 541.7780 - re_lu_121_loss: 119.7001 - re_lu_177_loss: 32.1402 - re_lu_233_loss: 12.6713 - re_lu_65_accuracy: 0.12\n",
      "Epoch 00025: re_lu_233_loss did not improve from 12.49181\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 706.0755 - re_lu_65_loss: 541.4799 - re_lu_121_loss: 119.6504 - re_lu_177_loss: 32.2196 - re_lu_233_loss: 12.7254 - re_lu_65_accuracy: 0.1298 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.4068 - re_lu_233_accuracy: 0.6417 - val_loss: 11449.0430 - val_re_lu_65_loss: 2658.9624 - val_re_lu_121_loss: 2802.7310 - val_re_lu_177_loss: 2942.9902 - val_re_lu_233_loss: 3044.3625 - val_re_lu_65_accuracy: 0.1171 - val_re_lu_121_accuracy: 0.1419 - val_re_lu_177_accuracy: 0.3446 - val_re_lu_233_accuracy: 0.6208\n",
      "Learning rate:  1e-05\n",
      "Epoch 26/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 704.7440 - re_lu_65_loss: 541.4354 - re_lu_121_loss: 118.6558 - re_lu_177_loss: 32.0546 - re_lu_233_loss: 12.5982 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4085 - re_lu_233_accuracy: 0.6439  - ETA: 6:05 - loss: 674.9534 - re_lu_65_loss: 530.4652 - re_lu_121_loss: 106.6922 - re_lu_177_loss: 27.0580 - re_lu_233_loss: 10.7381 - re_lu_65_accuracy: 0.1309 - re_lu_121_accuracy: 0.1804 - re_lu_177_accuracy: 0.4087 - re_lu - ETA: 6:02 - loss: 667.9753 - re_lu_65_loss: 524.5328 - re_lu_121_loss: 105.7913 - re_lu_177_loss: 27.1122 - re_lu_233_loss: 10.5390 - re_lu_65_accuracy: 0.1310 - re_lu_121_accuracy: 0.1806 - re_lu_177_accuracy: 0.4070 - re - ETA: 5:59 - loss: 674.7592 - re_lu_65_loss: 527.1348 - re_lu_121_loss: 108.7739 - re_lu_177_loss: 28.1998 - re_lu_233_loss: 10.6507 - re - ETA: 28s - loss: 704.2134 - re_lu_65_loss: 540.6041 - re_lu_121_loss: 118.7482 - re_lu_177_loss: 32.1489 - re_lu_233_loss: 12.7125 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4083\n",
      "Epoch 00026: re_lu_233_loss did not improve from 12.49181\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 704.7440 - re_lu_65_loss: 541.4354 - re_lu_121_loss: 118.6558 - re_lu_177_loss: 32.0546 - re_lu_233_loss: 12.5982 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4085 - re_lu_233_accuracy: 0.6439 - val_loss: 11449.1484 - val_re_lu_65_loss: 2661.1143 - val_re_lu_121_loss: 2802.9084 - val_re_lu_177_loss: 2942.2971 - val_re_lu_233_loss: 3042.8313 - val_re_lu_65_accuracy: 0.1162 - val_re_lu_121_accuracy: 0.1442 - val_re_lu_177_accuracy: 0.3489 - val_re_lu_233_accuracy: 0.6246\n",
      "Learning rate:  1e-05\n",
      "Epoch 27/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 701.7213 - re_lu_65_loss: 539.3216 - re_lu_121_loss: 118.2035 - re_lu_177_loss: 31.7870 - re_lu_233_loss: 12.4086 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4096 - re_lu_233_accuracy: 0.6446- ETA: 5s - loss: 701.4074 - re_lu_65_loss: 539.0574 - re_lu_121_loss: 118.2057 - re_lu_177_loss: 31.7544 - re_lu_233_loss: 12.3892 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4096\n",
      "Epoch 00027: re_lu_233_loss improved from 12.49181 to 12.40864, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 426s 187ms/step - loss: 701.7213 - re_lu_65_loss: 539.3216 - re_lu_121_loss: 118.2035 - re_lu_177_loss: 31.7870 - re_lu_233_loss: 12.4086 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4096 - re_lu_233_accuracy: 0.6446 - val_loss: 11452.3115 - val_re_lu_65_loss: 2660.9016 - val_re_lu_121_loss: 2804.0505 - val_re_lu_177_loss: 2943.5002 - val_re_lu_233_loss: 3043.8586 - val_re_lu_65_accuracy: 0.1146 - val_re_lu_121_accuracy: 0.1403 - val_re_lu_177_accuracy: 0.3466 - val_re_lu_233_accuracy: 0.6311\n",
      "Learning rate:  1e-05\n",
      "Epoch 28/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 702.2895 - re_lu_65_loss: 539.2610 - re_lu_121_loss: 118.4323 - re_lu_177_loss: 32.0035 - re_lu_233_loss: 12.5924 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4121 - re_lu_233_accuracy: 0.6464\n",
      "Epoch 00028: re_lu_233_loss did not improve from 12.40864\n",
      "2280/2280 [==============================] - 418s 184ms/step - loss: 702.2895 - re_lu_65_loss: 539.2610 - re_lu_121_loss: 118.4323 - re_lu_177_loss: 32.0035 - re_lu_233_loss: 12.5924 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4121 - re_lu_233_accuracy: 0.6464 - val_loss: 11455.4092 - val_re_lu_65_loss: 2661.9031 - val_re_lu_121_loss: 2805.3967 - val_re_lu_177_loss: 2942.9255 - val_re_lu_233_loss: 3045.1851 - val_re_lu_65_accuracy: 0.1164 - val_re_lu_121_accuracy: 0.1429 - val_re_lu_177_accuracy: 0.3435 - val_re_lu_233_accuracy: 0.6215\n",
      "Learning rate:  1e-05\n",
      "Epoch 29/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 699.4196 - re_lu_65_loss: 538.2363 - re_lu_121_loss: 117.3160 - re_lu_177_loss: 31.4683 - re_lu_233_loss: 12.3988 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4132 - re_lu_233_accuracy: 0.6478  ETA: 6:11  - ETA: 5:34 - loss: 695.2392 - re_lu_65_loss: 532.0775 - re_lu_121_loss: 118.1174 - re_lu_177_ - ETA: 5:08 - loss: 700.3994 - re_lu_65_loss: 537.2547 - re_lu_121_loss: 118.0697 - re_lu_177_loss: 32.0002 - re_lu_233_loss: 13.0750 - re_lu_65_accuracy: 0.1298 - re_lu_121_accuracy: 0.1795 - re_lu_1 - ETA: 5:00 - loss: 701.6793 - re_lu_65_loss: 538.8978 - re_lu_121_loss: 118.1922 - re_lu_177_loss: 31.8070 - re_lu_233_loss: 12.7826 - re_lu_65_accur - ETA: 4:43 - loss: 700.3062 - re_lu_65_loss: 537.9200 - re_lu_121_loss: 117 - ETA: 4:13 - loss: 701.6691 - re_lu_65_loss: 540.1566 - re_lu_121_loss: 117.7571 - re_lu_177_loss: 31.2818 - re_lu_233_loss: 12.4740  - ETA: 3:11 - loss: 700.3528 - re_lu_65_loss: 539.0163 - re_lu_ - ETA: 2:39 - loss: 704.3073 - re_lu_65_loss: 541.3619 - re_lu_121_loss: 118.3326 - re_lu_177_loss: 31.7864 - re_lu_233_loss: 12.8273 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1784 - re_lu - ETA: 1:48 - loss: 702.8921 - re_lu_65_loss: 539.5607 - re_lu_121_loss: 118.3010 - re_lu_177_loss: 32.0908 - re_lu_233_loss: 12.9405 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1784 - ETA: 1:38 - loss: 700.3981 - re_lu_65_loss: 538.0394 - re_lu_121_loss: 117.6617 - re_lu_177_loss: 31.8931 - re_lu_233_loss: 12.8050 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4129 - re_lu_233_accuracy - ETA: 1:36 - loss: 700.6620 - re_lu_65_loss: 538.1445 - re_lu_121_loss: 117.7183 - re_lu_177_loss: 31.9401 - re_lu_233_loss: 12.8601 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4 - ETA: 1:31 - loss: 700.3495 - re_lu_65_loss: 538.1062 - re_lu_121_loss: 117.6780 - re_lu_177_loss: 31.7964 - re_lu_233_loss: 12.7700 - re_lu_65_ac - ETA: 1:13 - loss: 697.8459 - re_lu_65_loss: 536.4 - ETA: 4s - loss: 699.7436 - re_lu_65_loss: 538.4905 - re_lu_121_loss: 117.3830 - re_lu_177_loss: 31.4594 - re_lu_233_loss: 12.4105 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4133 - r\n",
      "Epoch 00029: re_lu_233_loss improved from 12.40864 to 12.39877, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 426s 187ms/step - loss: 699.4196 - re_lu_65_loss: 538.2363 - re_lu_121_loss: 117.3160 - re_lu_177_loss: 31.4683 - re_lu_233_loss: 12.3988 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4132 - re_lu_233_accuracy: 0.6478 - val_loss: 11461.1035 - val_re_lu_65_loss: 2660.8469 - val_re_lu_121_loss: 2807.0552 - val_re_lu_177_loss: 2946.2690 - val_re_lu_233_loss: 3046.9314 - val_re_lu_65_accuracy: 0.1176 - val_re_lu_121_accuracy: 0.1489 - val_re_lu_177_accuracy: 0.3492 - val_re_lu_233_accuracy: 0.6196\n",
      "Learning rate:  1e-05\n",
      "Epoch 30/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 697.9792 - re_lu_65_loss: 537.1638 - re_lu_121_loss: 116.9209 - re_lu_177_loss: 31.5153 - re_lu_233_loss: 12.3787 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4154 - re_lu_233_accuracy: 0.6497  ETA: 24s - loss: 697.1\n",
      "Epoch 00030: re_lu_233_loss improved from 12.39877 to 12.37875, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 433s 190ms/step - loss: 697.9792 - re_lu_65_loss: 537.1638 - re_lu_121_loss: 116.9209 - re_lu_177_loss: 31.5153 - re_lu_233_loss: 12.3787 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4154 - re_lu_233_accuracy: 0.6497 - val_loss: 11459.4141 - val_re_lu_65_loss: 2662.9036 - val_re_lu_121_loss: 2805.5261 - val_re_lu_177_loss: 2944.7329 - val_re_lu_233_loss: 3046.2402 - val_re_lu_65_accuracy: 0.1166 - val_re_lu_121_accuracy: 0.1442 - val_re_lu_177_accuracy: 0.3602 - val_re_lu_233_accuracy: 0.6290\n",
      "Learning rate:  1e-05\n",
      "Epoch 31/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 694.7012 - re_lu_65_loss: 535.7690 - re_lu_121_loss: 115.8824 - re_lu_177_loss: 30.9839 - re_lu_233_loss: 12.0651 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4142 - re_lu_233_accuracy: 0.6518   ETA: 5:39 - loss: 744.4113 - re_lu_65_loss: 574.2131 - re_lu_121_ - ETA: 3:13 - loss: 696.8546 - re_lu_65_loss: 538.7773 - re_lu_121_loss: 115.1889 - re_lu_177_loss: 30.7892 - re_lu_233_loss: 12.0988 - re_l - ETA: 2:54 - loss: 694.2105 - re_lu_65_loss: 536.5035 - re_lu_121_loss: 114. - ETA: 2:25 - loss: 695.0093 - re_lu_65_loss: 536.9443 - re_lu_121_loss: 115.2898 - re_lu_177_loss: 30.7244 -\n",
      "Epoch 00031: re_lu_233_loss improved from 12.37875 to 12.06514, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 429s 188ms/step - loss: 694.7012 - re_lu_65_loss: 535.7690 - re_lu_121_loss: 115.8824 - re_lu_177_loss: 30.9839 - re_lu_233_loss: 12.0651 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4142 - re_lu_233_accuracy: 0.6518 - val_loss: 11468.3154 - val_re_lu_65_loss: 2664.6497 - val_re_lu_121_loss: 2809.0530 - val_re_lu_177_loss: 2947.6106 - val_re_lu_233_loss: 3046.9985 - val_re_lu_65_accuracy: 0.1158 - val_re_lu_121_accuracy: 0.1431 - val_re_lu_177_accuracy: 0.3472 - val_re_lu_233_accuracy: 0.6263\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 32/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 693.5188 - re_lu_65_loss: 534.7951 - re_lu_121_loss: 115.6718 - re_lu_177_loss: 30.9645 - re_lu_233_loss: 12.0856 - re_lu_65_accuracy: 0.1299 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4155 - re_lu_233_accuracy: 0.6519  ETA: 14s - loss: 693.5912 - re_lu_65_loss: 534.7172 - re_lu_121_loss: 115.7167 - re_lu_177_loss: 31.0359 - re_lu_233_loss: 12.1197 \n",
      "Epoch 00032: re_lu_233_loss did not improve from 12.06514\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 693.5188 - re_lu_65_loss: 534.7951 - re_lu_121_loss: 115.6718 - re_lu_177_loss: 30.9645 - re_lu_233_loss: 12.0856 - re_lu_65_accuracy: 0.1299 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4155 - re_lu_233_accuracy: 0.6519 - val_loss: 11467.3154 - val_re_lu_65_loss: 2664.0894 - val_re_lu_121_loss: 2808.4548 - val_re_lu_177_loss: 2947.1763 - val_re_lu_233_loss: 3047.5969 - val_re_lu_65_accuracy: 0.1184 - val_re_lu_121_accuracy: 0.1455 - val_re_lu_177_accuracy: 0.3486 - val_re_lu_233_accuracy: 0.6233\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 33/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 693.0058 - re_lu_65_loss: 534.5889 - re_lu_121_loss: 115.4706 - re_lu_177_loss: 30.8015 - re_lu_233_loss: 12.1450 - re_lu_65_accuracy: 0.1298 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4155 - re_lu_233_accuracy: 0.6522  - ETA: 5:43 - loss: 705.2934 - re_lu_65_loss: 546.4733 - re_lu_121_loss: 117.0579 - re_lu_177_loss: 30.1184 - re_lu_233_loss: 11.6438 - re_lu_65_accur - ETA: 5:27 - loss: 699.4628 - re_lu_65_loss: 540.7198 - re_lu_121_loss: 116.0614 - re_lu_177_loss: 30.7476 - re_lu_233_los - ETA: 3:40 - loss: 700.8240 - re_lu_65_loss: 539.7590 - re_lu_121_loss: 117.3712 - re_lu_177_loss: 31.5516 - re_lu_233_loss: 12.14 - ETA: 3:20 - loss: 700.2404 - re_lu_65_loss: 539.7731 - re_lu_121_loss: 117.1021 - re_lu_177_loss: 31.2791 - re_lu_233_loss: 12.0864 - - ETA: 34s - loss: 692.7245 - re_lu_65_loss: 534.3754 - re_lu_121_loss: 115.3764 - re_l - ETA: 20s - loss: 692.7477 - re_lu_65_loss: 534.1712 - re_lu\n",
      "Epoch 00033: re_lu_233_loss did not improve from 12.06514\n",
      "2280/2280 [==============================] - 417s 183ms/step - loss: 693.0058 - re_lu_65_loss: 534.5889 - re_lu_121_loss: 115.4706 - re_lu_177_loss: 30.8015 - re_lu_233_loss: 12.1450 - re_lu_65_accuracy: 0.1298 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4155 - re_lu_233_accuracy: 0.6522 - val_loss: 11467.4443 - val_re_lu_65_loss: 2664.4946 - val_re_lu_121_loss: 2808.3074 - val_re_lu_177_loss: 2947.2522 - val_re_lu_233_loss: 3047.3813 - val_re_lu_65_accuracy: 0.1155 - val_re_lu_121_accuracy: 0.1417 - val_re_lu_177_accuracy: 0.3528 - val_re_lu_233_accuracy: 0.6371\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 34/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 693.3972 - re_lu_65_loss: 534.7923 - re_lu_121_loss: 115.5035 - re_lu_177_loss: 30.9334 - re_lu_233_loss: 12.1680 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1786 - re_lu_177_accuracy: 0.4157 - re_lu_233_accuracy: 0.6535  ETA: 14s - loss: 693.3311 - re_lu_65_loss: 534.5242 - re_lu_121_loss: 115.6786 - re_lu_177_loss: 31.0060 - re_lu_233_loss: 12.1223 - re_\n",
      "Epoch 00034: re_lu_233_loss did not improve from 12.06514\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 693.3972 - re_lu_65_loss: 534.7923 - re_lu_121_loss: 115.5035 - re_lu_177_loss: 30.9334 - re_lu_233_loss: 12.1680 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1786 - re_lu_177_accuracy: 0.4157 - re_lu_233_accuracy: 0.6535 - val_loss: 11463.3281 - val_re_lu_65_loss: 2662.4172 - val_re_lu_121_loss: 2807.1636 - val_re_lu_177_loss: 2946.3887 - val_re_lu_233_loss: 3047.3726 - val_re_lu_65_accuracy: 0.1174 - val_re_lu_121_accuracy: 0.1432 - val_re_lu_177_accuracy: 0.3572 - val_re_lu_233_accuracy: 0.6322\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 35/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 691.8138 - re_lu_65_loss: 534.2186 - re_lu_121_loss: 114.9624 - re_lu_177_loss: 30.6571 - re_lu_233_loss: 11.9762 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4161 - re_lu_233_accuracy: 0.6531  - ETA: 2: - ETA: 1:28 - loss: 688.6473 - re_lu_65_loss: 532.4677 - re_lu_121_loss: 114.0309 - re_lu_177_loss: 30.3617 - re_lu_233_loss: 11.7874 - re_lu_65_accuracy: - ETA: 44s - loss: 690.9559 - re_lu_\n",
      "Epoch 00035: re_lu_233_loss improved from 12.06514 to 11.97620, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 425s 187ms/step - loss: 691.8138 - re_lu_65_loss: 534.2186 - re_lu_121_loss: 114.9624 - re_lu_177_loss: 30.6571 - re_lu_233_loss: 11.9762 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4161 - re_lu_233_accuracy: 0.6531 - val_loss: 11466.0527 - val_re_lu_65_loss: 2662.7598 - val_re_lu_121_loss: 2809.2681 - val_re_lu_177_loss: 2946.8132 - val_re_lu_233_loss: 3047.2124 - val_re_lu_65_accuracy: 0.1165 - val_re_lu_121_accuracy: 0.1445 - val_re_lu_177_accuracy: 0.3523 - val_re_lu_233_accuracy: 0.6253\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 36/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 692.4705 - re_lu_65_loss: 534.3891 - re_lu_121_loss: 115.2073 - re_lu_177_loss: 30.7986 - re_lu_233_loss: 12.0746 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4164 - re_lu_233_accuracy: 0.6531\n",
      "Epoch 00036: re_lu_233_loss did not improve from 11.97620\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 692.4705 - re_lu_65_loss: 534.3891 - re_lu_121_loss: 115.2073 - re_lu_177_loss: 30.7986 - re_lu_233_loss: 12.0746 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4164 - re_lu_233_accuracy: 0.6531 - val_loss: 11467.8408 - val_re_lu_65_loss: 2662.2961 - val_re_lu_121_loss: 2808.8286 - val_re_lu_177_loss: 2947.6062 - val_re_lu_233_loss: 3049.1040 - val_re_lu_65_accuracy: 0.1173 - val_re_lu_121_accuracy: 0.1431 - val_re_lu_177_accuracy: 0.3514 - val_re_lu_233_accuracy: 0.6301\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 37/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 691.4788 - re_lu_65_loss: 533.9507 - re_lu_121_loss: 114.8891 - re_lu_177_loss: 30.6665 - re_lu_233_loss: 11.9719 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4164 - re_lu_233_accuracy: 0.6532\n",
      "Epoch 00037: re_lu_233_loss improved from 11.97620 to 11.97193, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 426s 187ms/step - loss: 691.4788 - re_lu_65_loss: 533.9507 - re_lu_121_loss: 114.8891 - re_lu_177_loss: 30.6665 - re_lu_233_loss: 11.9719 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4164 - re_lu_233_accuracy: 0.6532 - val_loss: 11466.1221 - val_re_lu_65_loss: 2664.5359 - val_re_lu_121_loss: 2809.2219 - val_re_lu_177_loss: 2946.3054 - val_re_lu_233_loss: 3046.0557 - val_re_lu_65_accuracy: 0.1183 - val_re_lu_121_accuracy: 0.1495 - val_re_lu_177_accuracy: 0.3533 - val_re_lu_233_accuracy: 0.6214\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 38/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 691.3979 - re_lu_65_loss: 533.5575 - re_lu_121_loss: 114.8949 - re_lu_177_loss: 30.7833 - re_lu_233_loss: 12.1614 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4161 - re_lu_233_accuracy: 0.6531  ETA: 22s - loss: 689.7213 - re_lu_65_loss: 532.5251 - re_lu_121_loss: 114.5451 - re_lu_177_loss: 30.6354 - re_lu_233_loss: 12.0156 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1782 - re_lu_177 - ETA: 18s - loss: 689.2708 - re_lu_65_loss: 532.3011 - re_lu_121_loss: 114.4117 - re_l\n",
      "Epoch 00038: re_lu_233_loss did not improve from 11.97193\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 691.3979 - re_lu_65_loss: 533.5575 - re_lu_121_loss: 114.8949 - re_lu_177_loss: 30.7833 - re_lu_233_loss: 12.1614 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4161 - re_lu_233_accuracy: 0.6531 - val_loss: 11468.8486 - val_re_lu_65_loss: 2664.5005 - val_re_lu_121_loss: 2808.3027 - val_re_lu_177_loss: 2947.8838 - val_re_lu_233_loss: 3048.1621 - val_re_lu_65_accuracy: 0.1168 - val_re_lu_121_accuracy: 0.1434 - val_re_lu_177_accuracy: 0.3569 - val_re_lu_233_accuracy: 0.6351\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 39/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.5934 - re_lu_65_loss: 533.1053 - re_lu_121_loss: 114.4537 - re_lu_177_loss: 30.3556 - re_lu_233_loss: 11.6783 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4166 - re_lu_233_accuracy: 0.6535  - ETA: 3:12 - loss: 686.1737 - re_lu_65_loss: 530.6232 - re_lu_121_loss: 114.1743 - re_lu_177_loss: 29.9523 - re_lu_233_loss: 11.4228 - re_lu_65 - ETA: 2:54 - loss: 685.8846 - re_lu_65_loss: 530.6107 - re_lu_121_loss: 113.8615 - re_lu_177_loss: 29.9153 - re_lu_233_loss: 11.4958 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1777 - re_lu_177_accuracy: - ETA: 2:48 - loss: 685.5645 - re_lu_65_loss: 530.2815 - re_lu_121_loss: 113.6841 - re_lu_177_loss: 30.0115 - re_lu_233_loss: 11.5 - ETA: 2:28 - loss: 688.2936 - re_lu_65_loss: 531.5687 - re_lu_121_loss: 114.4264 - re_lu_177_loss: 30.4713 - re_lu_233_loss: 11.8260 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1778 - re_lu_177_accurac - E - ETA: 58s - loss: 689.6388 - re_lu_65_loss: 532.6383 - re_lu_121_loss: 114.6199 - re_lu_177_loss: 30.5487 - re_lu_233_loss: 11.8314 - re_lu_65_accuracy: 0.1296 - re_lu_121_ac - ETA: 51s - loss: 688.9887 - re_lu_65_loss: 532.2603 - re_lu_121_loss: 114.4571 - re_lu_177_loss: 30.4733 - re_lu_233_loss: 11.7977 - re_lu_65_accuracy: 0.1296 - re_lu_121_ - ETA: 45s - loss: 689.4426 - re_lu_65_loss: 532.6591 - re_lu_121_loss: 114.5038 - re_lu_177_loss: 30.4935 - re_lu_233_loss: 11.7858 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1778 - re_lu_177_accuracy: 0.4 - ETA: 42s - loss: 689.4271 - re_lu_65_loss: 532.6233 - re_lu_121_loss: 114.5460 - re_lu_177_loss: 30.4696 - re_lu_233_loss: 11.7878 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.17 - ETA: 37s - loss: 689.5527 - re_lu_65_loss: 532.7711 - re_lu_121_loss: 114.5842 - re_lu_177_loss: 30.4423 - re_lu_2\n",
      "Epoch 00039: re_lu_233_loss improved from 11.97193 to 11.67828, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 427s 187ms/step - loss: 689.5934 - re_lu_65_loss: 533.1053 - re_lu_121_loss: 114.4537 - re_lu_177_loss: 30.3556 - re_lu_233_loss: 11.6783 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4166 - re_lu_233_accuracy: 0.6535 - val_loss: 11468.3574 - val_re_lu_65_loss: 2663.9502 - val_re_lu_121_loss: 2809.6106 - val_re_lu_177_loss: 2947.5762 - val_re_lu_233_loss: 3047.2158 - val_re_lu_65_accuracy: 0.1170 - val_re_lu_121_accuracy: 0.1460 - val_re_lu_177_accuracy: 0.3543 - val_re_lu_233_accuracy: 0.6289\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 40/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 690.1075 - re_lu_65_loss: 533.1166 - re_lu_121_loss: 114.4449 - re_lu_177_loss: 30.5758 - re_lu_233_loss: 11.9691 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4171 - re_lu_233_accuracy: 0.6537  - ETA: 3:07 - loss: 692.0961 - re_lu_65_loss: 535.0087 - re_lu_121_loss: 114.3369 - re_lu_177_loss: 30.6559 - re_lu_233_loss: 12.0940 - re_lu_65_accuracy: 0.1301 - re_lu_121_accuracy: 0.1785 - re_lu_1 - ETA: 2:59 - loss: 688.6942 - re_lu_65_loss: 532.9202 - re_lu_121_loss: 113.4756 - re_lu_177_loss: 30.3188 - re_lu_233_loss: 11.9791 - re_lu_65_accuracy: 0.1302 - re_lu_121_accuracy: 0.1780 - re_ - ETA: 2:50 - loss: 689.9641 - re_lu_65_loss: 534.0384 - re_lu_121_loss: 113.6982 - re_lu_177_loss: 30.3053 - re_lu_233_loss: 11.9216 - re_lu_65_accuracy: 0.1300 - re_lu_121_accuracy: 0.1782 - re_lu_177_acc - ETA: 2:42 - loss: 689.6622 - re_lu_65_loss: 533.6912 - re_lu_121_loss: 113.7461 - re_lu_177_loss: 30.2943 - re_lu_233_loss: 11.9303 - re_lu_65_accuracy: 0.1300 - re_ - ETA: 2:28 - loss: 688.6527 - re_lu_65_loss: 533.2054 - re_lu_121_loss: 113.4940 - re_lu_177_loss: 30.100 - ETA:  - ETA: 4s - loss: 690.6543 - re_lu_65_loss: 533.4644 - re_lu_121_loss: 114.5335 - re_lu_177_loss: 30.6579 - re_lu_233_loss: 11.9975 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1787 - re_lu_177_accuracy: 0.4172 - r\n",
      "Epoch 00040: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 690.1075 - re_lu_65_loss: 533.1166 - re_lu_121_loss: 114.4449 - re_lu_177_loss: 30.5758 - re_lu_233_loss: 11.9691 - re_lu_65_accuracy: 0.1297 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4171 - re_lu_233_accuracy: 0.6537 - val_loss: 11463.6885 - val_re_lu_65_loss: 2662.5461 - val_re_lu_121_loss: 2808.3904 - val_re_lu_177_loss: 2946.0613 - val_re_lu_233_loss: 3046.6963 - val_re_lu_65_accuracy: 0.1176 - val_re_lu_121_accuracy: 0.1419 - val_re_lu_177_accuracy: 0.3523 - val_re_lu_233_accuracy: 0.6313\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 41/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 690.9752 - re_lu_65_loss: 533.6061 - re_lu_121_loss: 114.7450 - re_lu_177_loss: 30.6133 - re_lu_233_loss: 12.0113 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4174 - re_lu_233_accuracy: 0.6534  - ETA: 5:32 - loss: 707.5834 - re_lu_65_loss: 546.5768 - re_lu_121_loss: 116.8861 - re_lu_177_loss: 31.3570 - re_lu_233_loss: 12.7636 - re_lu_65_accuracy: 0.1298 - re_lu_121_accu - ETA: 5:20 - loss: 702.0547 - re_lu_65_loss: 542.0976 - re_lu_121_loss:  - ETA: 4:50 - loss: 699.2151 - re_lu_65_loss: 537.7591 - re_lu_121_loss: 117.0160 - re_lu_177_loss: 31.8144 - re_lu_233_loss: 12.6256 - re_lu_65_accuracy: 0.1303 - re_lu_121_accuracy: 0.1806 - re_lu_177_accuracy: 0.4176 - re_lu_233_accuracy: 0.651 - ETA: 4:50  - ETA: 4:09 - loss: 694.6848 - re_l - ETA: 3:33 - loss: 693.2268 - re_lu_65_loss: 535.3857 - re_lu_121_loss - ETA: 3:02 - loss: 692.6188 - re_lu_65_loss: 535.2363 - re_lu_121_loss: 115.0728 - re_lu_177_loss: 30.5810 - re_lu_233_loss: 1 - ETA: 2:41 - loss: 693.1443 - re_lu_65_loss: 535.5358 - re_lu_121_loss: 115.1200 - re_lu_177_loss: 30.6053 - re_lu_233_loss: 11.8835 - re_lu_65_a - ETA: 2:24 - loss: 694. - ETA: 1:45 - loss: 691.3754 - re_lu_65_loss: 534.0364 - re_lu_121_loss: 114.9383 - re_lu_1\n",
      "Epoch 00041: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 422s 185ms/step - loss: 690.9752 - re_lu_65_loss: 533.6061 - re_lu_121_loss: 114.7450 - re_lu_177_loss: 30.6133 - re_lu_233_loss: 12.0113 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4174 - re_lu_233_accuracy: 0.6534 - val_loss: 11466.2100 - val_re_lu_65_loss: 2663.7361 - val_re_lu_121_loss: 2807.9304 - val_re_lu_177_loss: 2946.8438 - val_re_lu_233_loss: 3047.7051 - val_re_lu_65_accuracy: 0.1163 - val_re_lu_121_accuracy: 0.1444 - val_re_lu_177_accuracy: 0.3568 - val_re_lu_233_accuracy: 0.6302\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 42/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 691.6519 - re_lu_65_loss: 533.9290 - re_lu_121_loss: 114.7933 - re_lu_177_loss: 30.7454 - re_lu_233_loss: 12.1850 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4172 - re_lu_233_accuracy: 0.6535  - ETA: 3:46 - loss: 677.5864 - re_lu_65_loss: 524.2162 - re_lu_121_loss: 111.2151 - re_lu_177_ - ETA: 3:20 - loss: 679.9703 - re_lu_65_loss: 526.3142 - re_lu_12 - ETA: 4s - loss: 691.6373 - re_lu_65_loss: 533.9055 - re_lu_121_loss: 114.7219 - re_lu_177_loss: 30.7823 - re_lu_233_loss: 12.2285 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4171 - re\n",
      "Epoch 00042: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 691.6519 - re_lu_65_loss: 533.9290 - re_lu_121_loss: 114.7933 - re_lu_177_loss: 30.7454 - re_lu_233_loss: 12.1850 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1789 - re_lu_177_accuracy: 0.4172 - re_lu_233_accuracy: 0.6535 - val_loss: 11468.0820 - val_re_lu_65_loss: 2664.1816 - val_re_lu_121_loss: 2810.0754 - val_re_lu_177_loss: 2947.5105 - val_re_lu_233_loss: 3046.3054 - val_re_lu_65_accuracy: 0.1162 - val_re_lu_121_accuracy: 0.1453 - val_re_lu_177_accuracy: 0.3563 - val_re_lu_233_accuracy: 0.6331\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 43/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.2643 - re_lu_65_loss: 532.8428 - re_lu_121_loss: 114.3269 - re_lu_177_loss: 30.3539 - re_lu_233_loss: 11.7405 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4171 - re_lu_233_accuracy: 0.6538  - ETA: 2:14 - loss: 689.4907 - re_lu_65_loss: 533.2620 - re_lu_121_loss: 114.3903 - re_lu_177_loss: 30.2929 - re_lu_233_loss: 11.5455 - re_lu_65_accura - ETA: 1:57 - loss: 6\n",
      "Epoch 00043: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.2643 - re_lu_65_loss: 532.8428 - re_lu_121_loss: 114.3269 - re_lu_177_loss: 30.3539 - re_lu_233_loss: 11.7405 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4171 - re_lu_233_accuracy: 0.6538 - val_loss: 11469.4590 - val_re_lu_65_loss: 2663.4258 - val_re_lu_121_loss: 2809.8740 - val_re_lu_177_loss: 2948.2122 - val_re_lu_233_loss: 3047.9495 - val_re_lu_65_accuracy: 0.1171 - val_re_lu_121_accuracy: 0.1477 - val_re_lu_177_accuracy: 0.3539 - val_re_lu_233_accuracy: 0.6277\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 44/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.8641 - re_lu_65_loss: 532.4156 - re_lu_121_loss: 114.1291 - re_lu_177_loss: 30.4102 - re_lu_233_loss: 11.9091 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4170 - re_lu_233_accuracy: 0.6535  ETA: 29s - loss: 689.4312 - re_lu_65_loss: 532.5200 - re_lu_121_loss: 114.2895 - re_lu_177_loss: 30.6017 - re_lu_233_loss: 12.0196 - re_lu_65_accuracy: 0.1296 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0\n",
      "Epoch 00044: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 417s 183ms/step - loss: 688.8641 - re_lu_65_loss: 532.4156 - re_lu_121_loss: 114.1291 - re_lu_177_loss: 30.4102 - re_lu_233_loss: 11.9091 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4170 - re_lu_233_accuracy: 0.6535 - val_loss: 11465.7744 - val_re_lu_65_loss: 2662.8857 - val_re_lu_121_loss: 2808.3457 - val_re_lu_177_loss: 2946.5491 - val_re_lu_233_loss: 3047.9985 - val_re_lu_65_accuracy: 0.1167 - val_re_lu_121_accuracy: 0.1426 - val_re_lu_177_accuracy: 0.3538 - val_re_lu_233_accuracy: 0.6330\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 45/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.1224 - re_lu_65_loss: 532.9866 - re_lu_121_loss: 114.3075 - re_lu_177_loss: 30.1282 - re_lu_233_loss: 11.7002 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4177 - re_lu_233_accuracy: 0.6541  - ETA: 1:40 - loss: 688.2803 - re_lu_65_loss: 532.5435 - re_lu_121_loss: 114.1691 - re_lu_177_loss: 30.0619 - re_lu_233_loss: 11.5056 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1777 - re_lu_177_accuracy: 0.4175 - re_lu_233_accuracy: 0.655 - ETA: 1:40 - loss: 688.5569 - re_lu_65_loss: 532.7567 - re_lu_121_loss: 114.2297 - re_lu_177_loss: 30 - ETA: 24s - loss: \n",
      "Epoch 00045: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.1224 - re_lu_65_loss: 532.9866 - re_lu_121_loss: 114.3075 - re_lu_177_loss: 30.1282 - re_lu_233_loss: 11.7002 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4177 - re_lu_233_accuracy: 0.6541 - val_loss: 11466.9658 - val_re_lu_65_loss: 2663.8997 - val_re_lu_121_loss: 2808.2085 - val_re_lu_177_loss: 2947.2827 - val_re_lu_233_loss: 3047.5745 - val_re_lu_65_accuracy: 0.1183 - val_re_lu_121_accuracy: 0.1457 - val_re_lu_177_accuracy: 0.3537 - val_re_lu_233_accuracy: 0.6288\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 46/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.9436 - re_lu_65_loss: 532.7400 - re_lu_121_loss: 114.4332 - re_lu_177_loss: 30.5694 - re_lu_233_loss: 12.2000 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1787 - re_lu_177_accuracy: 0.4182 - re_lu_233_accuracy: 0.6539  - ETA: 4:40 - loss: 681.7805 - re_lu_65_loss: 527.5534 - re_lu_121_loss: 112.9548 - re_lu_177_loss: 29.6432 - re_lu_233_loss: 11.628 - ETA: 3:37 - loss: 682.6942 - re_lu_65_loss: 527.1301 - re_lu_121_loss: 113.0663 - re_lu_177_loss: 30.3590 - re_lu_233_loss: 12.1381 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1793 - re_lu_177_accuracy: 0.4181 - r - ETA: 3:33 - l - ETA: 2:53 - loss: 686.2334 - re_lu_65_loss - ETA: 2:17 - loss: 689.4940 - re_lu_65_loss: 532.3919 - re_lu_121_loss: 114.3968 - re - ETA: 1:49 - loss: 687.2933 - re_lu_65_loss: 530.8513 - re_lu_121_loss: 113.9385 - re_lu_177_loss: 30.3695 - re_lu_233_loss: 12.13 - ETA: 1:29 - loss: 690.4836 - re_ - ETA: 56s - loss: 692.2366 - re_lu_65_loss: 533.9114 - re_lu_121_loss: 115.0827 - re_lu_177_loss: 30.8494 - re_lu_233_loss: 12.3919 - re_lu_65_accuracy: 0.12 - ETA: 1s - loss: 689.5402 - re_lu_65_loss: 532.5139 - re_lu_121_loss: 114.2931 - re_lu_177_loss: 30.5514 - re_lu_233_loss: 12.1807 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1787 - re_lu_177_accuracy: 0.4181 - re_lu_233_accura\n",
      "Epoch 00046: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 689.9436 - re_lu_65_loss: 532.7400 - re_lu_121_loss: 114.4332 - re_lu_177_loss: 30.5694 - re_lu_233_loss: 12.2000 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1787 - re_lu_177_accuracy: 0.4182 - re_lu_233_accuracy: 0.6539 - val_loss: 11461.5488 - val_re_lu_65_loss: 2660.9941 - val_re_lu_121_loss: 2807.5508 - val_re_lu_177_loss: 2945.9753 - val_re_lu_233_loss: 3047.0251 - val_re_lu_65_accuracy: 0.1154 - val_re_lu_121_accuracy: 0.1390 - val_re_lu_177_accuracy: 0.3560 - val_re_lu_233_accuracy: 0.6376\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 47/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.9388 - re_lu_65_loss: 533.0099 - re_lu_121_loss: 114.5366 - re_lu_177_loss: 30.4517 - re_lu_233_loss: 11.9409 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4185 - re_lu_233_accuracy: 0.6539\n",
      "Epoch 00047: re_lu_233_loss did not improve from 11.67828\n",
      "2280/2280 [==============================] - 417s 183ms/step - loss: 689.9388 - re_lu_65_loss: 533.0099 - re_lu_121_loss: 114.5366 - re_lu_177_loss: 30.4517 - re_lu_233_loss: 11.9409 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4185 - re_lu_233_accuracy: 0.6539 - val_loss: 11470.3057 - val_re_lu_65_loss: 2661.7380 - val_re_lu_121_loss: 2809.9465 - val_re_lu_177_loss: 2948.8884 - val_re_lu_233_loss: 3049.7349 - val_re_lu_65_accuracy: 0.1167 - val_re_lu_121_accuracy: 0.1418 - val_re_lu_177_accuracy: 0.3553 - val_re_lu_233_accuracy: 0.6296\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 48/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.7789 - re_lu_65_loss: 532.8058 - re_lu_121_loss: 114.0806 - re_lu_177_loss: 30.2233 - re_lu_233_loss: 11.6686 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4179 - re_lu_233_accuracy: 0.6535  - ETA: 4:48 - loss: 694.4800 - re_lu_65_loss: 537.3239 - re_lu_121_loss: 115.1178 - re_lu_177_loss: 30.7506 - re_lu_233_loss: 11.2879 - re_l - ETA: 4:30 - loss: 698.0500 - re_lu_65_loss: 538.8885 - re_lu_121_loss: 116.3342 - re_lu_177_loss: 31.082 - ETA: 4:05 - loss: 697.0647 - re_lu_65_loss: 538.6565 - re_lu_121_loss: 11 - ETA: 3:36 - loss: 697.4290 - re_lu_65_loss: 537.9152 - re_lu_121_loss: 116.3210 - re_lu_177_loss: 31.1398 - re_lu_233_loss: 12.0530 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1785 - re_lu_177_accur - ETA: 3:29 - loss: 696.3000 - re_lu_65_loss: 537.3691 - re_lu_121_loss: 115.9402 - re_lu_177_loss: 31.0067 - re_lu_233_loss: 11.9839 - re_lu_65_accuracy: 0.1289 - re_lu_121_accuracy: 0.1784 - re_lu_177 - ETA: 1:12 - loss: 686.2564 - r\n",
      "Epoch 00048: re_lu_233_loss improved from 11.67828 to 11.66859, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 426s 187ms/step - loss: 688.7789 - re_lu_65_loss: 532.8058 - re_lu_121_loss: 114.0806 - re_lu_177_loss: 30.2233 - re_lu_233_loss: 11.6686 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4179 - re_lu_233_accuracy: 0.6535 - val_loss: 11470.8721 - val_re_lu_65_loss: 2665.4751 - val_re_lu_121_loss: 2810.2593 - val_re_lu_177_loss: 2947.5608 - val_re_lu_233_loss: 3047.5837 - val_re_lu_65_accuracy: 0.1174 - val_re_lu_121_accuracy: 0.1489 - val_re_lu_177_accuracy: 0.3527 - val_re_lu_233_accuracy: 0.6217\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 49/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 690.3636 - re_lu_65_loss: 533.2917 - re_lu_121_loss: 114.4311 - re_lu_177_loss: 30.6006 - re_lu_233_loss: 12.0404 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1778 - re_lu_177_accuracy: 0.4180 - re_lu_233_accuracy: 0.6545\n",
      "Epoch 00049: re_lu_233_loss did not improve from 11.66859\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 690.3636 - re_lu_65_loss: 533.2917 - re_lu_121_loss: 114.4311 - re_lu_177_loss: 30.6006 - re_lu_233_loss: 12.0404 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1778 - re_lu_177_accuracy: 0.4180 - re_lu_233_accuracy: 0.6545 - val_loss: 11472.9199 - val_re_lu_65_loss: 2665.1035 - val_re_lu_121_loss: 2810.8333 - val_re_lu_177_loss: 2948.4089 - val_re_lu_233_loss: 3048.5671 - val_re_lu_65_accuracy: 0.1181 - val_re_lu_121_accuracy: 0.1483 - val_re_lu_177_accuracy: 0.3503 - val_re_lu_233_accuracy: 0.6149\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 50/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.8788 - re_lu_65_loss: 532.5228 - re_lu_121_loss: 114.3155 - re_lu_177_loss: 30.3034 - re_lu_233_loss: 11.7365 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6544\n",
      "Epoch 00050: re_lu_233_loss did not improve from 11.66859\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 688.8788 - re_lu_65_loss: 532.5228 - re_lu_121_loss: 114.3155 - re_lu_177_loss: 30.3034 - re_lu_233_loss: 11.7365 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6544 - val_loss: 11473.7539 - val_re_lu_65_loss: 2663.7236 - val_re_lu_121_loss: 2811.2244 - val_re_lu_177_loss: 2949.3118 - val_re_lu_233_loss: 3049.4958 - val_re_lu_65_accuracy: 0.1169 - val_re_lu_121_accuracy: 0.1459 - val_re_lu_177_accuracy: 0.3534 - val_re_lu_233_accuracy: 0.6258\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 51/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.8656 - re_lu_65_loss: 531.9556 - re_lu_121_loss: 113.7503 - re_lu_177_loss: 30.3825 - re_lu_233_loss: 11.7771 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4184 - re_lu_233_accuracy: 0.6543  - ETA: 3:11 - loss: 688.5323 - re_lu_65_loss: 532.1232 - re_lu_121_loss: 113.9245 - re_lu_177_loss: 30.6968 - re_lu_233_loss: 11.7878 - re_lu_65_accuracy: 0.1290 - re_lu_121_accur - ETA: 1:34 - loss: 689.9860 - re_lu_65_loss: 533.6851 - re_lu_121_loss: 113.9234 - re_lu_177_loss: 30.5151 - re_lu_233_loss: 11.8622 - re_lu_65_accuracy: 0 - ETA: 1:18 - loss: 688.5656 - re_lu_65_loss: 532.7180 - re_lu_121_loss: 113.6956 - re_lu_177_loss: 30.3358 - re_lu_233_loss: 11.8161 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1780 - re_lu_177_accurac - ETA: 23s - loss: 688.1227 - re_lu_\n",
      "Epoch 00051: re_lu_233_loss did not improve from 11.66859\n",
      "2280/2280 [==============================] - 422s 185ms/step - loss: 687.8656 - re_lu_65_loss: 531.9556 - re_lu_121_loss: 113.7503 - re_lu_177_loss: 30.3825 - re_lu_233_loss: 11.7771 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4184 - re_lu_233_accuracy: 0.6543 - val_loss: 11471.0078 - val_re_lu_65_loss: 2662.9783 - val_re_lu_121_loss: 2809.9033 - val_re_lu_177_loss: 2949.4133 - val_re_lu_233_loss: 3048.7029 - val_re_lu_65_accuracy: 0.1166 - val_re_lu_121_accuracy: 0.1396 - val_re_lu_177_accuracy: 0.3540 - val_re_lu_233_accuracy: 0.6326\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 52/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.1503 - re_lu_65_loss: 532.0856 - re_lu_121_loss: 113.9644 - re_lu_177_loss: 30.2595 - re_lu_233_loss: 11.8409 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6540  - ETA: 5:06 - loss: 670.8678 - re_lu_65_loss: 522.0399 - re_lu_121_loss: 108.8192 - re_lu_177_loss: 28.8674 - re_lu_233_loss: 11.1408 - re_lu_65_ - ETA: 4:48 - loss: 671.9\n",
      "Epoch 00052: re_lu_233_loss did not improve from 11.66859\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 688.1503 - re_lu_65_loss: 532.0856 - re_lu_121_loss: 113.9644 - re_lu_177_loss: 30.2595 - re_lu_233_loss: 11.8409 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6540 - val_loss: 11474.6484 - val_re_lu_65_loss: 2665.6951 - val_re_lu_121_loss: 2809.8899 - val_re_lu_177_loss: 2949.6594 - val_re_lu_233_loss: 3049.3970 - val_re_lu_65_accuracy: 0.1151 - val_re_lu_121_accuracy: 0.1474 - val_re_lu_177_accuracy: 0.3567 - val_re_lu_233_accuracy: 0.6301\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 53/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.3333 - re_lu_65_loss: 532.8432 - re_lu_121_loss: 114.5241 - re_lu_177_loss: 30.1726 - re_lu_233_loss: 11.7931 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6543- ETA: 4s - loss: 689.3738 - re_lu_65_loss: 532.7282 - re_lu_121_loss: 114.6225 - re_lu_177_loss: 30.2000 - re_lu_233_loss: 11.8229 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1787 - re_lu_177_accuracy: 0.4183 -\n",
      "Epoch 00053: re_lu_233_loss did not improve from 11.66859\n",
      "2280/2280 [==============================] - 417s 183ms/step - loss: 689.3333 - re_lu_65_loss: 532.8432 - re_lu_121_loss: 114.5241 - re_lu_177_loss: 30.1726 - re_lu_233_loss: 11.7931 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6543 - val_loss: 11472.5273 - val_re_lu_65_loss: 2664.1692 - val_re_lu_121_loss: 2810.4707 - val_re_lu_177_loss: 2948.7520 - val_re_lu_233_loss: 3049.1357 - val_re_lu_65_accuracy: 0.1158 - val_re_lu_121_accuracy: 0.1470 - val_re_lu_177_accuracy: 0.3514 - val_re_lu_233_accuracy: 0.6227\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 54/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.1591 - re_lu_65_loss: 531.5403 - re_lu_121_loss: 113.6928 - re_lu_177_loss: 30.2670 - re_lu_233_loss: 11.6590 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6543  - ETA: 4:27 - loss: 683.6666 - re_lu_65_loss: 529.8340 - re_lu_121_loss: 113.0691 - re_lu_177_loss: 29.6479 - re_lu_233_loss: 11.1162 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1766 - re_lu_177_accura - ETA: 4:21 - loss: 683.4805 - re_lu_65_loss: 529.5439 - re_lu_121_loss: 112.7504 - re_lu_177_loss: 29.8424 - re_lu_233_loss: 11.3442 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1765 - re - ETA: 2:46 - loss: 682.7224 - re_lu_65_loss: 528.2244 - re_lu_121_loss: 112.9987 - re_lu_177_loss: 30.0870 - re_lu_233_loss: 11.4122 - re_lu_65_accu - ETA: 2:29 - loss: 681.8849 - re_lu_65_loss: 528.1957 - re_lu_121_loss: 112.5383 - re_lu_177_loss: 29.9003 - re_lu_233_loss: 11.2506 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1775 - re_lu_177_accuracy: 0.4185 - re_lu_233_ - ETA: 2:26 - loss: 682.2574 - re_lu_65_loss: 528.1890 - re_lu_121_loss: 112.6291 - re_lu_177_loss: 3\n",
      "Epoch 00054: re_lu_233_loss improved from 11.66859 to 11.65903, saving model to single_person_modelv6_new_model_structure.h5\n",
      "2280/2280 [==============================] - 427s 187ms/step - loss: 687.1591 - re_lu_65_loss: 531.5403 - re_lu_121_loss: 113.6928 - re_lu_177_loss: 30.2670 - re_lu_233_loss: 11.6590 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6543 - val_loss: 11470.1797 - val_re_lu_65_loss: 2662.8955 - val_re_lu_121_loss: 2810.9004 - val_re_lu_177_loss: 2948.0823 - val_re_lu_233_loss: 3048.3020 - val_re_lu_65_accuracy: 0.1171 - val_re_lu_121_accuracy: 0.1460 - val_re_lu_177_accuracy: 0.3569 - val_re_lu_233_accuracy: 0.6299\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 55/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.4361 - re_lu_65_loss: 532.4116 - re_lu_121_loss: 113.9766 - re_lu_177_loss: 30.3016 - re_lu_233_loss: 11.7466 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6545  - ETA: 5:17 - loss: 677.2698 - re_lu_65_loss: 525.3748 - re - ETA: 4:02 - loss: 686.4922 - re_lu_65_loss: 531.2231 - re_lu_121_loss: 113.2288 - re_lu_177_loss: 30.1016 - re_lu_233_loss: 11.9391 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4185 - r - ETA: 3:58 - loss: 685.8344 - re_lu_65_loss: 531.1606 - re_lu_121_l\n",
      "Epoch 00055: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 688.4361 - re_lu_65_loss: 532.4116 - re_lu_121_loss: 113.9766 - re_lu_177_loss: 30.3016 - re_lu_233_loss: 11.7466 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6545 - val_loss: 11471.4180 - val_re_lu_65_loss: 2663.4019 - val_re_lu_121_loss: 2809.6660 - val_re_lu_177_loss: 2948.7776 - val_re_lu_233_loss: 3049.5754 - val_re_lu_65_accuracy: 0.1149 - val_re_lu_121_accuracy: 0.1452 - val_re_lu_177_accuracy: 0.3545 - val_re_lu_233_accuracy: 0.6277\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 56/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.5746 - re_lu_65_loss: 532.2441 - re_lu_121_loss: 114.0198 - re_lu_177_loss: 30.4219 - re_lu_233_loss: 11.8889 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4184 - re_lu_233_accuracy: 0.6549- ETA: 4s - loss: 689.3601 - re_lu_65_loss: 532.7162 - re_lu_121_loss: 114.1772 - re_lu_177_loss: 30.5258 - re_lu_233_loss: 11.9407 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4184 -\n",
      "Epoch 00056: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 688.5746 - re_lu_65_loss: 532.2441 - re_lu_121_loss: 114.0198 - re_lu_177_loss: 30.4219 - re_lu_233_loss: 11.8889 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4184 - re_lu_233_accuracy: 0.6549 - val_loss: 11471.5664 - val_re_lu_65_loss: 2662.4717 - val_re_lu_121_loss: 2810.9958 - val_re_lu_177_loss: 2949.4363 - val_re_lu_233_loss: 3048.6621 - val_re_lu_65_accuracy: 0.1171 - val_re_lu_121_accuracy: 0.1451 - val_re_lu_177_accuracy: 0.3501 - val_re_lu_233_accuracy: 0.6305\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 57/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.0585 - re_lu_65_loss: 532.8832 - re_lu_121_loss: 113.9522 - re_lu_177_loss: 30.3286 - re_lu_233_loss: 11.8936 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4184 - re_lu_233_accuracy: 0.6542\n",
      "Epoch 00057: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.0585 - re_lu_65_loss: 532.8832 - re_lu_121_loss: 113.9522 - re_lu_177_loss: 30.3286 - re_lu_233_loss: 11.8936 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4184 - re_lu_233_accuracy: 0.6542 - val_loss: 11468.2197 - val_re_lu_65_loss: 2664.0840 - val_re_lu_121_loss: 2808.6440 - val_re_lu_177_loss: 2947.4695 - val_re_lu_233_loss: 3048.0212 - val_re_lu_65_accuracy: 0.1162 - val_re_lu_121_accuracy: 0.1420 - val_re_lu_177_accuracy: 0.3502 - val_re_lu_233_accuracy: 0.6286\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 58/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.7256 - re_lu_65_loss: 532.7312 - re_lu_121_loss: 114.3868 - re_lu_177_loss: 30.5886 - re_lu_233_loss: 12.0188 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6545\n",
      "Epoch 00058: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.7256 - re_lu_65_loss: 532.7312 - re_lu_121_loss: 114.3868 - re_lu_177_loss: 30.5886 - re_lu_233_loss: 12.0188 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6545 - val_loss: 11473.1436 - val_re_lu_65_loss: 2665.6182 - val_re_lu_121_loss: 2810.2791 - val_re_lu_177_loss: 2948.4709 - val_re_lu_233_loss: 3048.7686 - val_re_lu_65_accuracy: 0.1169 - val_re_lu_121_accuracy: 0.1482 - val_re_lu_177_accuracy: 0.3511 - val_re_lu_233_accuracy: 0.6211\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 59/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.3198 - re_lu_65_loss: 532.8047 - re_lu_121_loss: 113.9869 - re_lu_177_loss: 30.4290 - re_lu_233_loss: 12.0985 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6545- ETA: 7s - loss: 688.5272 - re_lu_65_loss: 532.4999 - re_lu_121_loss: 113.7248 - re_lu_177_loss: 30.3318 - re_lu_233_loss: 11.9701 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1782 - re_lu_177_ac\n",
      "Epoch 00059: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.3198 - re_lu_65_loss: 532.8047 - re_lu_121_loss: 113.9869 - re_lu_177_loss: 30.4290 - re_lu_233_loss: 12.0985 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6545 - val_loss: 11471.9727 - val_re_lu_65_loss: 2664.6965 - val_re_lu_121_loss: 2809.9812 - val_re_lu_177_loss: 2949.0527 - val_re_lu_233_loss: 3048.2393 - val_re_lu_65_accuracy: 0.1151 - val_re_lu_121_accuracy: 0.1456 - val_re_lu_177_accuracy: 0.3569 - val_re_lu_233_accuracy: 0.6301\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 60/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.6456 - re_lu_65_loss: 532.3143 - re_lu_121_loss: 113.5207 - re_lu_177_loss: 30.0753 - re_lu_233_loss: 11.7346 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6543  - ETA: 1:15 - loss: 688.8152 - re_lu_65_loss: 532.1070 - re_lu_121_loss: 114.1331 - re_lu_177_loss: 30.4725 - re_lu_233_loss: 12.1017 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1784 - re_lu_177_accuracy: 0. - ETA: 1:09 - loss: 687.9280 - re_lu_65_loss: 531.666\n",
      "Epoch 00060: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 687.6456 - re_lu_65_loss: 532.3143 - re_lu_121_loss: 113.5207 - re_lu_177_loss: 30.0753 - re_lu_233_loss: 11.7346 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6543 - val_loss: 11471.8086 - val_re_lu_65_loss: 2665.9290 - val_re_lu_121_loss: 2809.2378 - val_re_lu_177_loss: 2947.8503 - val_re_lu_233_loss: 3048.7944 - val_re_lu_65_accuracy: 0.1156 - val_re_lu_121_accuracy: 0.1434 - val_re_lu_177_accuracy: 0.3568 - val_re_lu_233_accuracy: 0.6296\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 61/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.7906 - re_lu_65_loss: 531.7449 - re_lu_121_loss: 113.7486 - re_lu_177_loss: 30.3817 - re_lu_233_loss: 11.9155 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6548  - ETA: 1:17 - loss: 688.9308 - re_lu_65_l - ETA: 50s - loss: 687.8191 - re_lu_65_loss: 531.5726 - re_lu_121_loss: 113.7230 - re_lu_177_loss - ETA: 37s  - ETA: 17s - loss: 687.5513 - re_lu_65_loss: 531.4934 - re_lu_121_loss: 113.7674 - re_lu_177_loss: 30\n",
      "Epoch 00061: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 421s 185ms/step - loss: 687.7906 - re_lu_65_loss: 531.7449 - re_lu_121_loss: 113.7486 - re_lu_177_loss: 30.3817 - re_lu_233_loss: 11.9155 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6548 - val_loss: 11475.5664 - val_re_lu_65_loss: 2664.3757 - val_re_lu_121_loss: 2812.2085 - val_re_lu_177_loss: 2949.8416 - val_re_lu_233_loss: 3049.1367 - val_re_lu_65_accuracy: 0.1176 - val_re_lu_121_accuracy: 0.1448 - val_re_lu_177_accuracy: 0.3548 - val_re_lu_233_accuracy: 0.6284\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 62/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.5267 - re_lu_65_loss: 532.4478 - re_lu_121_loss: 114.5114 - re_lu_177_loss: 30.5435 - re_lu_233_loss: 12.0244 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4186 - re_lu_233_accuracy: 0.6543  - ETA: 3:49 - loss: 686.0898 - re_lu_65_loss: 530.5464 - re_lu_121_loss: 113.5243 - re_lu_177_loss: 30.0516 - re_lu_233_loss: 11.9677 - re - ETA: 3:30 - loss: 688.1042 - re_lu_65_loss: 532.8800 - re_lu_121_loss: 113.5180 - re_lu_177_loss: 29.8709 - re_lu_233_loss: 11.8355 - re_lu_65_accuracy: 0. - ETA: 2:31 - loss:  - ETA: 1:52 - loss: 688.9619 - re_lu_65_loss: 532.2921 - re_lu_121_loss: 114.7093 - re_lu_177_loss: 30.1791 - re_lu_233_loss: 11.7816 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy:  - ETA: 1:41 - loss: 688.6413 - re_lu_65_loss: 532.2129 - re_lu_121_loss: 114.5864 - re_lu_177_loss: 30.1152 - re_lu_233_loss: 11.7271 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1786 - re_lu_177_accuracy: 0.4183 - - ETA: 1:36 - loss: 688.9002 - re_lu_65_loss: 532.5740 - re_lu_121_loss: 114.5652 - re_lu_177_loss: 30.0665 - re_lu_233_loss: 11.6949 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: - ETA: 1:25 - loss: 689.1102 - re_lu_65_loss: 532.5856 - re_lu_121_loss: 114.6055 - re_lu_177_loss: 30.1418 - re_lu_233_loss: 11.7777 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4183 - re_lu_233_accurac - ETA: 1:23 - loss: 688.6829 - re_lu_65_loss: 532.2774 - re_lu_121_loss: 114.5589 - re_lu_177_loss: 30.0969 - re_lu_233_loss: 11.7500 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4183 - r - ETA: 1:19 - loss: 687.4892 - re_lu_65_loss: 531.5021 -  - ETA: 10s - loss: 691.3134 - re_lu_65_loss: 533.6423 - re_lu_121_loss: 114.9779 - re_lu_177_loss: 30.6178 - re_lu_233_loss: 12.0758 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy:\n",
      "Epoch 00062: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.5267 - re_lu_65_loss: 532.4478 - re_lu_121_loss: 114.5114 - re_lu_177_loss: 30.5435 - re_lu_233_loss: 12.0244 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4186 - re_lu_233_accuracy: 0.6543 - val_loss: 11471.3154 - val_re_lu_65_loss: 2663.1433 - val_re_lu_121_loss: 2810.5515 - val_re_lu_177_loss: 2948.8711 - val_re_lu_233_loss: 3048.7490 - val_re_lu_65_accuracy: 0.1165 - val_re_lu_121_accuracy: 0.1434 - val_re_lu_177_accuracy: 0.3536 - val_re_lu_233_accuracy: 0.6302\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 63/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.8506 - re_lu_65_loss: 532.1430 - re_lu_121_loss: 113.8031 - re_lu_177_loss: 30.1771 - re_lu_233_loss: 11.7279 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4190 - re_lu_233_accuracy: 0.6548  ETA: 46s - loss: 688.8835 - re_lu_65 - ETA: 4s - loss: 688.4105 - re_lu_65_loss: 532.5592 - re_lu_121_loss: 113.9600 - re_lu_177_loss: 30.1650 - re_lu_233_loss: 11.7266 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4189 -\n",
      "Epoch 00063: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 687.8506 - re_lu_65_loss: 532.1430 - re_lu_121_loss: 113.8031 - re_lu_177_loss: 30.1771 - re_lu_233_loss: 11.7279 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4190 - re_lu_233_accuracy: 0.6548 - val_loss: 11471.2021 - val_re_lu_65_loss: 2663.1936 - val_re_lu_121_loss: 2810.4299 - val_re_lu_177_loss: 2948.8979 - val_re_lu_233_loss: 3048.6812 - val_re_lu_65_accuracy: 0.1173 - val_re_lu_121_accuracy: 0.1440 - val_re_lu_177_accuracy: 0.3549 - val_re_lu_233_accuracy: 0.6311\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 64/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.1917 - re_lu_65_loss: 531.9745 - re_lu_121_loss: 113.9937 - re_lu_177_loss: 30.4086 - re_lu_233_loss: 11.8143 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6551  ETA: 20s - loss: 688.0115 - re_lu_65_loss: 531.8719 - re_lu_121\n",
      "Epoch 00064: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 688.1917 - re_lu_65_loss: 531.9745 - re_lu_121_loss: 113.9937 - re_lu_177_loss: 30.4086 - re_lu_233_loss: 11.8143 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6551 - val_loss: 11472.5391 - val_re_lu_65_loss: 2664.2876 - val_re_lu_121_loss: 2811.2217 - val_re_lu_177_loss: 2948.6843 - val_re_lu_233_loss: 3048.3511 - val_re_lu_65_accuracy: 0.1186 - val_re_lu_121_accuracy: 0.1488 - val_re_lu_177_accuracy: 0.3548 - val_re_lu_233_accuracy: 0.6271\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 65/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.5094 - re_lu_65_loss: 532.2285 - re_lu_121_loss: 113.9586 - re_lu_177_loss: 30.3730 - re_lu_233_loss: 11.9496 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6546  - ETA: 4:36 - loss: 684.3488 - re_lu_65_loss: 527.3305 - re_lu_121_loss: 112.8665 - re_lu_177_loss: 31.2881 - re_lu_233_loss: 12.8637 - re_lu_65_accuracy: 0.1293 - re_lu_121_accur - ETA: 3:42 - loss: 681.1530 - re_lu_65_loss: 525.8702 - re_lu_121_loss: 111.7371 - re_lu_177_loss: 30.8813 - re_lu_233_loss - ETA: 3:21 - loss - ETA: 2:41 - lo\n",
      "Epoch 00065: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 417s 183ms/step - loss: 688.5094 - re_lu_65_loss: 532.2285 - re_lu_121_loss: 113.9586 - re_lu_177_loss: 30.3730 - re_lu_233_loss: 11.9496 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4183 - re_lu_233_accuracy: 0.6546 - val_loss: 11473.5586 - val_re_lu_65_loss: 2665.2910 - val_re_lu_121_loss: 2810.2522 - val_re_lu_177_loss: 2949.0271 - val_re_lu_233_loss: 3048.9875 - val_re_lu_65_accuracy: 0.1162 - val_re_lu_121_accuracy: 0.1436 - val_re_lu_177_accuracy: 0.3553 - val_re_lu_233_accuracy: 0.6329\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 66/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.1195 - re_lu_65_loss: 531.9111 - re_lu_121_loss: 113.9030 - re_lu_177_loss: 30.4137 - re_lu_233_loss: 11.8925 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6551  - ETA: 2:19 - loss: 684.1510 - re_lu_65_loss: 528.6382 - re_lu_121_loss: 113.0275 - re_lu_177_loss: 30.5353 - re_lu_233_loss: 11.9502 - re_lu_65\n",
      "Epoch 00066: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 417s 183ms/step - loss: 688.1195 - re_lu_65_loss: 531.9111 - re_lu_121_loss: 113.9030 - re_lu_177_loss: 30.4137 - re_lu_233_loss: 11.8925 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6551 - val_loss: 11469.4639 - val_re_lu_65_loss: 2662.6235 - val_re_lu_121_loss: 2809.3855 - val_re_lu_177_loss: 2948.4639 - val_re_lu_233_loss: 3048.9956 - val_re_lu_65_accuracy: 0.1161 - val_re_lu_121_accuracy: 0.1420 - val_re_lu_177_accuracy: 0.3541 - val_re_lu_233_accuracy: 0.6334\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 67/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.5784 - re_lu_65_loss: 531.4047 - re_lu_121_loss: 113.8336 - re_lu_177_loss: 30.3777 - re_lu_233_loss: 11.9612 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4185 - re_lu_233_accuracy: 0.6545\n",
      "Epoch 00067: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 687.5784 - re_lu_65_loss: 531.4047 - re_lu_121_loss: 113.8336 - re_lu_177_loss: 30.3777 - re_lu_233_loss: 11.9612 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4185 - re_lu_233_accuracy: 0.6545 - val_loss: 11474.4629 - val_re_lu_65_loss: 2664.8005 - val_re_lu_121_loss: 2811.7769 - val_re_lu_177_loss: 2949.4675 - val_re_lu_233_loss: 3048.4116 - val_re_lu_65_accuracy: 0.1157 - val_re_lu_121_accuracy: 0.1468 - val_re_lu_177_accuracy: 0.3487 - val_re_lu_233_accuracy: 0.6183\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 68/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.0864 - re_lu_65_loss: 532.3350 - re_lu_121_loss: 113.8932 - re_lu_177_loss: 30.1279 - re_lu_233_loss: 11.7301 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6540  - ETA: 4:00 - loss: 694.7297 - re_lu_65_loss: 536.2203 \n",
      "Epoch 00068: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 688.0864 - re_lu_65_loss: 532.3350 - re_lu_121_loss: 113.8932 - re_lu_177_loss: 30.1279 - re_lu_233_loss: 11.7301 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1782 - re_lu_177_accuracy: 0.4188 - re_lu_233_accuracy: 0.6540 - val_loss: 11470.5791 - val_re_lu_65_loss: 2664.1753 - val_re_lu_121_loss: 2810.4111 - val_re_lu_177_loss: 2947.8396 - val_re_lu_233_loss: 3048.1521 - val_re_lu_65_accuracy: 0.1171 - val_re_lu_121_accuracy: 0.1442 - val_re_lu_177_accuracy: 0.3554 - val_re_lu_233_accuracy: 0.6325\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 69/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.6964 - re_lu_65_loss: 531.8690 - re_lu_121_loss: 114.1891 - re_lu_177_loss: 30.5656 - re_lu_233_loss: 12.0714 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4186 - re_lu_233_accuracy: 0.6541\n",
      "Epoch 00069: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 688.6964 - re_lu_65_loss: 531.8690 - re_lu_121_loss: 114.1891 - re_lu_177_loss: 30.5656 - re_lu_233_loss: 12.0714 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4186 - re_lu_233_accuracy: 0.6541 - val_loss: 11471.0928 - val_re_lu_65_loss: 2663.7036 - val_re_lu_121_loss: 2809.4514 - val_re_lu_177_loss: 2948.9287 - val_re_lu_233_loss: 3049.0081 - val_re_lu_65_accuracy: 0.1170 - val_re_lu_121_accuracy: 0.1426 - val_re_lu_177_accuracy: 0.3503 - val_re_lu_233_accuracy: 0.6246\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 70/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.2730 - re_lu_65_loss: 532.1389 - re_lu_121_loss: 114.4362 - re_lu_177_loss: 30.6041 - re_lu_233_loss: 12.0945 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4189 - re_lu_233_accuracy: 0.6539  ETA: 26s - loss: 690.9729 - re_lu_65_loss: 532.9753 - re_lu_121_loss: 114.8682 - re_lu_177_loss: 30.8616 - re_lu_233_loss: 12.2680 - re_lu_65_accuracy: 0.1292 - re_l - ETA: 19s - loss: 691.0338 - re_lu_65_loss: 533.1523 - re_lu_121_loss: 114.8218 - \n",
      "Epoch 00070: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 418s 183ms/step - loss: 689.2730 - re_lu_65_loss: 532.1389 - re_lu_121_loss: 114.4362 - re_lu_177_loss: 30.6041 - re_lu_233_loss: 12.0945 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4189 - re_lu_233_accuracy: 0.6539 - val_loss: 11468.4111 - val_re_lu_65_loss: 2662.9158 - val_re_lu_121_loss: 2810.0305 - val_re_lu_177_loss: 2947.5872 - val_re_lu_233_loss: 3047.8831 - val_re_lu_65_accuracy: 0.1169 - val_re_lu_121_accuracy: 0.1440 - val_re_lu_177_accuracy: 0.3512 - val_re_lu_233_accuracy: 0.6287\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "Epoch 71/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 687.6708 - re_lu_65_loss: 531.8410 - re_lu_121_loss: 113.9153 - re_lu_177_loss: 30.2049 - re_lu_233_loss: 11.7090 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6545  - ETA: 6:02 - loss: 692.0503 - re_lu_65_loss: 535.8245 - re_lu_121_loss: 113.8598 - re_lu_177_loss: 30.5147 - re_lu_233_loss: 11.8514 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1788 - re_lu_177_accuracy: 0.4153 - re_lu_233_accuracy:  - ETA: 6:01 - loss: 694.1320 - re_lu_65_loss: 536.1155 - re_lu_121_loss: 114.8411 - re_lu_177_loss: 30.9359 - re_lu_233_loss: 12.2395 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1787 - re_lu_177_accuracy: 0.4149 - re_lu_233_ - ETA: 6:01 - loss: 695.5684 - re_lu_65_loss: 535.2960 - re_lu_121_loss: 115.4341 - re_lu_177_loss: 32\n",
      "Epoch 00071: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 425s 187ms/step - loss: 687.6708 - re_lu_65_loss: 531.8410 - re_lu_121_loss: 113.9153 - re_lu_177_loss: 30.2049 - re_lu_233_loss: 11.7090 - re_lu_65_accuracy: 0.1292 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6545 - val_loss: 11469.4971 - val_re_lu_65_loss: 2662.4861 - val_re_lu_121_loss: 2810.2361 - val_re_lu_177_loss: 2948.2004 - val_re_lu_233_loss: 3048.5679 - val_re_lu_65_accuracy: 0.1145 - val_re_lu_121_accuracy: 0.1419 - val_re_lu_177_accuracy: 0.3556 - val_re_lu_233_accuracy: 0.6362\n",
      "Learning rate:  1e-08\n",
      "Epoch 72/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 688.4006 - re_lu_65_loss: 531.9393 - re_lu_121_loss: 114.1242 - re_lu_177_loss: 30.3587 - re_lu_233_loss: 11.9784 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6543  - ETA: 5:59 - loss: 697.6629 - re_lu_65_loss: 540.6874 - r - ETA: 4:44 - loss: 690.8641 - re_lu_65_loss: 532.6019 - re_lu_121_loss: 113.9767 - re_lu_177 - ETA: 4:17 - loss:  - ETA: 3:38 - loss: 687.0560 - re_lu_65_loss: 531.2382 - re_lu_121_loss: 113.4825 - re_lu_177_loss: 30.1702 - re_lu_233_loss: 12.1649 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1780 - re_lu_177_accuracy: 0.4191 - re_lu_233_ - ETA: 3:35 - loss: 685.5807 - re_lu_65_loss: 530.1534 - re_lu_121_loss: 113.2351 - re_lu_177_loss: 30.0714 - re_lu_233_loss: 12.1206 - re_lu_65_accuracy: 0.1295 - re_lu_121_accuracy:  - ETA: 2:41 - loss: 687.5510 - re_lu_65_loss: 531.6924 - re_lu_121_loss: 113.6071 - re_lu_177_loss: 30.3094 - ETA: 2:17 - loss: 684.2441 - re_lu_65_loss: 529.0314 -  - ETA: 17s - loss: 687.5707 - re_lu_65_loss: 531.1182 - re_lu_121_loss: 113.9915 - re_lu_177_loss: 30.\n",
      "Epoch 00072: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 688.4006 - re_lu_65_loss: 531.9393 - re_lu_121_loss: 114.1242 - re_lu_177_loss: 30.3587 - re_lu_233_loss: 11.9784 - re_lu_65_accuracy: 0.1293 - re_lu_121_accuracy: 0.1785 - re_lu_177_accuracy: 0.4187 - re_lu_233_accuracy: 0.6543 - val_loss: 11471.8135 - val_re_lu_65_loss: 2666.0503 - val_re_lu_121_loss: 2809.7363 - val_re_lu_177_loss: 2948.3806 - val_re_lu_233_loss: 3047.6438 - val_re_lu_65_accuracy: 0.1185 - val_re_lu_121_accuracy: 0.1454 - val_re_lu_177_accuracy: 0.3520 - val_re_lu_233_accuracy: 0.6188\n",
      "Learning rate:  1e-08\n",
      "Epoch 73/100\n",
      "2280/2280 [==============================] - ETA: 0s - loss: 689.6184 - re_lu_65_loss: 532.8843 - re_lu_121_loss: 114.2226 - re_lu_177_loss: 30.4832 - re_lu_233_loss: 12.0281 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4190 - re_lu_233_accuracy: 0.6544  - ETA: 4:45 - loss: 689.6764 - re_lu_65_loss: 532.4235 - re_lu_121_loss: 114.1708 - re_lu_177_loss: 30.5039 - re - ETA: 4:22 - loss: 684.9353 - re_lu_65_loss: 529.3630 - - ETA: 3:49 - loss: 687.4014 - re_lu_65_loss: 530.6689 - re_lu_121_loss: 113.6026 - re_lu_177_loss: 30.5513 - re_lu_233_ - ETA: 3:27 - loss: 688.6023 - re_lu_65_loss: 532.1199 - re_lu_121_loss: 113.8172 - re_lu_177_loss: 30.3713 - re_lu_233_loss: 12.2933 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1778 - re_lu_177_accuracy: 0.419 - ETA: 3:22 - loss: 687.6042 - re_lu_65_loss: 531.5782 - re_lu_121_loss: 113.4569 - re_lu_177_loss: 30.2733 - re_lu_233_loss: 12.2951 - re_lu_65_accuracy: 0. - ETA: 3:06 - loss: 686.5201 - re_lu_65_loss: 530.6168 - re_lu_121_loss: 113.3616 - re_lu_177_loss: 30.2259 - re_lu_233_lo\n",
      "Epoch 00073: re_lu_233_loss did not improve from 11.65903\n",
      "2280/2280 [==============================] - 419s 184ms/step - loss: 689.6184 - re_lu_65_loss: 532.8843 - re_lu_121_loss: 114.2226 - re_lu_177_loss: 30.4832 - re_lu_233_loss: 12.0281 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1781 - re_lu_177_accuracy: 0.4190 - re_lu_233_accuracy: 0.6544 - val_loss: 11474.9160 - val_re_lu_65_loss: 2665.6265 - val_re_lu_121_loss: 2810.6318 - val_re_lu_177_loss: 2949.7131 - val_re_lu_233_loss: 3048.9385 - val_re_lu_65_accuracy: 0.1186 - val_re_lu_121_accuracy: 0.1474 - val_re_lu_177_accuracy: 0.3549 - val_re_lu_233_accuracy: 0.6203\n",
      "Learning rate:  1e-08\n",
      "Epoch 74/100\n",
      "1370/2280 [=================>............] - ETA: 2:37 - loss: 681.8353 - re_lu_65_loss: 528.7342 - re_lu_121_loss: 112.2729 - re_lu_177_loss: 29.4370 - re_lu_233_loss: 11.3901 - re_lu_65_accuracy: 0.1294 - re_lu_121_accuracy: 0.1797 - re_lu_177_accuracy: 0.4198 - re_lu_233_accuracy: 0.6535- ETA: 6:11 - loss: 659.4100 - re_lu_65_loss: 511.1187 - re_lu_121_loss: 108.6833 - re_lu_177_loss: 28.5744 - re_lu_233_loss: 11.0336 - re_lu_65_accuracy: 0.1294 - re_lu_121_acc - ETA: 6:00 - loss: 669.1610 - re_lu_65_loss: 520.1618 - re_lu_121_loss: 110.4934 - re_lu_177_loss: 27.7615 - re_lu_233_loss: 10.7443 - r - ETA: 5:42 - loss: 667.8292 - re_lu_65_loss: 518.9576 - re_lu_121_loss: 109.0319 - re_lu_177_loss: 28.2824 - re_lu_233_loss: 11.5572 - re_lu_65_accuracy: 0.1284 - re_lu_121_accuracy: 0.1779 - re_lu_177_accuracy: 0.4185 - re_lu_2 - ETA: 5:38 - loss: 669.5567 - re_lu_65_loss: 520.4760 - re_lu_121_loss: 109.4265 - re_lu_ - ETA: 5:12 - loss: 687.4492 - re_lu_65_loss: 531.4602 - re_lu_121_loss: 114.0158 - - ETA: 4:44 - loss: 686.4659 - re_lu_65_loss: 532.1656 - re_lu_121_loss: 112.8971 - re_lu_177_loss: 29.6338 - re_lu_233_loss: 11.7688 - re_lu_65_accuracy: 0.1287 - re_lu_121_accuracy: 0.1783 - re_lu_177_accuracy: 0.4201 - re_lu_233_accura - ETA: 4:42 - loss: 686.7637 - re_lu_65_loss: 532.7957 - re_lu_121_lo - ETA: 4:11 - loss: 687.1502 - re_lu_65_loss: 532.3937 - re_lu_121_loss: 113.1524 - re_lu_177_loss: 29.7438 - re_lu_233_loss: 11.8598 - re_lu_65_accuracy: 0.1290 - re_lu_121_accuracy: 0.1 - ETA: 4:01 - loss: 686.6031 - re_lu_65_loss: 532.4017 - re_lu_121_loss: 112.9182 - re_lu_177_loss: 29.6049 - re_lu_233_loss: 11.6776 - re_lu_65_accuracy: 0.1291 - re_lu_121_accuracy: 0.1797 - re_lu_177_accuracy: 0.4202 -  - ETA: 3:56 - loss: 685.3928 - re_lu_65"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=4, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
