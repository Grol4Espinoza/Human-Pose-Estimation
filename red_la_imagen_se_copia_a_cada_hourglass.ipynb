{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!python\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from operator import itemgetter\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import (\n",
    "                                    Dense,\n",
    "                                    Conv2D, \n",
    "                                    BatchNormalization, \n",
    "                                    ReLU, \n",
    "                                    Add,\n",
    "                                    Input,\n",
    "                                    MaxPooling2D,\n",
    "                                    UpSampling2D,\n",
    "                                    )\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from math import exp\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de Datos/Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################\n",
    "def generate_dataset_obj(obj):\n",
    "    if type(obj) == np.ndarray:\n",
    "        dim = obj.shape[0]\n",
    "        if dim == 1:\n",
    "            ret = generate_dataset_obj(obj[0])             \n",
    "        else:\n",
    "            ret = []\n",
    "            for i in range(dim):\n",
    "                ret.append(generate_dataset_obj(obj[i]))                \n",
    "\n",
    "    elif type(obj) == scipy.io.matlab.mio5_params.mat_struct:\n",
    "        ret = {}\n",
    "        for field_name in obj._fieldnames:            \n",
    "            field = generate_dataset_obj(obj.__dict__[field_name])\n",
    "            if field_name in must_be_list_fields:\n",
    "                field = [field]\n",
    "                ret[field_name] = field\n",
    "\n",
    "    else:\n",
    "        ret = obj\n",
    "\n",
    "    return ret\n",
    "########################################################################################################################################################\n",
    "def generate_dataset_obj(obj):\n",
    "    if type(obj) == np.ndarray:\n",
    "        dim = obj.shape[0]\n",
    "        if dim == 1:\n",
    "            ret = generate_dataset_obj(obj[0])             \n",
    "        else:\n",
    "            ret = []\n",
    "            for i in range(dim):\n",
    "                ret.append(generate_dataset_obj(obj[i]))                \n",
    "\n",
    "    elif type(obj) == scipy.io.matlab.mio5_params.mat_struct:\n",
    "        ret = {}\n",
    "        for field_name in obj._fieldnames:            \n",
    "            field = generate_dataset_obj(obj.__dict__[field_name])\n",
    "            if field_name in must_be_list_fields:\n",
    "                field = [field]\n",
    "                ret[field_name] = field\n",
    "\n",
    "    else:\n",
    "        ret = obj\n",
    "\n",
    "    return ret\n",
    "\n",
    "########################################################################################################################################################\n",
    "def print_dataset_obj(obj, depth = 0, maxIterInArray = 20):\n",
    "    prefix = \"  \"*depth\n",
    "    if type(obj) == dict:\n",
    "        for key in obj.keys():\n",
    "            print(\"{}{}\".format(prefix, key))\n",
    "            print_dataset_obj(obj[key], depth + 1)\n",
    "    elif type(obj) == list:\n",
    "        for i, value in enumerate(obj):\n",
    "            if i >= maxIterInArray:\n",
    "                break\n",
    "            print(\"{}{}\".format(prefix, i))\n",
    "            print_dataset_obj(value, depth + 1)\n",
    "    else:\n",
    "        print(\"{}{}\".format(prefix, obj))\n",
    "########################################################################################################################################################\n",
    "def return_image_joints(name,data):\n",
    "    for item in data: # guardar coordenadas de los joints\n",
    "        if item[0] == name:\n",
    "            #print(item[1]) \n",
    "            return item[1]\n",
    "########################################################################################################################################################\n",
    "rightconnections = [\n",
    "                    (0,1),(1,2),(3,4),(4,5),(2,6),\n",
    "                    (3,6),(6,7),(7,8),(8,9),(10,11),\n",
    "                    (11,12),(12,7),(13,7),(13,14),(14,15)\n",
    "                   ]\n",
    "size_img_x = 256\n",
    "size_img_y = 256\n",
    "def draw_img_joints(file_name, data, resize = False ):    \n",
    "    # Load image\n",
    "    #img = cv2.imread(Path_To_Single_Person_Images + \"/\" + file_name,1)  \n",
    "    img = image.load_img(Path_To_Single_Person_Images + \"/\" + file_name)\n",
    "    img = image.img_to_array(img) \n",
    "    img = img/255\n",
    "    if resize:\n",
    "        img = np.float32(tf.image.resize(img,(size_img_x, size_img_y)))  \n",
    "    pts = return_image_joints(file_name, data)        \n",
    "    #plt.imshow(img)  \n",
    "    X = [x[0] for x in pts]\n",
    "    Y = [y[1] for y in pts]\n",
    "    X = [int(x) for x in X]\n",
    "    Y = [int(y) for y in Y]\n",
    "    \n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if (i,j) in rightconnections:\n",
    "                if X[i]>0 and X[j]>0 and Y[i]>0 and Y[j]>0:\n",
    "                    img = cv2.line(img,(X[i],Y[i]),(X[j],Y[j]),(1,0,0),5)\n",
    "                    plt.scatter(X[i], Y[i], marker=\"o\", color=\"red\", s=20)\n",
    "                    plt.scatter(X[j], Y[j], marker=\"o\", color=\"red\", s=20)\n",
    "                    \n",
    "    plt.imshow(img)\n",
    "########################################################################################################################################################\n",
    "def load_image(train_data, a, b):\n",
    "    train = np.asarray(train_data[a:b])\n",
    "    train_image = np.zeros((b-a,size_img_x,size_img_y,3))\n",
    "    for i in tqdm(range(a,b)):\n",
    "        name_img = train[i][0]\n",
    "        img = image.load_img(Path_To_Single_Person_Images + '/' + name_img)\n",
    "        img = image.img_to_array(img)\n",
    "        img_x = img.shape[1]\n",
    "        img_y = img.shape[0]\n",
    "        scala_x = img_x / size_img_x\n",
    "        scala_y = img_y / size_img_y\n",
    "        for j in range(len(train[i][1])): # escala los puntos clave\n",
    "            train[i][1][j] = np.array([train[i][1][j][0] / scala_x, train[i][1][j][1] / scala_y])            \n",
    "        img = tf.image.resize(img,(size_img_x, size_img_y))        \n",
    "        img = img/255\n",
    "        train_image[i] = img\n",
    "    return train_image, train\n",
    "########################################################################################################################################################\n",
    "def MakeHeatmap(x, y, width, height, show = False):\n",
    "    # Probability as a function of distance from the center derived\n",
    "    # from a gaussian distribution with mean = 0 and stdv = 1\n",
    "    scaledGaussian = lambda x : exp(-(1/2)*(x**2))\n",
    "\n",
    "    imgSize = (height, width)\n",
    "    center_x = x\n",
    "    center_y = y\n",
    "\n",
    "    isotropicGrayscaleImage = np.zeros((imgSize[0],imgSize[1]),np.uint8)\n",
    "    \n",
    "    if center_x != -1 and center_y != -1:\n",
    "        for i in range(imgSize[0]):\n",
    "            for j in range(imgSize[1]):\n",
    "\n",
    "                # find euclidian distance from center of image (x,y) \n",
    "                # and scale it to range of 0 to 2.5 as scaled Gaussian\n",
    "                # returns highest probability for x=0 and approximately\n",
    "                # zero probability for x > 2.5\n",
    "\n",
    "                distanceFromCenter = np.linalg.norm(np.array([i-center_y,j-center_x]))\n",
    "                #distanceFromCenter = 18*distanceFromCenter/(imgSize/2)\n",
    "                scaledGaussianProb = scaledGaussian(distanceFromCenter)\n",
    "                isotropicGrayscaleImage[i,j] = np.clip(scaledGaussianProb*255,0,255)   \n",
    "\n",
    "        return isotropicGrayscaleImage\n",
    "    else: \n",
    "        return isotropicGrayscaleImage\n",
    "########################################################################################################################################################    \n",
    "def Joints_heatmaps(lista_de_joints, heatmap_size_x, heatmap_size_y, num_heatmaps = 16, show = False):\n",
    "    heatmaps = np.zeros((16,64,64))\n",
    "    for i in range(num_heatmaps):\n",
    "        x, y = lista_de_joints[i] \n",
    "        x = x / 4 # entre 4 por que el array es de 256x256\n",
    "        y = y / 4 # entre 4 por que el array es de 256x256\n",
    "        heatmaps[i] = MakeHeatmap(x, y, heatmap_size_x, heatmap_size_y)\n",
    "    if show:\n",
    "        plotImages(heatmaps, num_heatmaps)\n",
    "    return heatmaps\n",
    "########################################################################################################################################################        \n",
    "def plotImages(images_arr, num_images):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "########################################################################################################################################################    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos, Generación de heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divimos la data para ingresarla al modelo,\n",
    "if os.path.isfile('X_train.npy') and os.path.isfile('X_test.npy') and os.path.isfile('y_train.npy') and os.path.isfile('y_test.npy'):    \n",
    "    #Primero comprobamos si existen ya datos para usar en el modelo, si hay los mapeamos, no se cargan a la ram, se leen desde disco \n",
    "    X_train = np.load('X_train.npy', mmap_mode='r')\n",
    "    X_test = np.load('X_test.npy', mmap_mode='r')\n",
    "    y_train = np.load('y_train.npy', mmap_mode='r')\n",
    "    y_test = np.load('y_test.npy', mmap_mode='r')  \n",
    "else:      \n",
    "    # si no existen entonces iniciamos el preprocesado:   \n",
    "    ########################################################################################################################################################\n",
    "    if os.path.isfile('lista_de_imagenes.npy') and os.path.isfile('lista_de_heatmaps.npy'):    \n",
    "        #Ahora cargamos las imagenes y sus heatmaps\n",
    "        lista_de_heatmaps = np.load('lista_de_heatmaps.npy')  \n",
    "        lista_de_imagenes = np.load('lista_de_imagenes.npy')    \n",
    "    else: \n",
    "        ########################################################################################################################################################\n",
    "        #darle formato de diccionario\n",
    "        matph = './mpii.mat'\n",
    "        decoded1 = loadmat(matph, struct_as_record=False)[\"RELEASE\"]\n",
    "        must_be_list_fields = [\"annolist\",\"image\",\"name\", \"annorect\", \"scale\", \"x\", \"y\", \"annopoints\", \"point\", \"id\"]\n",
    "        # Convert to dict\n",
    "        dataset_obj = generate_dataset_obj(decoded1)\n",
    "        # Print it out\n",
    "        #print_dataset_obj(dataset_obj)\n",
    "        len(dataset_obj['annolist'][0])\n",
    "        #solo queremos la información en 'annolist'\n",
    "        dataset = dataset_obj['annolist'][0]\n",
    "        ########################################################################################################################################################\n",
    "        #guardamos solo informacion de las imagenes que tienen solo una persona\n",
    "        train_data = []\n",
    "        for i in range(len(dataset)):\n",
    "            if \"annopoints\" in dataset[i]['annorect'][0]:     \n",
    "                name = dataset[i]['image'][0]['name'][0]\n",
    "                tupla = [] \n",
    "                for j in range(16):     #ordena los puntos de articulaciones del id = 0 al id = 15       \n",
    "                    try:\n",
    "                        x = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['x'][0]\n",
    "                    except:\n",
    "                        x = -1\n",
    "                    try:\n",
    "                        y = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['y'][0]\n",
    "                    except:\n",
    "                        y = -1\n",
    "                    try:\n",
    "                        id = dataset[i]['annorect'][0]['annopoints'][0]['point'][0][j]['id'][0]\n",
    "                    except:\n",
    "                        id = -1          \n",
    "                    tupla.append((x,y,id))\n",
    "                tupla = sorted(tupla, key = itemgetter(2)) # esto lo ordena\n",
    "                for j in range(len(tupla)):   #quita id de las tuplas,\n",
    "                    tupla[j] = tupla[j][:2]\n",
    "                #pasa de tupla a array\n",
    "                tupla = np.asarray(tupla)        \n",
    "                train_data.append((name,tupla))\n",
    "        #Creamos un array para guardar los nombres        \n",
    "        names = []\n",
    "        for item in train_data:#guardar nombres de las imagenes que voy a usar en \"name\"\n",
    "            names.append(item[0])\n",
    "        ########################################################################################################################################################\n",
    "        #Crear Carpeta para guardar imagenes del dataset\n",
    "        Path_To_Raw_Images = 'DataSet/mpii_human_pose_v1_images'\n",
    "        Path_To_Single_Person_Images = 'DataSet/mpii_human_pose_v1_images/SinglePersonImagesWithData'\n",
    "        os.chdir(Path_To_Raw_Images)\n",
    "\n",
    "        if os.path.isdir('SinglePersonImagesWithData') is False:\n",
    "            os.makedirs('SinglePersonImagesWithData')\n",
    "            for images in names:\n",
    "                shutil.move(images, 'SinglePersonImagesWithData')\n",
    "\n",
    "        os.chdir('../../')\n",
    "\n",
    "        #Demostración dibujar joints en imagenes con data\n",
    "        #draw_img_joints('060111501.jpg',train_data)\n",
    "        ########################################################################################################################################################\n",
    "        #Ahora cargamos las imagenes\n",
    "        lista_de_imagenes, lista_de_joints = load_image(train_data,0,5000)\n",
    "        np.save('lista_de_imagenes', lista_de_imagenes)\n",
    "        ########################################################################################################################################################\n",
    "        #Ahora creamos los heatmaps para lista_de_imagenes:\n",
    "        heatmap_size_x = 64\n",
    "        heatmap_size_y = 64 \n",
    "        #dibujo_test_heatmaps = Joints_heatmaps(lista_de_joints[0][1], heatmap_size_x, heatmap_size_y, show = False)\n",
    "        #creamos los heatmaps de nuestra data\n",
    "        lista_de_heatmaps = np.zeros((5000,64,64,16))\n",
    "        for i in tqdm(range(lista_de_joints.shape[0])):\n",
    "            joints = return_image_joints(lista_de_joints[i][0], lista_de_joints)\n",
    "            lista_de_heatmaps[i] = np.moveaxis(Joints_heatmaps(joints, heatmap_size_x, heatmap_size_y), 0, -1) # change shape from 16x64x64 to 64x64x16\n",
    "        #guardamos el array    \n",
    "        np.save('lista_de_heatmaps', lista_de_heatmaps)\n",
    "        #plotImages(lista_de_heatmaps[67], 16)\n",
    "    ######################################################################################################################################################## \n",
    "    X_train, X_test, y_train, y_test = train_test_split(lista_de_imagenes, lista_de_heatmaps, random_state=7, test_size=0.2)\n",
    "    #save \n",
    "    np.save('X_train', X_train)\n",
    "    np.save('X_test', X_test)\n",
    "    np.save('y_train', y_train)\n",
    "    np.save('y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(inputs, \n",
    "           filters, \n",
    "           kernel_size = 1,\n",
    "           strides = 1,\n",
    "           padding = 'same',\n",
    "           kernel_initializer = 'he_normal',\n",
    "           activation = True,\n",
    "           batch_normalization = True,\n",
    "           name = \"conv\"):\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,\n",
    "            use_bias=False, kernel_initializer=kernel_initializer)(inputs)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = ReLU()(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquitectura ResNetV2 de cuello de botella\n",
    "def ResNetV2(inputs, filters, strides = 1, lift_channels = False, name = 'bloque'):\n",
    "    \n",
    "    res = inputs\n",
    "    #incrementa el número de canales si es necesario\n",
    "    if lift_channels:\n",
    "        res = conv2D(\n",
    "            inputs,\n",
    "            filters,\n",
    "            activation = False,\n",
    "            batch_normalization = False)\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    #conv de tamaño 1x1\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters/2)\n",
    "    \n",
    "    #conv de tamaño 3x3\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters/2,\n",
    "        kernel_size = 3)\n",
    "    \n",
    "    #conv de tamaño 1x1\n",
    "    x = conv2D(\n",
    "        x,\n",
    "        filters = filters,\n",
    "        activation = False,\n",
    "        batch_normalization = False)\n",
    "    \n",
    "    x = Add()([res,x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassUnit(inputs, depth, filters, resnet_per_block, name = 'hourglass_'):    \n",
    "    \n",
    "    #Capas \"superiores\"\n",
    "    up_1 = ResNetV2(inputs,filters)\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        up_1 = ResNetV2(up_1, filters)\n",
    "    \n",
    "    #Capas \"inferiores\"\n",
    "    #Reducir resolución\n",
    "    low_1 = MaxPooling2D(pool_size = 2, strides = 2)(inputs)\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        low_1 = ResNetV2(low_1, filters)\n",
    "    \n",
    "    low_2 = low_1\n",
    "    if depth > 1 : \n",
    "        low_2 = HourglassUnit(low_1, depth-1, filters, resnet_per_block)\n",
    "    else:\n",
    "        low_2 = ResNetV2(low_2, filters)\n",
    "    \n",
    "    low_3 = low_2\n",
    "    \n",
    "    for i in range(resnet_per_block):\n",
    "        low_3 = ResNetV2(low_3, filters)\n",
    "    \n",
    "    #Aumentar resolución\n",
    "    up_2 = UpSampling2DUpSampling2D()(low_3)\n",
    "    \n",
    "    return Add()([up_1,up_2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassNetwork(input_shape = (256,256,3), stacks = 8, resnet_per_block = 3, heatmaps = 16):\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    #la data llega en formato 256x256x3, la pasamos a 64x64x256\n",
    "    #preprocessing\n",
    "    #amplia canales a 64\n",
    "    x = conv2D(\n",
    "        inputs,\n",
    "        filters = 64,\n",
    "        kernel_size = 7,\n",
    "        strides = 2)\n",
    "    #amplia canales de 64 a 128 \n",
    "    x = ResNetV2(x, filters = 128, lift_channels = True)\n",
    "    x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "    x = ResNetV2(x, filters = 128)\n",
    "    #amplia canales de 64 a 128\n",
    "    x = ResNetV2(x, filters = 256, lift_channels = True)\n",
    "    skip = x\n",
    "    y_heatmaps = []\n",
    "    \n",
    "    for i in range(stacks):\n",
    "        x = HourglassUnit(x, depth = 4, filters = 256, resnet_per_block = resnet_per_block)\n",
    "        \n",
    "        x = ResNetV2(x, filters = 256)\n",
    "        \n",
    "        #prediccion de 256 canales \n",
    "        x = conv2D(x, filters = 256)\n",
    "        \n",
    "        #prediccion temporal de heatmaps\n",
    "        y = conv2D(x, filters = heatmaps)\n",
    "        #agregamos el resultado temportal al array de resultados para la supervision intermedia\n",
    "        y_heatmaps.append(y)\n",
    "        \n",
    "        #ahora regresamos el tensor y al orden de 256 canales si es que no es el ultimo output\n",
    "        if i < stacks - 1:\n",
    "            y_recovery1 = conv2D(x, filters = 256, activation = False, batch_normalization = False)\n",
    "            y_recovery2 = conv2D(y, filters = 256, activation = False, batch_normalization = False)\n",
    "            x = Add()([skip, y_recovery1, y_recovery2])\n",
    "    #print(y_heatmaps)\n",
    "    return Model(inputs = inputs, outputs = y_heatmaps, name = 'HourglassNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasa de decrecimiento del learning rate por numero de epoch\n",
    "def lr_schedule(epoch): #tome esto de resnet.ipynb\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 5e-4\n",
    "    if epoch > 180:\n",
    "        lr *= 5e-4\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr \n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('single_person_model.h5'):\n",
    "    # verificamos si hay algun punto de guardado del modelo\n",
    "    model = load_model('single_person_model.h5')\n",
    "else:    \n",
    "    # si no lo hay creamos el modelo desde cero\n",
    "    model = HourglassNetwork(stacks = 4, resnet_per_block = 1)\n",
    "    rms = RMSprop(lr=lr_schedule(0))\n",
    "    model.compile(optimizer=rms, loss=mean_squared_error, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos puntos de guardado del modelo para que guarde solo la mejor version durante el entrenamiento:\n",
    "checkpoint = ModelCheckpoint('single_person_model.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# modificaciones al learning rate per epoch:\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "# modificaciones al learning rate por estancamiento:\n",
    "lr_reducer = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor = 0.1,\n",
    "                               patience = 15,\n",
    "                               min_lr = 0)\n",
    "# agregamos estas funciones al callback_list\n",
    "callbacks_list = [checkpoint, lr_scheduler, lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0005\n",
      "Epoch 1/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 77.8656 - re_lu_65_loss: 30.6317 - re_lu_121_loss: 18.7400 - re_lu_177_loss: 15.1624 - re_lu_233_loss: 13.3315 - re_lu_65_accuracy: 0.1471 - re_lu_121_accuracy: 0.2804 - re_lu_177_accuracy: 0.3496 - re_lu_233_accuracy: 0.3581   ETA: 2:49 - loss: 79.1859 - re_lu_65_lo - ETA: 2:40 - loss: 78.2329 - re_lu_65_loss: 30.9741 - re_lu_121_loss: 18.9868 - re_lu_177_loss: 15.1609 - re_lu_233_loss: 13.1110 - re_lu_65_accuracy: 0.1477 - re_lu_121_accuracy - ETA: 2:34 - loss: 78.4217 - re_lu_6 - ETA: 2:16 - loss: 77.0065 - re_lu_65_loss: 30.6534 - re_lu_121_loss: 18.5838 - re_lu_177_loss: 14.8657 - re_lu_233_loss: 12.9036 - re_lu_65_accuracy: 0.1482 - re_lu_ - ETA: 2:09 - loss: 77.1296 - re_lu_65_loss: 30.6881 - re_lu_121_loss: 18.5976 - re_lu_177_loss: 14.8901 - re_lu_233_loss: 12.9538 - re_lu_65_accuracy: 0.1466 - re_lu_121_accuracy: 0.2837 - re_lu_177_accuracy: 0.3449 - re_lu_233_accuracy - ETA: 2:08 - loss: 76.9882 - re_lu_65_loss: 30.6756 - re_lu_121_loss: 18.5618 - re_lu_177_loss: 14.8441 - re_lu_233_loss: 12.9067 - re_lu_65_accuracy: 0.1466 - re_lu_121_accuracy: 0.2830 - r - ETA: 2:03 - loss: 76.7876 - re_lu_65_loss: 30.6096 - re_lu_121_loss: 18.5 - ETA: 1:47 - loss: 76.8227 - re_lu_65_loss: 30.5952 - re_lu_121_loss: 18.5128 - re_lu_177_loss: 14.8149 - re_lu_233_loss: 12.8998 - re_lu_65_accuracy: 0.1432 - re_lu_121_accuracy: 0.2809 - re_lu_177_a - ETA: 1:43 - loss: 76.6266 - re_lu_65_loss: 30.5558 - re_lu_121_loss: 18.4594 - re_lu_177_loss: 14.7605 - re_lu_233_loss: 12.8510 - re_lu_65_accuracy: 0.1445 - re_lu_121_accuracy: 0.2839 - - ETA: 1:38 - loss: 76.765 - ETA: 53s - loss: 77.1521 - re_lu_65_loss: 30.5751 - re_lu_121_loss: 18.5831 - re_lu_177_loss: 14.9258 - re_lu_233_loss: 13.0681 - re_lu_65_accuracy: 0.1462 - re_lu_121_accuracy: 0.2755 - re_lu_177_accuracy: 0.3563 - re_lu_23 - ETA: 49s - loss: 77.2630 - re_lu_65_loss: 30.5765 - re_lu_121_loss: 18.6058 - re_lu_177_loss: - ETA: 23s - loss: 77.5939 - re_lu_65_loss: 30.6075 - re_lu_121_loss: 18.6718 - re_lu_177_loss: 1 - ETA: 3s - loss: 77.8037 - re_lu_65_loss: 30.6195 - re_lu_121_loss: 18.7276 - re_lu_177_loss: 15.1450 - re_lu_233_loss: 13.3116 - re_lu_65_accuracy: 0.1467 - re_lu_121_accuracy: 0.2800 - re_lu_177_accuracy: 0.3496 - re_lu_233_accuracy: 0. - ETA: 2s - loss: 77.7839 - re_lu_65_loss: 30.6168 - re_lu_121_loss: 18.7219 - re_lu_177_loss: 15.1390 - re_lu_233_loss: 13.3061 - re_lu_65_accuracy: 0.1467 - re_lu_121_accuracy: 0.2801 - re_lu_177_accuracy: 0.3\n",
      "Epoch 00001: loss improved from inf to 77.86562, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 77.8656 - re_lu_65_loss: 30.6317 - re_lu_121_loss: 18.7400 - re_lu_177_loss: 15.1624 - re_lu_233_loss: 13.3315 - re_lu_65_accuracy: 0.1471 - re_lu_121_accuracy: 0.2804 - re_lu_177_accuracy: 0.3496 - re_lu_233_accuracy: 0.3581 - val_loss: 150.5858 - val_re_lu_65_loss: 38.9173 - val_re_lu_121_loss: 36.9059 - val_re_lu_177_loss: 37.2852 - val_re_lu_233_loss: 37.4774 - val_re_lu_65_accuracy: 0.1671 - val_re_lu_121_accuracy: 0.2884 - val_re_lu_177_accuracy: 0.3239 - val_re_lu_233_accuracy: 0.2999\n",
      "Learning rate:  0.0005\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 75.1760 - re_lu_65_loss: 30.1625 - re_lu_121_loss: 18.0674 - re_lu_177_loss: 14.4118 - re_lu_233_loss: 12.5343 - re_lu_65_accuracy: 0.1592 - re_lu_121_accuracy: 0.2888 - re_lu_177_accuracy: 0.3599 - re_lu_233_accuracy: 0.3803   ETA: 1:03 - loss: 74.6635 - re_lu_65_loss: 30.1208 - re_lu_121_loss: 17.9287 - re_lu_177_loss: 14.2413 - re_lu_233_loss: 12.3727 - re_lu_65_accuracy: 0.1640 - re_lu_121_accuracy: 0.2990 - re_lu_177_ - ETA: 59s - loss: 74.6691 - re_lu_65_loss: 30.1372 - re_lu_121_loss: 17.9333 - re_lu_177_loss: 14.2400 - re_lu_233_loss: 12.3586 - re_lu_65_accuracy: 0.1629 - re_lu_121_accuracy: 0.2972 - re_lu_177_ - ETA: 51s - loss: 74.9367 - re_lu_65_loss: 30.1483 - re_lu_121_loss: 17.9997 - re_lu_177_loss: 14.3334 - re_lu_233_loss: 12.4552 - re_lu_65_accuracy: 0.1\n",
      "Epoch 00002: loss improved from 77.86562 to 75.17604, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 75.1760 - re_lu_65_loss: 30.1625 - re_lu_121_loss: 18.0674 - re_lu_177_loss: 14.4118 - re_lu_233_loss: 12.5343 - re_lu_65_accuracy: 0.1592 - re_lu_121_accuracy: 0.2888 - re_lu_177_accuracy: 0.3599 - re_lu_233_accuracy: 0.3803 - val_loss: 152.2197 - val_re_lu_65_loss: 38.7904 - val_re_lu_121_loss: 37.7313 - val_re_lu_177_loss: 37.8393 - val_re_lu_233_loss: 37.8587 - val_re_lu_65_accuracy: 0.1200 - val_re_lu_121_accuracy: 0.2243 - val_re_lu_177_accuracy: 0.3513 - val_re_lu_233_accuracy: 0.3513\n",
      "Learning rate:  0.0005\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 72.4976 - re_lu_65_loss: 29.7372 - re_lu_121_loss: 17.3714 - re_lu_177_loss: 13.6471 - re_lu_233_loss: 11.7419 - re_lu_65_accuracy: 0.1576 - re_lu_121_accuracy: 0.3022 - re_lu_177_accuracy: 0.4074 - re_lu_233_accuracy: 0.4394 - ETA: 34s - loss: 72.0106 - re_lu_65_loss: 29.6818 - re_lu_121_loss: 17.2565 - re_lu_177_loss: 13.4967 - re_lu_233_loss: 11.5756 - re_lu_65_accuracy: 0.1 - ETA: 17s - loss: 72.1567 - re_lu_65_loss: 29.6990 - re_lu_121_loss: 17.2826 - re_lu_177_loss: 13.5418 - re_lu_233_loss: 11.6333 - re_lu_65_accuracy: 0.1591 - re_lu_121_accu - ETA: 7s - loss: 72.3165 - re_lu_65_loss: 29.7133 - re_lu_121_loss: 17.3231 - re_lu_177_loss: 13.5948 - re_lu_233_loss: 11.6854 - re_lu_65_accuracy: 0.1584 - re\n",
      "Epoch 00003: loss improved from 75.17604 to 72.49760, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 208s 208ms/step - loss: 72.4976 - re_lu_65_loss: 29.7372 - re_lu_121_loss: 17.3714 - re_lu_177_loss: 13.6471 - re_lu_233_loss: 11.7419 - re_lu_65_accuracy: 0.1576 - re_lu_121_accuracy: 0.3022 - re_lu_177_accuracy: 0.4074 - re_lu_233_accuracy: 0.4394 - val_loss: 151.6059 - val_re_lu_65_loss: 38.3673 - val_re_lu_121_loss: 37.1205 - val_re_lu_177_loss: 37.3527 - val_re_lu_233_loss: 38.7653 - val_re_lu_65_accuracy: 0.1169 - val_re_lu_121_accuracy: 0.2779 - val_re_lu_177_accuracy: 0.3974 - val_re_lu_233_accuracy: 0.3858\n",
      "Learning rate:  0.0005\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 70.1380 - re_lu_65_loss: 29.3026 - re_lu_121_loss: 16.7581 - re_lu_177_loss: 13.0048 - re_lu_233_loss: 11.0726 - re_lu_65_accuracy: 0.1574 - re_lu_121_accuracy: 0.3177 - re_lu_177_accuracy: 0.4160 - re_lu_233_accuracy: 0.4733   ETA: 1:17 - loss: 69.2902 - re_lu_65_loss: 29.2639 - re_lu_121_loss: 16.5009 - re_lu_177_loss: 12.7268 - re_lu_233_loss: 10.7986 - re_lu_65_a - ETA: 1:08 - loss: 69.3551 - re_lu_65_loss: 29.2739 - re_lu_121_loss: 16.5262 - re_lu_177_loss: 12.7484 - re_lu_233_loss: 10.8066 - re_l - ETA: 57s - loss: 69.7018 - re_lu_65_loss: 29.3221 - re_lu_121_loss: 16.6335 - re_lu_177_loss: 12.8449 - re_lu_233_los\n",
      "Epoch 00004: loss improved from 72.49760 to 70.13804, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 70.1380 - re_lu_65_loss: 29.3026 - re_lu_121_loss: 16.7581 - re_lu_177_loss: 13.0048 - re_lu_233_loss: 11.0726 - re_lu_65_accuracy: 0.1574 - re_lu_121_accuracy: 0.3177 - re_lu_177_accuracy: 0.4160 - re_lu_233_accuracy: 0.4733 - val_loss: 151.8496 - val_re_lu_65_loss: 38.6421 - val_re_lu_121_loss: 36.9553 - val_re_lu_177_loss: 37.6835 - val_re_lu_233_loss: 38.5687 - val_re_lu_65_accuracy: 0.1584 - val_re_lu_121_accuracy: 0.2724 - val_re_lu_177_accuracy: 0.3084 - val_re_lu_233_accuracy: 0.4263\n",
      "Learning rate:  0.0005\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 67.9995 - re_lu_65_loss: 28.8951 - re_lu_121_loss: 16.1988 - re_lu_177_loss: 12.4387 - re_lu_233_loss: 10.4669 - re_lu_65_accuracy: 0.1626 - re_lu_121_accuracy: 0.3502 - re_lu_177_accuracy: 0.4363 - re_lu_233_accuracy: 0.5100   ETA: 1:50 - loss: 66.9567 - re_lu_65_loss: 28.6420 - re_lu_121_loss: 15.9612 - re_lu_177_loss: 12.161 - ETA: 1:37 - loss: 67.3792 - re_lu_65_loss: 28.7526 - re_lu_121_loss: 16.0858 - re_lu_177_loss: 12.2738 - re_lu_233_loss: 10.2670 - re_lu_65 - ETA: 1:05 - loss: 67.1763 - re_lu_65_loss: 28.7247 - re_lu_121_loss: 15.9778 - re_lu_177_loss: 12.2318 - re_lu_233_loss: 10.2421 - re_lu_65_accuracy: 0.1637 - re_lu_121_accuracy: 0.3575 - re_lu_177_accuracy: - ETA: 1:02 - loss: 67.2737 - re_lu_65_loss: 28.7340 - re_lu_121_loss: 16.0009 - re_lu_ - ETA: 36s - loss: 67.7822 - re_lu_65_loss: 28.8555 - re_lu_121_loss: 16.1414 - re_lu_177_loss: 12.3804 - re_lu_233_loss: 10.4049 - re_lu_65_accuracy: 0.1636 - re_lu - ETA: 21s - loss: 67.8027 - re_lu_65_loss: 28.8772 - re_lu_121_loss\n",
      "Epoch 00005: loss improved from 70.13804 to 67.99955, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 67.9995 - re_lu_65_loss: 28.8951 - re_lu_121_loss: 16.1988 - re_lu_177_loss: 12.4387 - re_lu_233_loss: 10.4669 - re_lu_65_accuracy: 0.1626 - re_lu_121_accuracy: 0.3502 - re_lu_177_accuracy: 0.4363 - re_lu_233_accuracy: 0.5100 - val_loss: 150.6003 - val_re_lu_65_loss: 38.1038 - val_re_lu_121_loss: 36.6293 - val_re_lu_177_loss: 37.5342 - val_re_lu_233_loss: 38.3331 - val_re_lu_65_accuracy: 0.1509 - val_re_lu_121_accuracy: 0.3254 - val_re_lu_177_accuracy: 0.4008 - val_re_lu_233_accuracy: 0.4184\n",
      "Learning rate:  0.0005\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 65.7537 - re_lu_65_loss: 28.4502 - re_lu_121_loss: 15.6512 - re_lu_177_loss: 11.8152 - re_lu_233_loss: 9.8370 - re_lu_65_accuracy: 0.1661 - re_lu_121_accuracy: 0.3750 - re_lu_177_accuracy: 0.4536 - re_lu_233_accuracy: 0.5424  - ETA: 2:46 - loss: 65.1912 - re_lu_65_loss: 28.6901 - re_lu_121_loss: 15.4971 - re_lu_177_loss: 11.5856 - re_lu_233_loss: 9.4185 - re_lu_65_accuracy: 0.1615 - re_lu_121_acc - ETA: 2:35 - loss: 63.8947 - re - ETA: 1:57 - loss: 65.0943 - re_lu_65_loss: 28.4664 - re_lu_121_loss: 15.4906 - re_lu_177_ - ETA: 1:29 - loss: 65.1801 - re_lu_65_loss: 28.4720 - re_lu_121_loss: 15.5064 - re_lu_177_loss: 11.6030 - re_lu_233_loss: 9.5987 - re_lu_65_accuracy: 0.1633 - re_lu_121_accuracy: 0.3791 - re_lu_177_accuracy: 0.4740 - re_ - ETA: 1:25 - loss: 65.2918 - re_lu_65_loss: 28.4714 - re_lu_121_loss: 15.5362 - re_lu_177_loss: 11.6448 - re_lu_233_loss: 9.6394 - re_lu_65_accur - ETA: 19s - loss: 65.5939 - re_lu_65_loss: 28.4465 - re_lu_121_loss: 15.6061 - re\n",
      "Epoch 00006: loss improved from 67.99955 to 65.75365, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 65.7537 - re_lu_65_loss: 28.4502 - re_lu_121_loss: 15.6512 - re_lu_177_loss: 11.8152 - re_lu_233_loss: 9.8370 - re_lu_65_accuracy: 0.1661 - re_lu_121_accuracy: 0.3750 - re_lu_177_accuracy: 0.4536 - re_lu_233_accuracy: 0.5424 - val_loss: 151.6342 - val_re_lu_65_loss: 38.3095 - val_re_lu_121_loss: 36.8943 - val_re_lu_177_loss: 37.9670 - val_re_lu_233_loss: 38.4632 - val_re_lu_65_accuracy: 0.1617 - val_re_lu_121_accuracy: 0.3780 - val_re_lu_177_accuracy: 0.4580 - val_re_lu_233_accuracy: 0.5335\n",
      "Learning rate:  0.0005\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 63.5982 - re_lu_65_loss: 28.0059 - re_lu_121_loss: 15.0886 - re_lu_177_loss: 11.2403 - re_lu_233_loss: 9.2634 - re_lu_65_accuracy: 0.1762 - re_lu_121_accuracy: 0.3857 - re_lu_177_accuracy: 0.4748 - re_lu_233_accuracy: 0.5785  - ETA: 2:49 - loss: 60.6107 - re_lu_65_loss: 27.4708 - re_lu_121_loss: 14.1937 - re_lu_177_loss: 10.4754 - re_lu_233_loss: 8.4708 - re_lu_65_accuracy: 0.2048 - re_lu_121_accuracy: 0.3692 -  - ETA: 2:43 - loss: 60.6459 - re_lu_65_loss: 27.5357 - re_lu_121_loss: 14.2373 - re_lu_177_loss: 10.3715 - re_lu_233_loss: 8.5014 - re_lu_65_accuracy: 0.1890 - re_lu_121_accuracy: 0.4043 - re_lu_177_accuracy: 0.5208 - re_lu_233_accuracy:  - ETA: 2:42 - loss: 61.5260 - ETA: 2:04 - loss: 62.8908 - re_lu_65_loss: 27.9136 - re_lu_121_loss: 14.9188 - re_lu_177_loss: 11. - ETA: 34s - loss: 63.2725 - re_lu_65_loss: 27.9515 - re_lu_121_loss: 15.0127 - re_lu_177_loss: 11.1468 - re_lu_233_loss: 9.1616 - re_lu_65_accuracy: 0.1740 - re_lu_121_ac - ETA: 28s - loss: 63.3275 - re_lu_65_loss: 27.9667 - re_lu_121_loss: 15.0297 - re_lu_177_loss: 11.1584 - re_lu_233_loss: 9 - ETA: 17s - loss: 63.5184 - re_lu_65_loss: 28.0248 - re_lu_121_loss: 15.0737 - re_lu_177_loss: 11.2032 - re_lu_ - ETA: 1s - loss: 63.5434 - re_lu_65_loss: 27.9973 - re_lu_121_loss: 15.0755 - re_lu_177_loss: 11.2245 - re_lu_233_loss: 9.2462 - re_lu_65_accuracy: 0.1762 - re_lu_121_accuracy: 0.3864 - re_lu_177_accuracy: 0.4754 - re_lu_233_accuracy\n",
      "Epoch 00007: loss improved from 65.75365 to 63.59823, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 63.5982 - re_lu_65_loss: 28.0059 - re_lu_121_loss: 15.0886 - re_lu_177_loss: 11.2403 - re_lu_233_loss: 9.2634 - re_lu_65_accuracy: 0.1762 - re_lu_121_accuracy: 0.3857 - re_lu_177_accuracy: 0.4748 - re_lu_233_accuracy: 0.5785 - val_loss: 151.4047 - val_re_lu_65_loss: 38.2875 - val_re_lu_121_loss: 36.9827 - val_re_lu_177_loss: 37.6991 - val_re_lu_233_loss: 38.4354 - val_re_lu_65_accuracy: 0.1814 - val_re_lu_121_accuracy: 0.3951 - val_re_lu_177_accuracy: 0.4334 - val_re_lu_233_accuracy: 0.4727\n",
      "Learning rate:  0.0005\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 61.5202 - re_lu_65_loss: 27.5304 - re_lu_121_loss: 14.5858 - re_lu_177_loss: 10.6834 - re_lu_233_loss: 8.7206 - re_lu_65_accuracy: 0.1802 - re_lu_121_accuracy: 0.4076 - re_lu_177_accuracy: 0.5044 - re_lu_233_accuracy: 0.6072  - ETA: 2:50 - loss: 61.1968 - re_lu_65_loss: 27.3445 - re_lu_121_loss: 14.3744 - re_lu_177_loss: 10.7138 - re_lu_233_loss: 8.7641 - re_lu_65_accuracy: 0.1857 - re_lu_121_accuracy: 0.3804 - re_lu_177_accuracy: 0.5226 -  - ETA: 2:47 - loss: 62.4176 - re_lu_65_loss: 27.7639 - re_lu_121_loss: 14.7608 - re_lu_177_loss: 10.9896 - re_lu_233_loss - ETA: 2:27 - loss: 61.2549 - re_lu_65_loss: 27.7621 - re_lu_121_loss: 14.4873 - re_lu_177_loss: 10.5291 - re_lu_233_loss - ETA: 2:0\n",
      "Epoch 00008: loss improved from 63.59823 to 61.52019, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 61.5202 - re_lu_65_loss: 27.5304 - re_lu_121_loss: 14.5858 - re_lu_177_loss: 10.6834 - re_lu_233_loss: 8.7206 - re_lu_65_accuracy: 0.1802 - re_lu_121_accuracy: 0.4076 - re_lu_177_accuracy: 0.5044 - re_lu_233_accuracy: 0.6072 - val_loss: 151.8723 - val_re_lu_65_loss: 38.3702 - val_re_lu_121_loss: 37.1340 - val_re_lu_177_loss: 37.5609 - val_re_lu_233_loss: 38.8072 - val_re_lu_65_accuracy: 0.1831 - val_re_lu_121_accuracy: 0.4141 - val_re_lu_177_accuracy: 0.5483 - val_re_lu_233_accuracy: 0.6924\n",
      "Learning rate:  0.0005\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 59.8500 - re_lu_65_loss: 27.0774 - re_lu_121_loss: 14.1511 - re_lu_177_loss: 10.2852 - re_lu_233_loss: 8.3363 - re_lu_65_accuracy: 0.1824 - re_lu_121_accuracy: 0.4289 - re_lu_177_accuracy: 0.5165 - re_lu_233_accuracy: 0.6074  - ETA: 2:50 - loss: 60.0308 - re_lu_65_loss: 27.2661 - re_lu_121_loss: 14.2261 - re_lu_177_loss: 10.3654 - re_lu_233_loss: 8.1732 - re_lu_65_accuracy: 0.1840 - re_lu_121_accuracy: 0.4142 - r - ETA: 2:45 - loss: 59.2876 - re_lu_65_loss: 27.1494 - re_lu_121 - ETA: 2:26 - loss: 57.8494 - re_lu_65_loss: 26.8009 - re_lu_121_loss: 13.6237 - re_lu_177_loss: 9.6714 - re_lu_233_loss: 7.7534 - re_lu_65_a - ETA: 1:55 - loss: 58.2066 - re_lu_65_loss: 26.8861 - re_lu_121_loss: 13.6718 - re_lu_177_loss: 9.7907 - re_lu_233_los - ETA: 1:44 - loss: 58.1500 - re_lu_65_loss: 26.8705 - re_lu_121_loss: 13.6 - ETA: 1:29 - loss: 58.1797 - re_lu_65_loss: 26.8793 - re_lu_121_loss: 13.6712 - re_lu_177_loss: 9.7883 - re_lu_233_loss: 7.8407 - re_lu - ETA: 31s - ETA: 9s - loss: 59.6676 - re_lu_65_loss: 27.0491 - re_lu_121_loss: 14.1013 - re_lu_177_loss: 10.2340 - re_lu_233_loss: 8.2832 - re_lu_65_accuracy: 0.1825 - re_lu_121_accuracy: 0.4319 - re_lu_\n",
      "Epoch 00009: loss improved from 61.52019 to 59.85003, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 59.8500 - re_lu_65_loss: 27.0774 - re_lu_121_loss: 14.1511 - re_lu_177_loss: 10.2852 - re_lu_233_loss: 8.3363 - re_lu_65_accuracy: 0.1824 - re_lu_121_accuracy: 0.4289 - re_lu_177_accuracy: 0.5165 - re_lu_233_accuracy: 0.6074 - val_loss: 150.9693 - val_re_lu_65_loss: 38.0829 - val_re_lu_121_loss: 36.9648 - val_re_lu_177_loss: 37.4154 - val_re_lu_233_loss: 38.5062 - val_re_lu_65_accuracy: 0.1760 - val_re_lu_121_accuracy: 0.4386 - val_re_lu_177_accuracy: 0.3562 - val_re_lu_233_accuracy: 0.4751\n",
      "Learning rate:  0.0005\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 57.8446 - re_lu_65_loss: 26.6518 - re_lu_121_loss: 13.6156 - re_lu_177_loss: 9.7596 - re_lu_233_loss: 7.8176 - re_lu_65_accuracy: 0.1870 - re_lu_121_accuracy: 0.4270 - re_lu_177_accuracy: 0.5410 - re_lu_233_accuracy: 0.6435   ETA: 2:02 - loss: 56.8875 - re_lu_65_loss: 26.6397 - re_lu_121_loss: 13.3211 - re_lu_177_loss: 9.4403 - re_lu_233_loss: 7.4864 - re_lu_65_accuracy: 0.1847 - re_lu_12 - ETA: 1:55 - loss: 57.0275 - re_ - ETA: 1:35 - loss: 57.4225 - re_lu_65_loss: 26.6640 - re_lu_121_loss: 13.5067 - re_lu_177_loss: 9.6093 - re_lu_233_loss: 7.6425 - re_lu_65_accuracy: 0.1808 - re_lu_121_accuracy: 0.434 - ETA: 31s - loss: \n",
      "Epoch 00010: loss improved from 59.85003 to 57.84462, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 57.8446 - re_lu_65_loss: 26.6518 - re_lu_121_loss: 13.6156 - re_lu_177_loss: 9.7596 - re_lu_233_loss: 7.8176 - re_lu_65_accuracy: 0.1870 - re_lu_121_accuracy: 0.4270 - re_lu_177_accuracy: 0.5410 - re_lu_233_accuracy: 0.6435 - val_loss: 152.4305 - val_re_lu_65_loss: 37.9557 - val_re_lu_121_loss: 36.8279 - val_re_lu_177_loss: 38.0437 - val_re_lu_233_loss: 39.6033 - val_re_lu_65_accuracy: 0.2087 - val_re_lu_121_accuracy: 0.4073 - val_re_lu_177_accuracy: 0.4696 - val_re_lu_233_accuracy: 0.5948\n",
      "Learning rate:  0.0005\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 56.2707 - re_lu_65_loss: 26.1993 - re_lu_121_loss: 13.2367 - re_lu_177_loss: 9.3867 - re_lu_233_loss: 7.4481 - re_lu_65_accuracy: 0.1890 - re_lu_121_accuracy: 0.4666 - re_lu_177_accuracy: 0.5367 - re_lu_233_accuracy: 0.6559   ETA: 1:01 - loss: 56.0213 - re_lu - ETA: 24s - loss: 56.1654 - re_lu_65_loss: 26.1941 -\n",
      "Epoch 00011: loss improved from 57.84462 to 56.27070, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 56.2707 - re_lu_65_loss: 26.1993 - re_lu_121_loss: 13.2367 - re_lu_177_loss: 9.3867 - re_lu_233_loss: 7.4481 - re_lu_65_accuracy: 0.1890 - re_lu_121_accuracy: 0.4666 - re_lu_177_accuracy: 0.5367 - re_lu_233_accuracy: 0.6559 - val_loss: 154.6151 - val_re_lu_65_loss: 38.4925 - val_re_lu_121_loss: 37.7532 - val_re_lu_177_loss: 38.7097 - val_re_lu_233_loss: 39.6597 - val_re_lu_65_accuracy: 0.1674 - val_re_lu_121_accuracy: 0.3957 - val_re_lu_177_accuracy: 0.4074 - val_re_lu_233_accuracy: 0.5785\n",
      "Learning rate:  0.0005\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 54.5738 - re_lu_65_loss: 25.7475 - re_lu_121_loss: 12.8123 - re_lu_177_loss: 8.9679 - re_lu_233_loss: 7.0460 - re_lu_65_accuracy: 0.1966 - re_lu_121_accuracy: 0.4831 - re_lu_177_accuracy: 0.5539 - re_lu_233_accuracy: 0.6941   ETA: 2:17 - loss: 53.1636 - re_lu_65_loss: 25.4488 - re_lu_121_loss: 12.4411 - re_lu_177_loss: 8.5875 - re_lu_233_loss: 6.6862 - re_lu_65_accuracy: 0.1958 - re_lu_121_accuracy: 0.5160 - re_lu_177_accuracy: 0.585 - ETA: 2:14 - loss: 53.2160 - re_lu_65_loss: 25.4622 - re_lu_121_loss: 12.4477 - re_lu_177_loss: 8.6029 - re_lu_233_loss: 6.7032 - re_lu_65_accuracy: 0.1955 - re_lu_121_accuracy: 0.5163 - re_lu_177_accuracy: 0.5868 - re_lu_233_ac - ETA: 2:13 - los - ETA: 1:52 - loss: 54.1241 - re_lu_65_loss: 25.7203 - re_lu_121_loss: 12.6946 - re_lu_177_loss: 8.8321 - re_lu_233_loss: 6.8770 - re_lu_65_accuracy: 0.1900 - re_lu_121_ac - ETA: 1:46 - loss: 54.2702 - re_lu_65_loss: 25.7371 - re_lu_121_loss: 12.7421 - re\n",
      "Epoch 00012: loss improved from 56.27070 to 54.57375, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 54.5738 - re_lu_65_loss: 25.7475 - re_lu_121_loss: 12.8123 - re_lu_177_loss: 8.9679 - re_lu_233_loss: 7.0460 - re_lu_65_accuracy: 0.1966 - re_lu_121_accuracy: 0.4831 - re_lu_177_accuracy: 0.5539 - re_lu_233_accuracy: 0.6941 - val_loss: 153.3724 - val_re_lu_65_loss: 38.3064 - val_re_lu_121_loss: 37.3262 - val_re_lu_177_loss: 38.1959 - val_re_lu_233_loss: 39.5440 - val_re_lu_65_accuracy: 0.2233 - val_re_lu_121_accuracy: 0.4929 - val_re_lu_177_accuracy: 0.4494 - val_re_lu_233_accuracy: 0.6226\n",
      "Learning rate:  0.0005\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 52.7419 - re_lu_65_loss: 25.2476 - re_lu_121_loss: 12.3654 - re_lu_177_loss: 8.5066 - re_lu_233_loss: 6.6223 - re_lu_65_accuracy: 0.2016 - re_lu_121_accuracy: 0.5037 - re_lu_177_accuracy: 0.5749 - re_lu_233_accuracy: 0.7083   ETA: 1:12 - loss: 52.6468 - re_lu_65_loss: 25.3520 - re_lu_121_loss: 12.3171 - re_lu_177_loss:  - ETA: 14s - loss: 52.7489 - re_lu_65_loss: 25.2696 - re_lu_121_loss: 12.3697 - re_lu_177_loss: 8.4969 - re_lu\n",
      "Epoch 00013: loss improved from 54.57375 to 52.74187, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 52.7419 - re_lu_65_loss: 25.2476 - re_lu_121_loss: 12.3654 - re_lu_177_loss: 8.5066 - re_lu_233_loss: 6.6223 - re_lu_65_accuracy: 0.2016 - re_lu_121_accuracy: 0.5037 - re_lu_177_accuracy: 0.5749 - re_lu_233_accuracy: 0.7083 - val_loss: 153.8958 - val_re_lu_65_loss: 38.3376 - val_re_lu_121_loss: 37.3083 - val_re_lu_177_loss: 38.4728 - val_re_lu_233_loss: 39.7771 - val_re_lu_65_accuracy: 0.1862 - val_re_lu_121_accuracy: 0.4663 - val_re_lu_177_accuracy: 0.5341 - val_re_lu_233_accuracy: 0.6655\n",
      "Learning rate:  0.0005\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 51.2605 - re_lu_65_loss: 24.7630 - re_lu_121_loss: 12.0005 - re_lu_177_loss: 8.1737 - re_lu_233_loss: 6.3232 - re_lu_65_accuracy: 0.2110 - re_lu_121_accuracy: 0.5173 - re_lu_177_accuracy: 0.6010 - re_lu_233_accuracy: 0.7272   ETA: 1:53 - loss: 51.3266 - re_lu_65_loss: 24.8744 - re_lu_121_ - ETA: 1:37 - loss: 51.4 - ETA: 50s - loss: 51.2372 - re_lu_65_loss: 24.7559 - re_lu_121_loss: 11.9916 - re_lu_177_loss: 8.1663 - re_lu_233_loss: 6.3233 - re_lu_65_accuracy: 0.2056 - re_lu_121_accuracy: 0.5130 - re_l - ETA: 41s - loss: 51.2029 - re_lu_65_loss: 24.7462 - re_lu_121_loss: 11.9904 - re_lu_177_loss: 8.1532 - re_lu_233_loss: 6.3131 - re_lu_65_accuracy: 0.2068 - re_lu_121_accuracy: 0.5141 - re_lu_177_accuracy: 0.6002 - re_ - ETA: 37s - loss: 51.3030 - re_lu_65_loss: 24.7581 - re_lu_121_loss: 12.0164 - re_lu_177_loss: 8.1880 - re_lu_233_loss: 6.3404 - re_lu_65_accuracy: 0.2072 - re_lu_121_accuracy: 0.5130 - re_lu_177_accuracy: 0.5979 - re_lu_233_accuracy: 0. - ETA: 36s - loss: 51.3245 - re_lu_65_loss: 24.7687 - re_lu_121_loss: 12.0219 - re_lu_177_loss: 8.1906 - re_lu_233_loss: 6.3433 - re_lu_65_accuracy: 0.2072 - re_lu_121_accuracy: 0.5128 - re_lu_177_accuracy: 0.5978 - r - ETA: 31s - loss: 51.1999 - re_lu_65_loss: 24.7259 - re_lu_121_loss: 11.9881 - re_lu_177_loss: 8.1625 - re_lu_233_loss: 6.3233 - re_lu_65_accuracy: 0.2083 - re_lu_121_accuracy: 0.5143 - re_lu_177_accuracy: 0.5978 - ETA: 26s - loss: 51.3151 - re_lu_65_loss: 24.7580 - re_lu_121_loss: 12.0234 - re_lu_177_loss: 8.1927 - re_lu_233_loss: 6.3410 - re_lu_65_accuracy: 0.2095 - re_lu_121_ac - ETA: 13s - loss: 51.2741 - re_lu_65_loss: 24.7739 - re_lu_121_loss: 11.9982 - re_lu_177_loss: 8.1738 - re_lu_233_loss: 6.3280 - re_lu_65_accuracy: 0.2105 - re_lu_121_accuracy: 0.5166 - re_lu_177_accuracy: 0.6020 - re_lu_233_acc - ETA: 11s - loss: 51.2461 - re_lu_65_loss: 24.7638 - re_lu_121_loss: 11.9934 - re_lu_177_loss: 8.1670 - re_lu_233_loss: 6.32\n",
      "Epoch 00014: loss improved from 52.74187 to 51.26045, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 51.2605 - re_lu_65_loss: 24.7630 - re_lu_121_loss: 12.0005 - re_lu_177_loss: 8.1737 - re_lu_233_loss: 6.3232 - re_lu_65_accuracy: 0.2110 - re_lu_121_accuracy: 0.5173 - re_lu_177_accuracy: 0.6010 - re_lu_233_accuracy: 0.7272 - val_loss: 153.4968 - val_re_lu_65_loss: 38.2700 - val_re_lu_121_loss: 37.3601 - val_re_lu_177_loss: 38.4940 - val_re_lu_233_loss: 39.3725 - val_re_lu_65_accuracy: 0.2083 - val_re_lu_121_accuracy: 0.5228 - val_re_lu_177_accuracy: 0.4832 - val_re_lu_233_accuracy: 0.6386\n",
      "Learning rate:  0.0005\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 49.9669 - re_lu_65_loss: 24.3409 - re_lu_121_loss: 11.6798 - re_lu_177_loss: 7.8742 - re_lu_233_loss: 6.0720 - re_lu_65_accuracy: 0.2113 - re_lu_121_accuracy: 0.5265 - re_lu_177_accuracy: 0.6105 - re_lu_233_accuracy: 0.7337 - ETA: 35s - - ETA: 1s - loss: 49.9547 - re_lu_65_loss: 24.3440 - re_lu_121_loss: 11.6734 - re_lu_177_loss: 7.8689 - re_lu_233_loss: 6.0684 - re_lu_65_accuracy: 0.2115 - re_lu_121_accuracy: 0.5270 - re_lu_177_accuracy: 0.6113 - re_lu_\n",
      "Epoch 00015: loss improved from 51.26045 to 49.96688, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 49.9669 - re_lu_65_loss: 24.3409 - re_lu_121_loss: 11.6798 - re_lu_177_loss: 7.8742 - re_lu_233_loss: 6.0720 - re_lu_65_accuracy: 0.2113 - re_lu_121_accuracy: 0.5265 - re_lu_177_accuracy: 0.6105 - re_lu_233_accuracy: 0.7337 - val_loss: 154.1054 - val_re_lu_65_loss: 38.1994 - val_re_lu_121_loss: 37.7269 - val_re_lu_177_loss: 38.6338 - val_re_lu_233_loss: 39.5453 - val_re_lu_65_accuracy: 0.2389 - val_re_lu_121_accuracy: 0.4724 - val_re_lu_177_accuracy: 0.4961 - val_re_lu_233_accuracy: 0.5642\n",
      "Learning rate:  0.0005\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 48.3990 - re_lu_65_loss: 23.7728 - re_lu_121_loss: 11.3085 - re_lu_177_loss: 7.5455 - re_lu_233_loss: 5.7721 - re_lu_65_accuracy: 0.2149 - re_lu_121_accuracy: 0.5393 - re_lu_177_accuracy: 0.6323 - re_lu_233_accuracy: 0.7611   ETA: 2:50 - loss: 44.6376 - re_lu_65_loss: 22.9281 - re_lu_121_loss: 10.1476 - re_lu_177_loss: 6.5684 - re_lu_233_loss: 4.9935 - re_lu_65_accuracy: 0.2329 - re_lu_121_accuracy: 0.6411 - re_lu_177_accuracy: 0.7295 - re_lu_233_ac - ETA: 2:49 - loss: 46.2236 - re_lu_65_loss: 23.1824 - re_lu_121_loss: 10.6041 - re_lu_177_loss: 7.0155 - re_lu_233_loss: 5.4216 - re_lu_65_accuracy: 0.2345 - re_l - ETA: 2:43 - loss: 46. - ETA: 2:24 - loss: 47.5499 - re_lu_65_loss: 23.6024 - re_lu_121_loss: 11.0878 - re_lu_177_loss:  - ETA: 2:11 - loss: 47.7034 - re_lu_65_loss: 23.6166 - re_lu_121_loss: 11.1416 - re_lu_177_loss: 7.3603 - re_lu_233_loss: 5.5848 - re_lu_65_accuracy: 0.2116 - re_lu_ - ETA: 2:04 - los - ETA: 1:22 - loss: - ETA: 1:01 - loss: 47.7554 - re_lu_65_loss: 23.6712 - re_lu_121_loss: 11.0930 - re_ - ETA: 34s - loss: 47.9762 - re_lu_65_loss: 23.6750 - re_lu_121_loss: 11.1785 - re_lu_177_loss: 7.4378 - re_lu_233_loss: 5.6848 - re_lu_65_accuracy: 0.2152 - re_lu_121_accuracy: 0.5515 - re_lu_177_ - ETA: 26s - loss: 48.1835 - re_lu_65_loss: 23.7313 - re_lu_121_loss: 11.2406 - re_lu_177_loss: 7.4883 - re_lu_233_loss: 5.7234 - ETA: 7s - loss: 48.3961 - re_lu_65_loss: 23.7731 - re_lu_121_loss: 11.3122 - re_lu_177_loss: 7.5457 - re_lu_233_loss: 5.7650 - re_lu_65_accuracy: 0.2141 - re_lu_121_accuracy: 0.5419 - re_lu_177_accuracy: 0.6336 - re_l - ETA: 5s - loss: 48.3773 - re_lu_65_loss: 23.7725 - re_lu_121_loss: 11.3065 - re_lu_177_loss: 7.5382 - re_lu_233_loss: 5.7601 - re_lu_65_accuracy: 0.2141 - re_lu_121_accuracy: \n",
      "Epoch 00016: loss improved from 49.96688 to 48.39895, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 48.3990 - re_lu_65_loss: 23.7728 - re_lu_121_loss: 11.3085 - re_lu_177_loss: 7.5455 - re_lu_233_loss: 5.7721 - re_lu_65_accuracy: 0.2149 - re_lu_121_accuracy: 0.5393 - re_lu_177_accuracy: 0.6323 - re_lu_233_accuracy: 0.7611 - val_loss: 155.0014 - val_re_lu_65_loss: 38.1820 - val_re_lu_121_loss: 37.2055 - val_re_lu_177_loss: 39.3703 - val_re_lu_233_loss: 40.2438 - val_re_lu_65_accuracy: 0.2043 - val_re_lu_121_accuracy: 0.4179 - val_re_lu_177_accuracy: 0.5817 - val_re_lu_233_accuracy: 0.6303\n",
      "Learning rate:  0.0005\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 47.0680 - re_lu_65_loss: 23.2624 - re_lu_121_loss: 10.9910 - re_lu_177_loss: 7.2791 - re_lu_233_loss: 5.5355 - re_lu_65_accuracy: 0.2226 - re_lu_121_accuracy: 0.5473 - re_lu_177_accuracy: 0.6349 - re_lu_233_accuracy: 0.7690   ETA: 2:49 - loss: 46.6920 - re_lu_65_loss: 23.4594 - re_lu_121_loss: 10.7133 - re_lu_177_loss: 7.0820 - re_lu_233_loss: 5.4373 - re_lu_65 - ETA: 2:43 - loss: 47.8443 - re_lu_65_loss: 23.8412 - re_lu_121_loss: 11.2143 - re_lu_177_loss: 7.2784 - re_lu_233_loss: 5.5105  - ETA: 2:34 - loss: 46.1111 - re_lu_65_loss: 23.1718 -  - ETA: 2:17 - loss: 45.8381 - re_lu_65_loss: 23.0821 - re_lu_121_loss - ETA: 2:02 - loss: 45.8281 - re_lu_65_loss: 23.0027 - re_lu_121_loss: 10.5929 - re_lu_177_loss: 6.9574 - re_lu_233_loss: 5.2750 - re_lu_65_accuracy: 0.2224 - re_lu_121_accuracy: 0.5884 - re_lu_177_a - ETA: 1:58 - loss: 45.8349 - re_lu_65_loss: 22.9904 - re_lu_121_loss: 10.6176 - re_lu_177_loss: 6.9608 - re_lu_233_loss: 5.2662 - re_lu_65_accuracy: 0 - ETA: 1:49 - loss: 45.6212 - re_lu_65_loss: 22.9385 - re_lu_121_loss: 10.5566 - re_lu_177_loss: 6.9033 - re_lu_233_loss: 5.2228 - re_lu_65_accuracy: 0.2271 - re_lu_121_accuracy: 0.5927 - re_lu_177_accuracy: 0.6837 - re_lu_233_accuracy:  - ETA: 1:49 - loss: 45.6167 - re_lu_65_loss: 22.9423 - re_lu_121_loss: 10.5568 - re_lu_177_lo - ETA: 1:35 - loss: 45.9387 - re_lu_65_loss: 22.9752 - re_lu_121_loss: 10.6653 - re_lu_177_loss: 6.9971 - re_lu_233_loss: 5.3010 - re_lu_65_accuracy: 0.2312 - re_lu_121_accuracy: 0.5839 - re_lu_177_a - ETA: 1:31 - loss: 46.1135 - re_lu_65_loss: 23.0258 - re_lu_121_loss: 10.7200 - re_lu_177_loss: 7.0375 - re_lu_233_loss: 5.3303 -  - ETA: 58s - loss: 46.4880 - re_lu_65_loss: 23.1047 - re_lu_121_loss: 10.8254 - re_lu_177_loss: 7.1473 - re_lu_233_loss: 5.4106 - re_lu_65_accuracy: 0.2246 - re_lu_121_ac - ETA: 45s - loss: 46.4475 - re_lu_65_loss: 23.0869 - re_lu_121_loss: 10.7997 - re_lu_177_loss: 7.1476 - ETA: 20s - loss: 46.7103 - re_lu_65_loss: 23.1688 - re_lu_121_loss: 10.88\n",
      "Epoch 00017: loss improved from 48.39895 to 47.06802, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 47.0680 - re_lu_65_loss: 23.2624 - re_lu_121_loss: 10.9910 - re_lu_177_loss: 7.2791 - re_lu_233_loss: 5.5355 - re_lu_65_accuracy: 0.2226 - re_lu_121_accuracy: 0.5473 - re_lu_177_accuracy: 0.6349 - re_lu_233_accuracy: 0.7690 - val_loss: 154.6016 - val_re_lu_65_loss: 38.1508 - val_re_lu_121_loss: 37.3694 - val_re_lu_177_loss: 38.7854 - val_re_lu_233_loss: 40.2961 - val_re_lu_65_accuracy: 0.2036 - val_re_lu_121_accuracy: 0.4886 - val_re_lu_177_accuracy: 0.5190 - val_re_lu_233_accuracy: 0.6468\n",
      "Learning rate:  0.0005\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 45.6095 - re_lu_65_loss: 22.7131 - re_lu_121_loss: 10.6383 - re_lu_177_loss: 6.9701 - re_lu_233_loss: 5.2880 - re_lu_65_accuracy: 0.2294 - re_lu_121_accuracy: 0.5824 - re_lu_177_accuracy: 0.6704 - re_lu_233_accuracy: 0.7857   ETA: 2:23 - loss: 50.3915 - re_lu_65_ - ETA: 43s - loss: 45.2415 - re_lu_65_loss: 22.6939 - re_lu_121_loss: 10.5435 - re_lu_177_loss: 6.8453 - re_lu_233_loss: - ETA: 21s - loss: 45.5629 - re_lu_65_loss: 22.7078 - re_lu_121_loss: 10.6395 - re_lu_177_loss: 6.9548 - re_lu_233_loss: 5.2608 - re_lu_65_accuracy: 0.2280  - ETA: 7s - loss: 45.6603 - re_lu_65_loss: 22.7270 - re_lu_121_loss: 10.6592 - re_lu_177_loss: 6.9815 - re_lu_233_loss: 5.2926 - re_lu_65_accuracy: 0.2286 - re_lu_121_accuracy: 0.5821 - re_lu_177_accurac - ETA: 4s - loss: 45.6285 - re_lu_65_loss: 22.7142 - re_lu_121_loss: 10.6520 - re_lu_177_loss: 6.9740 - re_lu_233_loss: 5.2884 - re_lu_65_accuracy: 0.2288 - re_lu_121_accuracy: 0.5823 - re_lu_177\n",
      "Epoch 00018: loss improved from 47.06802 to 45.60947, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 45.6095 - re_lu_65_loss: 22.7131 - re_lu_121_loss: 10.6383 - re_lu_177_loss: 6.9701 - re_lu_233_loss: 5.2880 - re_lu_65_accuracy: 0.2294 - re_lu_121_accuracy: 0.5824 - re_lu_177_accuracy: 0.6704 - re_lu_233_accuracy: 0.7857 - val_loss: 153.9319 - val_re_lu_65_loss: 38.0100 - val_re_lu_121_loss: 37.5461 - val_re_lu_177_loss: 38.8748 - val_re_lu_233_loss: 39.5009 - val_re_lu_65_accuracy: 0.2023 - val_re_lu_121_accuracy: 0.5527 - val_re_lu_177_accuracy: 0.5706 - val_re_lu_233_accuracy: 0.6787\n",
      "Learning rate:  0.0005\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 44.2474 - re_lu_65_loss: 22.1623 - re_lu_121_loss: 10.3215 - re_lu_177_loss: 6.7115 - re_lu_233_loss: 5.0521 - re_lu_65_accuracy: 0.2559 - re_lu_121_accuracy: 0.5946 - re_lu_177_accuracy: 0.6725 - re_lu_233_accuracy: 0.7915   ETA: 1:16 - loss: 43.9894 - re_lu_65_loss: 22.1227 - re_lu_121_loss: 10.2149 - re_lu_177_loss: 6.6488 - re_lu_233_loss: 5.0029 - re_lu_65_accuracy: 0.2613 - re_lu_121_accuracy: 0.6017 - re_lu_177_a - ETA: 1:12 - loss: 44.1436 - re_lu_65_loss: 22.1597 - re_lu_121_loss: 10.2699 - re_lu_177_loss: 6.6855 - re_lu_233_loss: 5.0284 - re_lu_65_accuracy: 0.2604 - re_lu_121_accuracy: 0.5993 - re_lu_177_accuracy: 0.6775 - re_lu_233_ - ETA: 1:11 - loss: 44.0946 - re_lu_65_loss: 22.1342 - re_lu_121_loss: 10.2586 - re_lu_177_loss: 6.6770 - re_lu_233_loss: 5.0247 - re_lu_65_accuracy: 0 - ETA: 1:03 - loss: 44.1978 - re_lu_65_loss: 22.1565 - re_lu_121_loss: 10.2974 - re_lu_177_loss: 6.701 - ETA: 40s - loss: 44.0257 - re_lu_65_loss: 22.1037 - re_lu_121_loss: 10.2498 - re_lu_177_loss: 6.6610 - re_lu_233_loss: 5.0112 - re_lu_65_accuracy: 0.2596 - r - ETA: 25s - loss: 44.0035 - re_lu_65_loss: 22.0\n",
      "Epoch 00019: loss improved from 45.60947 to 44.24745, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 44.2474 - re_lu_65_loss: 22.1623 - re_lu_121_loss: 10.3215 - re_lu_177_loss: 6.7115 - re_lu_233_loss: 5.0521 - re_lu_65_accuracy: 0.2559 - re_lu_121_accuracy: 0.5946 - re_lu_177_accuracy: 0.6725 - re_lu_233_accuracy: 0.7915 - val_loss: 156.4834 - val_re_lu_65_loss: 38.3125 - val_re_lu_121_loss: 37.7984 - val_re_lu_177_loss: 39.3407 - val_re_lu_233_loss: 41.0319 - val_re_lu_65_accuracy: 0.2337 - val_re_lu_121_accuracy: 0.5339 - val_re_lu_177_accuracy: 0.5576 - val_re_lu_233_accuracy: 0.7035\n",
      "Learning rate:  0.0005\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 42.9107 - re_lu_65_loss: 21.5476 - re_lu_121_loss: 10.0335 - re_lu_177_loss: 6.4763 - re_lu_233_loss: 4.8533 - re_lu_65_accuracy: 0.2497 - re_lu_121_accuracy: 0.6011 - re_lu_177_accuracy: 0.6782 - re_lu_233_accuracy: 0.7934\n",
      "Epoch 00020: loss improved from 44.24745 to 42.91074, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 42.9107 - re_lu_65_loss: 21.5476 - re_lu_121_loss: 10.0335 - re_lu_177_loss: 6.4763 - re_lu_233_loss: 4.8533 - re_lu_65_accuracy: 0.2497 - re_lu_121_accuracy: 0.6011 - re_lu_177_accuracy: 0.6782 - re_lu_233_accuracy: 0.7934 - val_loss: 156.0178 - val_re_lu_65_loss: 38.1205 - val_re_lu_121_loss: 37.8473 - val_re_lu_177_loss: 39.4077 - val_re_lu_233_loss: 40.6423 - val_re_lu_65_accuracy: 0.2443 - val_re_lu_121_accuracy: 0.5089 - val_re_lu_177_accuracy: 0.6163 - val_re_lu_233_accuracy: 0.7403\n",
      "Learning rate:  0.0005\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 41.6349 - re_lu_65_loss: 21.0093 - re_lu_121_loss: 9.7343 - re_lu_177_loss: 6.2307 - re_lu_233_loss: 4.6606 - re_lu_65_accuracy: 0.2609 - re_lu_121_accuracy: 0.6166 - re_lu_177_accuracy: 0.6873 - re_lu_233_accuracy: 0.7950\n",
      "Epoch 00021: loss improved from 42.91074 to 41.63493, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 41.6349 - re_lu_65_loss: 21.0093 - re_lu_121_loss: 9.7343 - re_lu_177_loss: 6.2307 - re_lu_233_loss: 4.6606 - re_lu_65_accuracy: 0.2609 - re_lu_121_accuracy: 0.6166 - re_lu_177_accuracy: 0.6873 - re_lu_233_accuracy: 0.7950 - val_loss: 154.3660 - val_re_lu_65_loss: 37.9625 - val_re_lu_121_loss: 37.5054 - val_re_lu_177_loss: 38.6595 - val_re_lu_233_loss: 40.2386 - val_re_lu_65_accuracy: 0.2313 - val_re_lu_121_accuracy: 0.5762 - val_re_lu_177_accuracy: 0.6117 - val_re_lu_233_accuracy: 0.7460\n",
      "Learning rate:  0.0005\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 40.4986 - re_lu_65_loss: 20.4292 - re_lu_121_loss: 9.5138 - re_lu_177_loss: 6.0405 - re_lu_233_loss: 4.5152 - re_lu_65_accuracy: 0.2696 - re_lu_121_accuracy: 0.6223 - re_lu_177_accuracy: 0.7090 - re_lu_233_accuracy: 0.8055  - ETA: 2:13 - loss: 39.1181 - re_lu_65_loss: 20.1269 - re_lu_121_loss: 9.0735 - re_lu_177_loss: 5.6749 - re_lu_233_loss: 4.2426 - re_lu_65_accuracy: 0.2628 - re_lu_121_accuracy: 0.6543 - re_lu_ - ETA: 2:04 - loss: 39.1637 - re_lu_65_loss: 20.0753 - re_lu_121_loss: 9.1026 - re_lu_177_loss: 5.7158 - re_lu_233_loss: 4.2701 - re_lu_65_accuracy: 0.2646 - re_lu_121_accurac - ETA: 1:08 - loss: 39.6301 - re_lu_65_loss: 20.1868 - re_lu_121_loss: 9.2515 - re_lu_177_loss: 5.8336 - re_lu_233_loss: 4.3582 - re_lu_65_accuracy: 0.2691 - re_lu_121_accuracy: 0.6415 - re_lu_177_accuracy: 0.7285 - re_lu_233_accuracy - ETA - ETA: 41s - loss: 39.9000 - re_lu_65_loss: 20.2508 - re_lu_121_loss: 9.3591 - re_lu_177_loss: 5.8932 - re_lu_233_loss: 4.3969 - re_lu_65_accuracy: 0.2718 - re_lu_12 - ETA: 34s - loss: 40.0735 - re_lu_65_loss: 20.2899 - re_lu_121_loss: 9.4087 - re_lu_177_loss: 5.9442 - re_lu_233_loss: 4.4306 - re_lu_65_accuracy: 0.2719 - re_lu_121_accuracy: 0.6338 - ETA: 29s - loss: 40.2391 - re_lu_65_loss: 20.3443 - re_lu_121_loss: 9.4553 - re_lu_177_loss: 5.9791 - re_lu_233_loss: 4.4604 - re_lu_65_accuracy: 0.2717 - re_lu_121_accuracy: 0.6317 - - ETA: 24s - loss: 40.2079 - re_lu_65_loss: 20.3242 - re_lu_121_loss: 9.4458 - re_lu_177_loss: 5.9786 - re_lu_233_loss: 4.4594 - re_lu_65_accuracy: 0.2712 - re_lu_121_accuracy: 0.6296 - re_lu_177 - ETA: 20s - loss: 40.3041 - re_lu_65_loss: 20.3739 - re_lu_121_loss: 9.4679 - re_lu_177_loss: - ETA: 3s - loss: 40.4600 - re_lu_65_loss: 20.4151 - re_lu_121_loss: 9.5081 - re_lu_177_loss: 6.0291 - re_lu_233_loss: 4.5077 - re_lu_65_accuracy: 0.2703 - re_lu_121_accuracy: 0.6228 - re_lu_177_accuracy: 0.7087 - re_lu\n",
      "Epoch 00022: loss improved from 41.63493 to 40.49860, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 40.4986 - re_lu_65_loss: 20.4292 - re_lu_121_loss: 9.5138 - re_lu_177_loss: 6.0405 - re_lu_233_loss: 4.5152 - re_lu_65_accuracy: 0.2696 - re_lu_121_accuracy: 0.6223 - re_lu_177_accuracy: 0.7090 - re_lu_233_accuracy: 0.8055 - val_loss: 155.5538 - val_re_lu_65_loss: 38.2660 - val_re_lu_121_loss: 37.8172 - val_re_lu_177_loss: 38.9603 - val_re_lu_233_loss: 40.5104 - val_re_lu_65_accuracy: 0.2384 - val_re_lu_121_accuracy: 0.5195 - val_re_lu_177_accuracy: 0.5715 - val_re_lu_233_accuracy: 0.7436\n",
      "Learning rate:  0.0005\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 39.0291 - re_lu_65_loss: 19.8284 - re_lu_121_loss: 9.1903 - re_lu_177_loss: 5.7546 - re_lu_233_loss: 4.2558 - re_lu_65_accuracy: 0.2694 - re_lu_121_accuracy: 0.6390 - re_lu_177_accuracy: 0.7303 - re_lu_233_accuracy: 0.8128  ETA: 13s - loss: 39.0542 - re_lu_65_loss: 19.8466 - re_lu_121_loss: 9.1884 - re_lu_177_loss: 5.7582 - re_lu_233_loss: 4.2610 - re_lu_65_accurac\n",
      "Epoch 00023: loss improved from 40.49860 to 39.02914, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 39.0291 - re_lu_65_loss: 19.8284 - re_lu_121_loss: 9.1903 - re_lu_177_loss: 5.7546 - re_lu_233_loss: 4.2558 - re_lu_65_accuracy: 0.2694 - re_lu_121_accuracy: 0.6390 - re_lu_177_accuracy: 0.7303 - re_lu_233_accuracy: 0.8128 - val_loss: 155.9788 - val_re_lu_65_loss: 38.2220 - val_re_lu_121_loss: 37.7560 - val_re_lu_177_loss: 39.1972 - val_re_lu_233_loss: 40.8036 - val_re_lu_65_accuracy: 0.2641 - val_re_lu_121_accuracy: 0.5968 - val_re_lu_177_accuracy: 0.6300 - val_re_lu_233_accuracy: 0.7539\n",
      "Learning rate:  0.0005\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 37.9888 - re_lu_65_loss: 19.2572 - re_lu_121_loss: 8.9664 - re_lu_177_loss: 5.6022 - re_lu_233_loss: 4.1630 - re_lu_65_accuracy: 0.2928 - re_lu_121_accuracy: 0.6518 - re_lu_177_accuracy: 0.7274 - re_lu_233_accuracy: 0.8200  - ETA: 2:50 - loss: 37.8679 - re_lu_65_loss: 19.3600 - re_lu_121_loss: 9.0167 - re_lu_177_loss: 5.5178 - re_lu_233_loss: 3.9735 - re_lu_65_accuracy: 0.2902 - re_lu_121_ac - ETA: 2:39 - loss: 39.7386 - re_lu_65_loss: 19.8321 - re_lu_121_loss: 9.5199 - re_lu_177_loss: 5.9749 - re_lu_233_loss: 4.4117 - re_lu_65_accuracy: 0.2765 - re_lu_121_a - ETA: 2:27 - loss: 38.4148 - re_lu_65_loss: 19.4379 - re_lu_12 - ETA: 1:55 - loss: 38.1101 - re_lu_65_loss: 19.3501 - re_lu_121_loss: 9.0308 - re_lu_177_loss: 5.6008 - re_lu_233_loss: 4.1284 - re_lu_65_accuracy: 0.2846 - re_lu_121_accuracy: - ETA: 1:43 - loss: 38.1437 - re_lu_65_loss: 19.3784 - re_lu_121_loss: 9.0263 - re_lu_177_loss: 5.5992 - re_lu_233_loss: 4.1398 - re_lu_65_accuracy: 0.2835 - re_lu -  - ETA: 52s - - ETA: 9s - loss: 37.9241 - re_lu_65_loss: 19.2454 - re_lu_121_loss: 8.9561 - re_lu_177_loss: 5.5795 - re_lu_233_loss: 4.1431 - re_lu_65_accuracy: 0.2907 - re_lu_121_accuracy: 0.6523 - re_lu_177_accuracy: 0.7271 - re_l - ETA: 5s - loss: 37.8872 - re_lu_65_loss: 19.2380 - re_lu_121_loss: 8.9417 - re_lu_177_loss: 5.5714 - re_lu_233_loss: 4.1361 - re_lu_65_accuracy: 0.2928 - re_lu_121_accuracy: 0.6535 - re_lu_177_accuracy: 0.7290 - re_lu_233_a - ETA: 2s - loss: 37.9830 - re_lu_65_loss: 19.2576 - re_lu_121_loss: 8.9650 - re_lu_177_loss: 5.5985 - re_lu_233_loss: 4.1619 - re_lu_65_accuracy: 0.2928 - re_lu_121_accuracy: 0.6525 - re_lu_177_accuracy: 0.7283 - re_lu_233_ac\n",
      "Epoch 00024: loss improved from 39.02914 to 37.98883, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 37.9888 - re_lu_65_loss: 19.2572 - re_lu_121_loss: 8.9664 - re_lu_177_loss: 5.6022 - re_lu_233_loss: 4.1630 - re_lu_65_accuracy: 0.2928 - re_lu_121_accuracy: 0.6518 - re_lu_177_accuracy: 0.7274 - re_lu_233_accuracy: 0.8200 - val_loss: 155.0235 - val_re_lu_65_loss: 38.1882 - val_re_lu_121_loss: 37.8083 - val_re_lu_177_loss: 39.0516 - val_re_lu_233_loss: 39.9752 - val_re_lu_65_accuracy: 0.2918 - val_re_lu_121_accuracy: 0.5815 - val_re_lu_177_accuracy: 0.6889 - val_re_lu_233_accuracy: 0.7579\n",
      "Learning rate:  0.0005\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.7080 - re_lu_65_loss: 18.6709 - re_lu_121_loss: 8.6948 - re_lu_177_loss: 5.3779 - re_lu_233_loss: 3.9645 - re_lu_65_accuracy: 0.3185 - re_lu_121_accuracy: 0.6496 - re_lu_177_accuracy: 0.7664 - re_lu_233_accuracy: 0.8170\n",
      "Epoch 00025: loss improved from 37.98883 to 36.70802, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 36.7080 - re_lu_65_loss: 18.6709 - re_lu_121_loss: 8.6948 - re_lu_177_loss: 5.3779 - re_lu_233_loss: 3.9645 - re_lu_65_accuracy: 0.3185 - re_lu_121_accuracy: 0.6496 - re_lu_177_accuracy: 0.7664 - re_lu_233_accuracy: 0.8170 - val_loss: 155.0266 - val_re_lu_65_loss: 38.1646 - val_re_lu_121_loss: 37.9214 - val_re_lu_177_loss: 38.9931 - val_re_lu_233_loss: 39.9475 - val_re_lu_65_accuracy: 0.2881 - val_re_lu_121_accuracy: 0.6149 - val_re_lu_177_accuracy: 0.6841 - val_re_lu_233_accuracy: 0.6990\n",
      "Learning rate:  0.0005\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.4265 - re_lu_65_loss: 18.0459 - re_lu_121_loss: 8.4094 - re_lu_177_loss: 5.1735 - re_lu_233_loss: 3.7978 - re_lu_65_accuracy: 0.3318 - re_lu_121_accuracy: 0.6702 - re_lu_177_accuracy: 0.7725 - re_lu_233_accuracy: 0.8209  - ETA: 2:48 - loss: 32.5410 - re_lu_65_loss: 17.1129 - re_lu_121_loss: 7.6166 - re_lu_177_loss: 4.5024 - re_lu_233_loss: 3.3090 - re_lu_65_accuracy: 0.3476 - re_lu_121_ac - ETA: 2:36 - loss: 33.8640 - re_lu_65_loss: 17.5498 - re_lu_121_loss: 7.9595 - re_lu_177_loss: 4.8185 - re_lu_233_loss: 3.5362 - re_lu_65_accuracy: 0.3421 - re_lu_121_accuracy: 0.7011 - re_lu_177_accur - ETA: 2:29 - loss: 33.7595 - re_lu_65_loss: 17.4692 - re_lu_121_loss: 7.9737 - re_lu_177_loss: 4.8067 - re_lu_233_loss: 3.5098 - re_lu_65_accuracy: 0.3408 - re_lu_121_accuracy: 0.7100 - re_lu_177_accuracy:  - ETA: 2:23 - loss: 34.0266 - re_lu_65_loss: 17.5328 - re_lu_121_loss: 7.9941 - re_lu_177_loss: 4.8931 - re_lu_233_loss: 3.6067 - re_lu_65_accuracy: 0.3375 - re_lu_121_accuracy: 0.7017 - re_lu_177_accuracy: 0.7905 - r - ETA: 2:19 - loss: 34.2411 - re_lu_65_loss: 17.5846 - re_lu_121_loss: 8.0154 - ETA: 1:49 - loss: 34.8088 - re_lu_65_loss: 17.7471 - re_lu_121_loss: 8.2445 - re_lu_177_loss: 5.0853 - re_lu_233_loss: 3.7320 - re_lu_65_accuracy: 0.3346 - re_lu_121_accuracy: 0.6877 - re_lu_177_accuracy: 0.7848 - re_lu_233_ - ETA: 1:46 - loss: 34.8361 - re_lu_65_loss: 17.7756 - re_lu_121_loss: 8.2646 - re_lu_177_loss: 5.0769 - re_lu_233_loss: 3.7189 - re_lu_65_accuracy: 0.3323 - re_lu_121_accuracy: 0.6846 - re_lu_177_ - ETA: 1:38 - loss: 34.9753 - re_lu_65_loss: 17.8595 - re_lu_121_loss: 8.2872 - re_lu_177_loss: 5.0890 - re_lu_233_loss: 3.7395 - re_lu_65_accuracy: 0.3309 - re_lu_121_accuracy: 0.6836 - re_lu_177_accuracy: 0.7835  - ETA: 1:33 - loss: 34.9920 - re_lu_65_loss: 17.8777 - re_lu_121_loss: 8.2812 - re_lu_177_loss: 5.0891 - re_lu_233_loss: 3.7439 - re_lu_65_accuracy: 0.3314 - re_lu_121_accuracy: 0.6827  - ETA: 1:23 - loss: 34.9084 - re_lu_65_loss: 17.8432 - re_lu_121_loss: 8.2613 - re_lu_177_loss: 5.0785 - re_lu_233_loss: 3.7254 - re_lu - ETA: 1:03 - loss: 34.9320 - re_lu_65_loss: 17.8569 - re_lu_121_loss: 8.2588 - re_lu_177_loss: 5.0772 - re_lu_233_loss: 3.7392 - re_lu_65_accuracy: 0.3327 - re_lu_121_accuracy: 0.6817 - re_lu_177_accuracy - ETA: 58s - loss: 34.9833 - re_lu_65_loss: 17.8819 - re_lu_121_loss: 8.2849 - re_lu_177_loss: 5.0825 - re_lu_233_loss: 3.7339 - re_lu_65_accuracy: 0.3315 - re_lu_121_accuracy: 0. - ETA: 52s - loss: 35.0495 - re_lu_65_loss: 17.9027 - re_lu_121_loss: 8.3118 - re_lu_177_loss: 5.0947 - re_lu_233_loss: 3.7403 - re_lu_65_accuracy: 0.3316 - re_lu_121_accuracy: 0.6776 - re_lu_177_accuracy: 0.7772  - ETA: 50s - loss: 35.1051 - re_lu_65_loss: 17.9069 - re_lu_121_loss: 8.3373 - re - ETA: 35s - loss: 35.1347 - re_lu_65_loss: 17.9268 - re_lu_121_loss: 8.3361 - re_lu_177_loss: 5.1144 - re_lu - ETA: 23s - loss: 35.3284 - re_lu_65_loss: 18.0145 - re_lu_121_loss: 8.3857 - re_lu_177_loss: 5.1505 - re_lu_233_loss: 3.7776 - re_lu_65_accuracy: 0.3331 - re_lu_121_accuracy: 0.6736 - re_lu_177_accuracy: 0.7757 - re_lu_ - ETA: 21s - loss: 35.3529 - re_lu_65_loss: 18.0235 - re_\n",
      "Epoch 00026: loss improved from 36.70802 to 35.42652, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 35.4265 - re_lu_65_loss: 18.0459 - re_lu_121_loss: 8.4094 - re_lu_177_loss: 5.1735 - re_lu_233_loss: 3.7978 - re_lu_65_accuracy: 0.3318 - re_lu_121_accuracy: 0.6702 - re_lu_177_accuracy: 0.7725 - re_lu_233_accuracy: 0.8209 - val_loss: 155.8660 - val_re_lu_65_loss: 38.3528 - val_re_lu_121_loss: 37.7944 - val_re_lu_177_loss: 39.2222 - val_re_lu_233_loss: 40.4966 - val_re_lu_65_accuracy: 0.3191 - val_re_lu_121_accuracy: 0.5900 - val_re_lu_177_accuracy: 0.6673 - val_re_lu_233_accuracy: 0.7230\n",
      "Learning rate:  0.0005\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 34.4699 - re_lu_65_loss: 17.5143 - re_lu_121_loss: 8.2141 - re_lu_177_loss: 5.0379 - re_lu_233_loss: 3.7035 - re_lu_65_accuracy: 0.3452 - re_lu_121_accuracy: 0.6736 - re_lu_177_accuracy: 0.7742 - re_lu_233_accuracy: 0.8333  - ETA: 2:51 - loss: 37.3447 - re_lu_65_loss: 18.4852 - re_lu_121_loss: 8.9272 - re_lu_177_loss: 5.7389 - re_lu_233_loss: 4.1934 - re_lu_65_accuracy: 0.3294 - re_lu_121_accuracy: 0.6511 - re_lu_177_accuracy: 0.7615 - ETA: 2:50 - loss: 33.9361 - re_lu_65_loss: 17.2012 - re_lu_121_loss: 8.1390 - re_ - ETA: 58s - loss: 34.1013 - re_lu_65_loss: 17.4706 - re_lu_121_loss: 8.1176 - re_lu_177_loss: 4.9135 - re_lu_233_loss: 3.5996 - re_lu_65_accuracy: 0.3432 - re_lu_121_accuracy - ETA: 52s - loss: 34.3369 - re_lu_65_loss: 17.5474 - re_lu_121_loss: 8.1783 - re_lu_177_loss: 4.9704 - re_lu_233_loss: 3.6407 - re_lu_65_accuracy: 0.3422 - re_lu_121_accuracy: 0.6722 - re_lu_177_accuracy: 0.777\n",
      "Epoch 00027: loss improved from 35.42652 to 34.46991, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 34.4699 - re_lu_65_loss: 17.5143 - re_lu_121_loss: 8.2141 - re_lu_177_loss: 5.0379 - re_lu_233_loss: 3.7035 - re_lu_65_accuracy: 0.3452 - re_lu_121_accuracy: 0.6736 - re_lu_177_accuracy: 0.7742 - re_lu_233_accuracy: 0.8333 - val_loss: 156.3251 - val_re_lu_65_loss: 38.5318 - val_re_lu_121_loss: 38.0108 - val_re_lu_177_loss: 39.0893 - val_re_lu_233_loss: 40.6932 - val_re_lu_65_accuracy: 0.3277 - val_re_lu_121_accuracy: 0.6042 - val_re_lu_177_accuracy: 0.6591 - val_re_lu_233_accuracy: 0.7793\n",
      "Learning rate:  0.0005\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 33.5274 - re_lu_65_loss: 17.0240 - re_lu_121_loss: 8.0264 - re_lu_177_loss: 4.8841 - re_lu_233_loss: 3.5928 - re_lu_65_accuracy: 0.3614 - re_lu_121_accuracy: 0.6863 - re_lu_177_accuracy: 0.7717 - re_lu_233_accuracy: 0.8353  - ETA: 2:49 - loss: 32.3226 - re_lu_65_loss: 16.4074 - re_lu_121_loss: 7.7722 - re_lu_177_loss: 4.7183 - re_lu_233_loss: 3.4246 - re_lu_65_accurac - ETA: 2:34 - loss: 31.7621 - re_lu_65_loss: 16.4391 - re_lu_121_loss: 7.5464 - re_lu_177_loss: 4.4744 - re_lu_233_loss: 3.3023 - re_lu_65_accuracy: 0.3852 - re_lu_121_accuracy: 0.7134 - r - ETA: 2:24 - loss: 32.2142 - re_lu_65_loss: 16.6156 - re_lu_121_loss: 7.6471 - re_lu_177_loss: 4.5727 - re_lu_233_loss: 3.3788 - re_lu_65_accuracy: 0.3793 - re_lu_121_accuracy: 0.7036 - re_lu_177_accuracy: 0.7959 - re_lu_233_accura - ETA: 2:23 - loss: 32.2090 - re_lu_65_loss: 16.6467 - re_lu_121_loss: 7.6305 - re_lu_177_loss: 4.5641 - re_lu_233_loss: 3.3676 - re_lu_65_accuracy: 0.3794 - re_lu_121_accuracy: 0.7034 - re_ - ETA: 1:29 - loss: 32.8645 - re_lu_65_loss: 16.7643 - re_lu_121_loss: 7.8122 - re_lu_177_loss: 4.7710 - re_lu_233_loss: 3.5169 - re_lu_65_accuracy: 0.3765 - re_lu_121_accuracy: 0.7030 - re_lu_177_accuracy: 0.7906 - re_lu_233_accuracy - ETA: 1:28 - loss: 32.8047 - re_lu_65_loss: 16.7533 - re_lu_121_loss: 7.7969 - re_lu_177_loss: 4.7527 - re_lu_233_loss: 3.5019 - re_lu_65_accuracy: 0.3767 - re_lu_121_accuracy: 0.7035 - re_lu_177_accuracy: 0.7912 \n",
      "Epoch 00028: loss improved from 34.46991 to 33.52741, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 33.5274 - re_lu_65_loss: 17.0240 - re_lu_121_loss: 8.0264 - re_lu_177_loss: 4.8841 - re_lu_233_loss: 3.5928 - re_lu_65_accuracy: 0.3614 - re_lu_121_accuracy: 0.6863 - re_lu_177_accuracy: 0.7717 - re_lu_233_accuracy: 0.8353 - val_loss: 156.0752 - val_re_lu_65_loss: 38.3814 - val_re_lu_121_loss: 37.9412 - val_re_lu_177_loss: 39.2873 - val_re_lu_233_loss: 40.4653 - val_re_lu_65_accuracy: 0.3404 - val_re_lu_121_accuracy: 0.5817 - val_re_lu_177_accuracy: 0.7003 - val_re_lu_233_accuracy: 0.7605\n",
      "Learning rate:  0.0005\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32.4580 - re_lu_65_loss: 16.4854 - re_lu_121_loss: 7.7905 - re_lu_177_loss: 4.7311 - re_lu_233_loss: 3.4510 - re_lu_65_accuracy: 0.3703 - re_lu_121_accuracy: 0.6932 - re_lu_177_accuracy: 0.7771 - re_lu_233_accuracy: 0.8454  ETA: 41s - loss: 32.4251 - re_l - ETA: 22s - loss: 32.3996 - re_lu_65_loss: 16.5023 - re_lu_121_loss: 7.7770 - re_lu_177_loss: 4.6989 - re_lu_233_loss: 3.4213 - re_lu_65_accuracy: 0.3692 - re_lu_121_accuracy: 0. - ETA: 17s - loss: 32.3941 - re_lu_65_loss: 16.4951 - re_lu_121_loss: 7.7686 - re_lu_177_loss: 4.7039 - re_lu_233_loss: 3.4265 - re_lu_65_accuracy: 0.3699 - re_lu_121_accuracy: 0.6968 - re_lu_1 - ETA: 12s - loss: 32.4316 - re_lu_65_loss: 16.5154 - re_lu_121_loss: 7.7817 - re_lu_177_loss: 4.7069 - re_lu_233_loss: 3.4276 - re_lu_65_accuracy: 0.3693 - re_lu_121_ac - ETA: 2s - loss: 32.4568 - re_lu_65_loss: 16.4903 - re_lu_121_loss: 7.7877 - re_lu_177_loss: 4.7287 - re_lu_233_loss: 3.4501 - re_lu_65_accuracy: 0.3700 - re_lu_121_accuracy: 0.6935 - re_lu_177_accuracy: 0.7776 - re_lu_233_accu\n",
      "Epoch 00029: loss improved from 33.52741 to 32.45798, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 32.4580 - re_lu_65_loss: 16.4854 - re_lu_121_loss: 7.7905 - re_lu_177_loss: 4.7311 - re_lu_233_loss: 3.4510 - re_lu_65_accuracy: 0.3703 - re_lu_121_accuracy: 0.6932 - re_lu_177_accuracy: 0.7771 - re_lu_233_accuracy: 0.8454 - val_loss: 157.4000 - val_re_lu_65_loss: 38.5985 - val_re_lu_121_loss: 38.5305 - val_re_lu_177_loss: 39.6363 - val_re_lu_233_loss: 40.6347 - val_re_lu_65_accuracy: 0.3322 - val_re_lu_121_accuracy: 0.5429 - val_re_lu_177_accuracy: 0.7062 - val_re_lu_233_accuracy: 0.7714\n",
      "Learning rate:  0.0005\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.4276 - re_lu_65_loss: 16.0010 - re_lu_121_loss: 7.5495 - re_lu_177_loss: 4.5609 - re_lu_233_loss: 3.3162 - re_lu_65_accuracy: 0.3928 - re_lu_121_accuracy: 0.6994 - re_lu_177_accuracy: 0.8008 - re_lu_233_accuracy: 0.8541  - ETA: 2:49 - loss: 31.5625 - re_lu_65_loss: 16.1394 - re_lu_121_loss: 7.7788 - re_lu_177_loss: 4.5463 - re_lu_233_loss: 3.0979 - re_lu_65_accuracy: 0.3979 - re_lu_1 - ETA: 2:42 - loss: 29.0365 - re_lu_65_loss: 15.1079 - re_lu_121_loss: 6.8745 - re_lu_177_loss: 4.0738 - re_lu_233_loss: 2.9803 - re_lu_65_accuracy: 0.4103 - re_lu_121_accuracy: 0.7449 - re_lu_177_accuracy - ETA: 2:36 - loss: 29.9783 - re_lu_65_loss: 15.4774 - re_lu_121_loss: 7.1456 - re_lu_177_loss: 4.2892 - re_lu_233_loss: 3.0660 - re_lu_65_accuracy: 0.4110 - re_lu_121_accuracy: 0.7329 - re_lu_177_accuracy: 0.8259 - re_lu_233_accuracy: 0.8 - ETA: 2:35 - loss: 30.0690 - re_lu_65_loss: 15.5257 - re_lu_121_loss: 7.1613 - re_lu_177_loss: 4.3049 - re_lu_233_loss: 3.0771 - re_lu_65_accuracy: 0.4087 - re_lu_121_accuracy: 0.7311 - re_lu_177_accuracy: 0.8240 - re_lu_233_accur - ETA: 2:34 - loss: 30.3429 - re_lu_65_loss: 15.6406 - re_lu_121_loss: 7.2504 - re_lu_177_loss: 4.3554 - re_lu_233_loss: 3.0964 - re_lu_65_accuracy: 0.4011 - re_lu_121_accuracy: 0.7243 - re_lu_177_accuracy: 0.8179 - re - ETA: 2:29 - loss: 30.4254 - re_lu_65_loss: 15.6765 - re_lu_121_loss: 7.2790 - re_lu_177_loss: 4.3726 - re_lu_233_loss: 3.0973 - re_lu_65_accuracy: 0.4021 - re_lu_1 - ETA: 2:16 - loss: 30.2896 - re_lu_65_loss: 15.5718 - re - ETA: 1:43 - loss: 30.5456 - re_lu_65_loss: 15.6680 - re_lu_121_loss: 7.2932 - re_lu_177_loss: 4.4022 - re_lu_233_loss: 3.1822 - re_lu_65_accuracy: 0.4083 - re_lu_121_accuracy: 0.7200 - re_lu_177_accuracy: 0.8141 - re_ - ETA: 1:38 - loss: 30.6637 - re_lu_65_loss: 15.6975 - re_lu_121_loss: 7.3272 - re_lu_177_loss: 4.4358 - re_lu_233_loss: 3.2032 - re_lu_65_accuracy: 0.4071 - re_lu_121_accuracy: 0.7174 - re_lu_177_accuracy: 0.8127 - r - ETA: 1:34 - loss: 30.6174 - re_lu_65_loss: 15.7061 - re_lu_121_loss: 7.3156 - re_lu_177_loss: 4.4102 - re_lu_233_loss: 3.1854 - re_lu_65_accuracy: 0.4053 - re_lu_121_accuracy:\n",
      "Epoch 00030: loss improved from 32.45798 to 31.42760, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 31.4276 - re_lu_65_loss: 16.0010 - re_lu_121_loss: 7.5495 - re_lu_177_loss: 4.5609 - re_lu_233_loss: 3.3162 - re_lu_65_accuracy: 0.3928 - re_lu_121_accuracy: 0.6994 - re_lu_177_accuracy: 0.8008 - re_lu_233_accuracy: 0.8541 - val_loss: 154.7258 - val_re_lu_65_loss: 38.2643 - val_re_lu_121_loss: 37.6734 - val_re_lu_177_loss: 38.9672 - val_re_lu_233_loss: 39.8209 - val_re_lu_65_accuracy: 0.3462 - val_re_lu_121_accuracy: 0.6460 - val_re_lu_177_accuracy: 0.6602 - val_re_lu_233_accuracy: 0.7177\n",
      "Learning rate:  0.0005\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 30.6091 - re_lu_65_loss: 15.5318 - re_lu_121_loss: 7.3743 - re_lu_177_loss: 4.4485 - re_lu_233_loss: 3.2545 - re_lu_65_accuracy: 0.4026 - re_lu_121_accuracy: 0.7047 - re_lu_177_accuracy: 0.8006 - re_lu_233_accuracy: 0.8499  - ETA: 2:34 - loss: 29.6161 - re_lu_65_loss: 15.1254 - re_lu_121_loss: 7.1223 - re_lu_177_loss: 4.2479 - re_lu_233_loss: 3.1205 - re_lu_65_accuracy: 0 - ETA: 2:18 - loss: 29.9964 - re_lu_65_loss: 15.3931 - re_lu_121_loss: 7.1839 - re_lu_177_loss: 4.2893 - re_lu_233_loss: 3.1300 - re_lu_65_accuracy: 0.4015 - re_lu_121_accuracy: 0.7026 - re_lu_1 - ETA: 2:10 - loss: 29.6716 - re_lu_65_loss: 15.2577 - re_lu_121_loss: 7.0730 - re_lu_177_loss: 4.2328 - re_lu_233_loss: 3.1081 - re_lu_65_accuracy: 0.4133 - re_lu_121_accuracy: 0.7123 - re_lu_177 - ETA: 2:01 - loss: 29.7290 - re_lu_65_loss: 15.2827 - re_lu_121_loss: 7.0725 - re_lu_177_loss: - ETA: 1:35 - loss: 30.0532 - re_lu_65_loss: 15.3711 - re_lu_121_loss: 7.2234 - re_lu_177_loss: 4.3037 - re_lu_233_loss: 3.1551 - re_lu_65_accuracy: 0.4066 - re_lu_121_accuracy: 0.7118 - re_lu_177_ - ETA: 29s - loss: 30.6251 - re_lu_65_loss: 15.5540 - re_lu_121_loss: 7.3730 - re_lu_177_loss: 4.4367 - re_lu_233_loss: 3.2614 - re_lu_65_accuracy: 0.4023 - re_lu_121_accuracy: 0.7061 - re_lu_177_accuracy: - ETA: 25s \n",
      "Epoch 00031: loss improved from 31.42760 to 30.60906, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 30.6091 - re_lu_65_loss: 15.5318 - re_lu_121_loss: 7.3743 - re_lu_177_loss: 4.4485 - re_lu_233_loss: 3.2545 - re_lu_65_accuracy: 0.4026 - re_lu_121_accuracy: 0.7047 - re_lu_177_accuracy: 0.8006 - re_lu_233_accuracy: 0.8499 - val_loss: 155.6657 - val_re_lu_65_loss: 38.6368 - val_re_lu_121_loss: 38.0889 - val_re_lu_177_loss: 39.0483 - val_re_lu_233_loss: 39.8917 - val_re_lu_65_accuracy: 0.4534 - val_re_lu_121_accuracy: 0.6197 - val_re_lu_177_accuracy: 0.6845 - val_re_lu_233_accuracy: 0.7382\n",
      "Learning rate:  0.0005\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29.5452 - re_lu_65_loss: 15.0348 - re_lu_121_loss: 7.1366 - re_lu_177_loss: 4.2694 - re_lu_233_loss: 3.1044 - re_lu_65_accuracy: 0.4266 - re_lu_121_accuracy: 0.7175 - re_lu_177_accuracy: 0.8045 - re_lu_233_accuracy: 0.8583  - ETA: 1:47 - loss: 29.0967 - re_lu_65_loss: 14.8015 - re_lu_121_loss: 7.0174 - re_lu_177_loss: 4.2197 - re_lu_233_loss: 3. - ETA: 28s - loss: 29.5293 - re_ - ETA: 8s - loss: 29.5110 - re_lu_65_loss: 15.0228 - re_lu_121_loss: 7.1312 - re_lu_177_loss: 4.2636 - re_lu_233_loss: 3.0933 - re_lu_65_accuracy: 0.4277 - re_lu_121_accuracy: 0.7178 - re_lu_177_accuracy: 0.8042 - re_lu_2 - ETA: 5s - loss: 29.5356 - re_lu_65_loss: 15.0404 - re_lu_121_loss: 7.1407 - re_lu_177_loss: 4.2625 - re_lu_233_loss: 3.0920 - re_lu_65_accuracy: 0.4271 - re_lu_121_accuracy: 0.7176 - re_lu_177_accuracy: 0.8045 - re_lu_233_accuracy: - ETA: 4s - loss: 29.5194 - re_lu_65_loss: 15.0357 - re_lu_121_loss: 7.1337 - re_lu_177_loss: 4.2581 - re_lu_233_loss: 3.0918 - re_lu_65_accuracy: 0.4266 - re_lu_121_accuracy: 0.7174 - re_lu_177_accuracy: 0.8045 - re_\n",
      "Epoch 00032: loss improved from 30.60906 to 29.54523, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 29.5452 - re_lu_65_loss: 15.0348 - re_lu_121_loss: 7.1366 - re_lu_177_loss: 4.2694 - re_lu_233_loss: 3.1044 - re_lu_65_accuracy: 0.4266 - re_lu_121_accuracy: 0.7175 - re_lu_177_accuracy: 0.8045 - re_lu_233_accuracy: 0.8583 - val_loss: 156.8602 - val_re_lu_65_loss: 38.7846 - val_re_lu_121_loss: 38.2033 - val_re_lu_177_loss: 39.3791 - val_re_lu_233_loss: 40.4932 - val_re_lu_65_accuracy: 0.4003 - val_re_lu_121_accuracy: 0.6818 - val_re_lu_177_accuracy: 0.7016 - val_re_lu_233_accuracy: 0.7637\n",
      "Learning rate:  0.0005\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 28.8720 - re_lu_65_loss: 14.6259 - re_lu_121_loss: 7.0016 - re_lu_177_loss: 4.1986 - re_lu_233_loss: 3.0459 - re_lu_65_accuracy: 0.4326 - re_lu_121_accuracy: 0.7312 - re_lu_177_accuracy: 0.8137 - re_lu_233_accuracy: 0.8589  - ETA: 2:41 - loss: 27.5095 - re_lu_65_loss: 13.9448 - re_lu_121_loss: 6.6507 - re_lu_177_loss: 3.9561 - re_lu_233_loss: 2.9579 - re_lu_65_accuracy: 0.4588 - re - ETA: 2:27 - loss: 28.2092 - re_lu_65_loss: 14.2861 - re_lu_121_loss: 6.8134 - re_lu_177_loss: 4.0750 - re_lu_233_loss: 3.0348 - re_lu_65_accuracy: 0.4481 - re_lu_121_accurac - ETA: 2:15 - loss: 28.2206 - re_lu_65_loss: 14.2885 - re_lu_121_loss: 6.8262 - re_lu_177_loss: 4.0765 - re_lu_233_loss: 3.0294 - re_lu_65_accuracy: 0.4493 - re_lu_121_accuracy: 0.7432 - re_lu_177_accuracy: 0.8415 - re_lu_233_accuracy:  - ETA: 2:14 - loss: 28.1566 - re_lu_65_loss: 14.2715 - re_lu_121_loss: 6.8132 - re_lu_177_loss: 4.0608 - re_lu_233_loss: 3.0111 - re_lu_65_accuracy: 0.4501 - re_lu_121_ac - ETA: 2:01 - loss: 28.2586 - re_lu_65_loss: 14.3407 - re_lu_121_loss: 6.8417 - re_l - ETA: 1:33 - loss: 28.5887 - re_lu_65_loss: 14.5460 - re_lu_121_loss: 6.9247 - re_lu_177_loss: 4.1159 - re_lu_233_loss: 3.0022 - re_lu_65_accuracy: 0.4365 - re_lu_121_accuracy: 0.7318 - re_lu_177_accuracy: 0.8293 - re_lu_23 - ETA: 1:29 - loss: 28.8316 - re_lu_65_loss: 14.6128 - re_lu_121_loss: 7.0004 - re_lu_177_loss: 4.1817 - re_lu_233_loss: 3.0368 - re_lu_65_accuracy: 0.4347 - re_lu_121_accuracy: 0.7280 - re_lu_177_accurac - ETA: 1:23 - loss: 28.8941 - re_lu_65_loss: 14.6307 - re_lu_121_loss: 7.0354 - re_lu_177_loss: 4.1927 - re_lu_233_loss: 3.0353 - re_lu_65_accuracy: 0.4329 - re_lu_121_accu - ETA: 1:10 - loss: 28.6909 - re_lu_65_loss: 14.5708 - re_lu_121_loss: 6.9606 - re_lu_177_loss: 4.1501 - re_lu_233_loss: 3.0094 - re_lu_65_accuracy: 0.4344 - re_l - ETA: 57s - loss: 28.5163 - re_lu_65_loss: 14.4962 - re_lu_121_loss: 6.9049 - re_lu_177_loss: 4.1228 - re_lu_233_loss: 2.9925 - re_lu_65_accuracy: 0.4354 - re_lu_121_accuracy: 0.7309 - re_lu_177_accuracy: 0.8205 - re_lu_233_ac - ETA: 56s - loss: 28.5171 - re_lu_65_loss: 14.4965 - re_lu_121_loss: 6.9030 - re_lu_177_loss: 4.1234 - re_lu - ETA: 44s - loss: 28.7132 - re_lu_65_loss: 14.5675 - re_lu_121_loss: 6.9560 - re_lu_177_loss: 4.1667 - re_lu_2 - ETA: 32s - loss: 28.7841 - re_lu_65_loss: 14.5998 - re_lu_121_loss: 6.9683 - re_lu_177_loss: 4.1812 - re_lu_233_loss: 3.0347 - re_lu_65_accuracy: 0 - ETA: 24s - loss: 28.9166 - re_lu_65_loss: - ETA: 2s - loss: 28.8769 - re_lu_65_loss: 14.6300 - re_lu_121_loss: 7.0042 - re_lu_177_loss: 4.1973 - re_lu_233_loss: 3.0453 - re_lu_65_accuracy: 0.4318 - re_lu_121_accuracy: 0.7308 - re_lu_177_accuracy: 0.8134 - re_lu_233_ac\n",
      "Epoch 00033: loss improved from 29.54523 to 28.87199, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 28.8720 - re_lu_65_loss: 14.6259 - re_lu_121_loss: 7.0016 - re_lu_177_loss: 4.1986 - re_lu_233_loss: 3.0459 - re_lu_65_accuracy: 0.4326 - re_lu_121_accuracy: 0.7312 - re_lu_177_accuracy: 0.8137 - re_lu_233_accuracy: 0.8589 - val_loss: 156.6835 - val_re_lu_65_loss: 38.7929 - val_re_lu_121_loss: 38.3566 - val_re_lu_177_loss: 39.2661 - val_re_lu_233_loss: 40.2679 - val_re_lu_65_accuracy: 0.3709 - val_re_lu_121_accuracy: 0.6806 - val_re_lu_177_accuracy: 0.6850 - val_re_lu_233_accuracy: 0.7814\n",
      "Learning rate:  0.0005\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 28.0331 - re_lu_65_loss: 14.2351 - re_lu_121_loss: 6.7955 - re_lu_177_loss: 4.0576 - re_lu_233_loss: 2.9449 - re_lu_65_accuracy: 0.4677 - re_lu_121_accuracy: 0.7309 - re_lu_177_accuracy: 0.8213 - re_lu_233_accuracy: 0.8657\n",
      "Epoch 00034: loss improved from 28.87199 to 28.03313, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 28.0331 - re_lu_65_loss: 14.2351 - re_lu_121_loss: 6.7955 - re_lu_177_loss: 4.0576 - re_lu_233_loss: 2.9449 - re_lu_65_accuracy: 0.4677 - re_lu_121_accuracy: 0.7309 - re_lu_177_accuracy: 0.8213 - re_lu_233_accuracy: 0.8657 - val_loss: 156.8470 - val_re_lu_65_loss: 39.0473 - val_re_lu_121_loss: 38.6403 - val_re_lu_177_loss: 39.1514 - val_re_lu_233_loss: 40.0080 - val_re_lu_65_accuracy: 0.4479 - val_re_lu_121_accuracy: 0.6293 - val_re_lu_177_accuracy: 0.6275 - val_re_lu_233_accuracy: 0.7710\n",
      "Learning rate:  0.0005\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 27.2498 - re_lu_65_loss: 13.8139 - re_lu_121_loss: 6.6358 - re_lu_177_loss: 3.9401 - re_lu_233_loss: 2.8599 - re_lu_65_accuracy: 0.4816 - re_lu_121_accuracy: 0.7349 - re_lu_177_accuracy: 0.8293 - re_lu_233_accuracy: 0.8682  - ETA: 2:44 - loss: 28.5387 - re_lu_65_loss: 14.2316 - re_lu_121_loss: 7.1058 - re_lu_177_loss: 4.2135 - re_lu_233_loss: 2.9877 - re_lu_65_accuracy: 0.4748 - re_lu_121_accuracy: 0.7316 - re_lu_17 - ETA: 2:36 - l - ETA: 1:56 - loss: 27.0597 - re_lu_65_loss: 13.8765 - re_lu_121_loss: 6.5626 - re_lu_177_loss: 3.8504 - re_lu_233_loss: 2.7701 - re_lu_65_accuracy: 0.4755 - re_lu_121_accuracy: 0.7462 - re_lu_177_accuracy: 0.8376 - re_lu_233_accurac - ETA: 1:54 - loss: 27.1281 - re_lu_65_loss: 13.9002 - re_lu_121_loss: 6.5823 - re_lu_177_loss: 3.8639 - re_lu - ETA - ETA: 8s - loss: 27.2886 - re_lu_65_loss: 13.8366 - re_lu_121_loss: 6.6478 - re_lu_177_loss: 3.9427 - re_lu_233_loss: 2.8615 - re_lu_65_accuracy: 0.4811 - re_lu_121_accuracy: 0.7350 - re_lu_17\n",
      "Epoch 00035: loss improved from 28.03313 to 27.24976, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 27.2498 - re_lu_65_loss: 13.8139 - re_lu_121_loss: 6.6358 - re_lu_177_loss: 3.9401 - re_lu_233_loss: 2.8599 - re_lu_65_accuracy: 0.4816 - re_lu_121_accuracy: 0.7349 - re_lu_177_accuracy: 0.8293 - re_lu_233_accuracy: 0.8682 - val_loss: 156.7267 - val_re_lu_65_loss: 38.5550 - val_re_lu_121_loss: 38.4210 - val_re_lu_177_loss: 39.2990 - val_re_lu_233_loss: 40.4517 - val_re_lu_65_accuracy: 0.4746 - val_re_lu_121_accuracy: 0.6442 - val_re_lu_177_accuracy: 0.7171 - val_re_lu_233_accuracy: 0.7900\n",
      "Learning rate:  0.0005\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 26.5244 - re_lu_65_loss: 13.4467 - re_lu_121_loss: 6.4616 - re_lu_177_loss: 3.8398 - re_lu_233_loss: 2.7763 - re_lu_65_accuracy: 0.4960 - re_lu_121_accuracy: 0.7438 - re_lu_177_accuracy: 0.8295 - re_lu_233_accuracy: 0.8742  - ETA: 1:30 - loss: 25.9735 - re_lu_65_loss: 13.2534 - re_lu_121_loss: 6.3031 - re_lu_177_los - ETA: 39s - loss: 26.3541 - re_lu_65_loss: 13.3659 - re_lu_121_loss: 6.4429 - re_lu_177_loss:  - ETA: 25s - loss: 26.5161 - re_lu_65_loss: 13.4351 - re_lu_121_loss: 6.4665 - re_lu_177_loss: 3.8437 - re_lu_233_loss: 2.7707 - re_lu_65_accuracy: 0.4963 - re_lu_121_accuracy: 0.7437 - re_lu_177_accuracy: 0.8291 - re - ETA: 23s - loss: 26.5135 - re_lu_\n",
      "Epoch 00036: loss improved from 27.24976 to 26.52444, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 26.5244 - re_lu_65_loss: 13.4467 - re_lu_121_loss: 6.4616 - re_lu_177_loss: 3.8398 - re_lu_233_loss: 2.7763 - re_lu_65_accuracy: 0.4960 - re_lu_121_accuracy: 0.7438 - re_lu_177_accuracy: 0.8295 - re_lu_233_accuracy: 0.8742 - val_loss: 156.6634 - val_re_lu_65_loss: 38.8618 - val_re_lu_121_loss: 38.0919 - val_re_lu_177_loss: 39.3079 - val_re_lu_233_loss: 40.4017 - val_re_lu_65_accuracy: 0.5059 - val_re_lu_121_accuracy: 0.7274 - val_re_lu_177_accuracy: 0.7392 - val_re_lu_233_accuracy: 0.7386\n",
      "Learning rate:  0.0005\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25.7133 - re_lu_65_loss: 13.0471 - re_lu_121_loss: 6.2671 - re_lu_177_loss: 3.7097 - re_lu_233_loss: 2.6893 - re_lu_65_accuracy: 0.5189 - re_lu_121_accuracy: 0.7441 - re_lu_177_accuracy: 0.8298 - re_lu_233_accuracy: 0.8746  - ETA: 2:51 - loss: 24.4669 - re_lu_65_loss: 12.4517 - re_lu_121_loss: 5.8903 - re_lu_177_loss: 3.6120 - re_lu_233_loss: 2.5130 - re_ - ETA: 2:36 - loss: 24.4935 - re_lu_65_loss: 12.3350 - re_lu_121_loss: 5.9995 - re_lu_177_loss: 3.5942 - re_lu_233_loss: 2.5648 - re_lu_65_accuracy: 0.5645 - re_lu_121_accuracy: 0.7785 - re_lu_177_accuracy: 0.8525 - re_ - ETA: 2:32 - loss: 24.6716 - re_lu_65_loss: 12.3767 - re_lu_121_loss: 6.0414 - re_lu_177_loss: 3.6435 - re_lu_233_loss: 2.6099 - re_lu_65_accuracy: 0.5637 - re_lu_121_accuracy: 0.7736 - re_lu_177_accuracy: 0.8478 - ETA: 2:27 - loss: 24.4443 - re_lu_65_loss: 12.2952 - re_lu_121_loss: 5.9626 - re_lu_177_loss: 3.5891 - re_lu_233_loss: 2.5975 - re_lu_65_accuracy: 0. - ETA: 2:10 - loss: 24.9604 - re_lu_65_loss: 12.6494 - re_lu_121_loss: 6.0736 - re_l - ETA: 59s - loss: 25.9324 - re_lu_65_loss: 1 - ETA: 18s - loss: 25.7767 - re_lu_65_loss: 13.0535 - re_lu_121_loss: 6.2918 - re_lu_177_loss: 3.7323 - re_lu_233_loss: 2.6992 - re_lu_65_accuracy: 0.5178 - re_lu_121_accuracy: 0.74 - ETA: 13s - loss: 25.7290 - re_lu_65_loss: 13.0349 - re_lu_121_loss: 6.2837 - re_lu_177_loss: 3.7206 - re_lu_233_loss: 2.6897 - re_lu_65_accuracy: 0\n",
      "Epoch 00037: loss improved from 26.52444 to 25.71330, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 25.7133 - re_lu_65_loss: 13.0471 - re_lu_121_loss: 6.2671 - re_lu_177_loss: 3.7097 - re_lu_233_loss: 2.6893 - re_lu_65_accuracy: 0.5189 - re_lu_121_accuracy: 0.7441 - re_lu_177_accuracy: 0.8298 - re_lu_233_accuracy: 0.8746 - val_loss: 157.0112 - val_re_lu_65_loss: 38.7435 - val_re_lu_121_loss: 38.2354 - val_re_lu_177_loss: 39.3864 - val_re_lu_233_loss: 40.6459 - val_re_lu_65_accuracy: 0.5230 - val_re_lu_121_accuracy: 0.7082 - val_re_lu_177_accuracy: 0.7295 - val_re_lu_233_accuracy: 0.8325\n",
      "Learning rate:  0.0005\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25.0704 - re_lu_65_loss: 12.7497 - re_lu_121_loss: 6.1116 - re_lu_177_loss: 3.6118 - re_lu_233_loss: 2.5973 - re_lu_65_accuracy: 0.5360 - re_lu_121_accuracy: 0.7483 - re_lu_177_accuracy: 0.8461 - re_lu_233_accuracy: 0.8817  - ETA: 2:01 - loss: 24.0905 - re_lu_65_loss: 12.4087 - re_lu_121_loss: 5.8782 - re_lu_177_loss: 3.3714 - re_lu_233_loss: 2.4322 - re_lu_65_accuracy: 0.5512 - re_lu_121_accuracy: 0. - ETA: 1:50 - loss: 24.2369 - re_lu_65_loss: 12.4 - ETA: 23s - loss: 25.0716 - re_lu_65_los\n",
      "Epoch 00038: loss improved from 25.71330 to 25.07035, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 25.0704 - re_lu_65_loss: 12.7497 - re_lu_121_loss: 6.1116 - re_lu_177_loss: 3.6118 - re_lu_233_loss: 2.5973 - re_lu_65_accuracy: 0.5360 - re_lu_121_accuracy: 0.7483 - re_lu_177_accuracy: 0.8461 - re_lu_233_accuracy: 0.8817 - val_loss: 154.9319 - val_re_lu_65_loss: 38.5963 - val_re_lu_121_loss: 37.8026 - val_re_lu_177_loss: 38.8180 - val_re_lu_233_loss: 39.7151 - val_re_lu_65_accuracy: 0.5183 - val_re_lu_121_accuracy: 0.6464 - val_re_lu_177_accuracy: 0.6909 - val_re_lu_233_accuracy: 0.7316\n",
      "Learning rate:  0.0005\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.4048 - re_lu_65_loss: 12.4157 - re_lu_121_loss: 5.9385 - re_lu_177_loss: 3.5188 - re_lu_233_loss: 2.5318 - re_lu_65_accuracy: 0.5548 - re_lu_121_accuracy: 0.7524 - re_lu_177_accuracy: 0.8591 - re_lu_233_accuracy: 0.8808  - ETA: 1:17 - loss: 24.1265  - ETA: 26s - loss: 24.4995 - re_lu_65_loss: 12.4697 - re_lu_121_loss: 5.9 - ETA: 10s - loss: 24.4054 - re_lu_65_loss: 12.4183 - re_lu_121_loss: 5.9404 - re_lu_177_loss: 3.5167 - re_lu_233_loss: 2.5301 - re_lu_65_accuracy: 0.5548 - re_lu_121_accuracy: 0.7533 - re_lu_177_accuracy: 0.8600 - re_lu_233_accu - ETA: 9s - loss: 24.3867 - re_lu_65_loss: 12.4127 - re_lu_121_loss: 5.9350 - re_lu_177_loss: 3.5122 - re_lu_233_loss: 2.5268 - re_lu_65_accuracy: 0.5550 - re_lu_121_accuracy: 0.7532 - re_lu_177_accuracy: 0.8600 - r - ETA: 4s - loss: 24.3663 - re_lu_65_loss: 12.3974 - re_lu_121_loss: 5.9280 - re_lu_177_loss: 3.5098 - re_lu_233_loss: 2.5311 - re_lu_65_accuracy: 0.5554 - re_lu_121_accuracy: 0.7534 - re_lu_177_accuracy: 0.8599 -\n",
      "Epoch 00039: loss improved from 25.07035 to 24.40475, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 24.4048 - re_lu_65_loss: 12.4157 - re_lu_121_loss: 5.9385 - re_lu_177_loss: 3.5188 - re_lu_233_loss: 2.5318 - re_lu_65_accuracy: 0.5548 - re_lu_121_accuracy: 0.7524 - re_lu_177_accuracy: 0.8591 - re_lu_233_accuracy: 0.8808 - val_loss: 156.2519 - val_re_lu_65_loss: 38.5407 - val_re_lu_121_loss: 38.3291 - val_re_lu_177_loss: 39.0087 - val_re_lu_233_loss: 40.3734 - val_re_lu_65_accuracy: 0.5641 - val_re_lu_121_accuracy: 0.6873 - val_re_lu_177_accuracy: 0.7126 - val_re_lu_233_accuracy: 0.6799\n",
      "Learning rate:  0.0005\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.7843 - re_lu_65_loss: 12.1190 - re_lu_121_loss: 5.7928 - re_lu_177_loss: 3.4140 - re_lu_233_loss: 2.4584 - re_lu_65_accuracy: 0.5683 - re_lu_121_accuracy: 0.7519 - re_lu_177_accuracy: 0.8514 - re_lu_233_accuracy: 0.8878  - ETA: 1:49 - loss: 23.7475 - re_lu_65_loss: 12.1644 - re_lu_121_loss: 5.7789 - re_ - ETA: 1:20 - loss: 23.9668 - re_lu_65 - ETA: 4s - loss: 23.7945 - re_lu_65_loss: 12.1227 - re_lu_121_loss: 5.7978 - re_lu_177_loss: 3.4173 - re_lu_233_loss: 2.4567 - re_lu_65_accuracy: 0.5683 - re_lu_121_accuracy: 0.7513 - re_lu_177_accuracy: 0.8509 - r\n",
      "Epoch 00040: loss improved from 24.40475 to 23.78432, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 23.7843 - re_lu_65_loss: 12.1190 - re_lu_121_loss: 5.7928 - re_lu_177_loss: 3.4140 - re_lu_233_loss: 2.4584 - re_lu_65_accuracy: 0.5683 - re_lu_121_accuracy: 0.7519 - re_lu_177_accuracy: 0.8514 - re_lu_233_accuracy: 0.8878 - val_loss: 155.6046 - val_re_lu_65_loss: 38.6468 - val_re_lu_121_loss: 38.1217 - val_re_lu_177_loss: 38.7495 - val_re_lu_233_loss: 40.0865 - val_re_lu_65_accuracy: 0.5792 - val_re_lu_121_accuracy: 0.6962 - val_re_lu_177_accuracy: 0.7299 - val_re_lu_233_accuracy: 0.7770\n",
      "Learning rate:  0.0005\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.2650 - re_lu_65_loss: 11.8312 - re_lu_121_loss: 5.6755 - re_lu_177_loss: 3.3465 - re_lu_233_loss: 2.4118 - re_lu_65_accuracy: 0.5793 - re_lu_121_accuracy: 0.7527 - re_lu_177_accuracy: 0.8551 - re_lu_233_accuracy: 0.8895  - ETA: 2:51 - loss:  - ETA: 1:31 - loss: 22.7790 - re_lu_65_loss: 11.6641 - re_lu_121_loss: 5.5119 - re_lu_177_loss: 3.2569 - re_lu_233_loss: 2.3460 - re_lu_65_accuracy: 0.5851 - re_lu_121_accuracy: 0.7599 - re_lu_177_accur - ETA: 1:24 - loss: 22.7992 - re_lu_65_loss: 11.6788 - re_lu_121_loss: 5.5236 - re_lu_177_loss: 3.2532 - re_lu_233_loss: 2.3435 - re_lu_65_accuracy: 0.5828 - re_lu_121_accuracy: 0.7586 - re_lu_177_ - ETA: 1:16 - loss: 22.8641 - re_lu_65_loss: 11.7076 - re_lu_121_loss: 5.5356 - re_lu_177 - ETA: 32s - loss: 23.1056 - re_lu_65_loss: 11.7802 - re_lu_121_loss: 5.6271 - re_lu_177_loss: 3.3125 - re_lu_233_loss: 2.3857 - re_l - ETA: 22s - loss: 23.1695 - re_lu_65_loss: 11.7966 - re_lu_121_loss: 5.6432 - re_lu_177_loss: 3.3316 - re_lu_233_loss: 2.3981 - re_lu_65_accuracy: 0.5811 - re_lu_121_accuracy: 0.7547 - re_lu_177_acc - ETA: 18s - loss: 23.1635 - re_lu_65_loss: 11.8065 - re_lu_121_loss: 5.6421 - re_lu_177_loss: \n",
      "Epoch 00041: loss improved from 23.78432 to 23.26504, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 23.2650 - re_lu_65_loss: 11.8312 - re_lu_121_loss: 5.6755 - re_lu_177_loss: 3.3465 - re_lu_233_loss: 2.4118 - re_lu_65_accuracy: 0.5793 - re_lu_121_accuracy: 0.7527 - re_lu_177_accuracy: 0.8551 - re_lu_233_accuracy: 0.8895 - val_loss: 156.6506 - val_re_lu_65_loss: 38.6312 - val_re_lu_121_loss: 38.5235 - val_re_lu_177_loss: 39.3784 - val_re_lu_233_loss: 40.1175 - val_re_lu_65_accuracy: 0.5624 - val_re_lu_121_accuracy: 0.6547 - val_re_lu_177_accuracy: 0.6824 - val_re_lu_233_accuracy: 0.8120\n",
      "Learning rate:  0.0005\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 22.6330 - re_lu_65_loss: 11.5490 - re_lu_121_loss: 5.5109 - re_lu_177_loss: 3.2483 - re_lu_233_loss: 2.3248 - re_lu_65_accuracy: 0.5982 - re_lu_121_accuracy: 0.7699 - re_lu_177_accuracy: 0.8640 - re_lu_233_accuracy: 0.8920  - ETA: 1:46 - loss: 22.0386 - re_lu_65_loss: 11.2515 - re_lu_121_loss: 5.3547 - re_lu_177_loss: 3.1746 - re_lu_233_loss: 2.2578 - re_lu_65_accuracy: 0.6072 - re_lu_121_accuracy - ETA: 32s - loss: 22.4072 - re_lu_65_loss: 11.4471 - re_lu_121_loss: 5.4432 - re_lu_177_loss: 3.2108 - re_lu_233_loss: 2.3061 - re_lu_65_accuracy: 0.6026 - re_lu_121_accuracy: 0.7769 - re_ - ETA: 27s - loss: 22.3594 - re_l - ETA: 7s - loss: 22.5840 - re_lu_65_loss: 11.5331 - re_lu_121_loss: 5.4893 - re_lu_177_loss: 3.2372 - re_lu_233_loss: 2.3244 - re_lu_65_accuracy: 0.5985 - re_lu_121_accuracy: 0.7716 - re_lu_177_acc\n",
      "Epoch 00042: loss improved from 23.26504 to 22.63305, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 22.6330 - re_lu_65_loss: 11.5490 - re_lu_121_loss: 5.5109 - re_lu_177_loss: 3.2483 - re_lu_233_loss: 2.3248 - re_lu_65_accuracy: 0.5982 - re_lu_121_accuracy: 0.7699 - re_lu_177_accuracy: 0.8640 - re_lu_233_accuracy: 0.8920 - val_loss: 157.1510 - val_re_lu_65_loss: 38.6955 - val_re_lu_121_loss: 38.2923 - val_re_lu_177_loss: 39.4406 - val_re_lu_233_loss: 40.7225 - val_re_lu_65_accuracy: 0.5796 - val_re_lu_121_accuracy: 0.6893 - val_re_lu_177_accuracy: 0.6814 - val_re_lu_233_accuracy: 0.7580\n",
      "Learning rate:  0.0005\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 22.0347 - re_lu_65_loss: 11.2656 - re_lu_121_loss: 5.3695 - re_lu_177_loss: 3.1472 - re_lu_233_loss: 2.2524 - re_lu_65_accuracy: 0.6147 - re_lu_121_accuracy: 0.7742 - re_lu_177_accuracy: 0.8699 - re_lu_233_accuracy: 0.8860  - ETA: 2:50 - loss: 18.9247 - re_lu_65_loss: 10.0760 - re_lu_121_loss: 4.4409 - re_lu_177_loss: 2.5644 - re_lu_233_loss: 1.8434 - re_lu_65_accuracy: 0 - ETA: 1:58 - loss: 22.2897 - re_lu_65_loss: 11.3547 - re_lu_121_loss: 5.4486 - re_lu_177_loss: 3.2113 - re_lu_233_loss: 2.2751 - re_lu_65_ - ETA: 13s - loss: 22.0029 - re_lu_65_loss: 11.2516 - re_lu_121_loss: 5.3664 - re_lu_177_loss: 3.1366 - re_lu_233_loss: 2.2483 - re_lu_65_accuracy: 0.6\n",
      "Epoch 00043: loss improved from 22.63305 to 22.03474, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 22.0347 - re_lu_65_loss: 11.2656 - re_lu_121_loss: 5.3695 - re_lu_177_loss: 3.1472 - re_lu_233_loss: 2.2524 - re_lu_65_accuracy: 0.6147 - re_lu_121_accuracy: 0.7742 - re_lu_177_accuracy: 0.8699 - re_lu_233_accuracy: 0.8860 - val_loss: 158.0079 - val_re_lu_65_loss: 39.1789 - val_re_lu_121_loss: 38.6148 - val_re_lu_177_loss: 39.6110 - val_re_lu_233_loss: 40.6032 - val_re_lu_65_accuracy: 0.6207 - val_re_lu_121_accuracy: 0.6848 - val_re_lu_177_accuracy: 0.6838 - val_re_lu_233_accuracy: 0.7453\n",
      "Learning rate:  0.0005\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.5425 - re_lu_65_loss: 11.0181 - re_lu_121_loss: 5.2473 - re_lu_177_loss: 3.0793 - re_lu_233_loss: 2.1977 - re_lu_65_accuracy: 0.6277 - re_lu_121_accuracy: 0.7870 - re_lu_177_accuracy: 0.8723 - re_lu_233_accuracy: 0.8906  - ETA: 2:40 - loss: 21.5363 - re_lu_65_loss: 10.9949 - re_lu_121_loss: 5.2979 - re_lu_177_loss: 3.0106 - re_lu_233_loss: 2.2330 - re_lu_65_accuracy: 0.6257 - re_lu_121_accuracy: 0.7919 - re_lu_177_accuracy: 0.8692 - ETA: 2:35 - loss: 20.9803 - re_lu_65_loss: 10.6929 - re_lu_121_loss: 5.1342 - re_lu_177_loss: 2. - ETA: 2s - loss: 21.5342 - re_lu_65_loss: 11.0166 - re_lu_121_loss: 5.2469 - re_lu_177_loss: 3.0769 - re_lu_233_loss: 2.1938 - re_lu_65_accuracy: 0.6278 - re_lu_121_accuracy: 0.7871 - re_lu_177_accuracy: 0.8723 - re_lu_233_\n",
      "Epoch 00044: loss improved from 22.03474 to 21.54248, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 21.5425 - re_lu_65_loss: 11.0181 - re_lu_121_loss: 5.2473 - re_lu_177_loss: 3.0793 - re_lu_233_loss: 2.1977 - re_lu_65_accuracy: 0.6277 - re_lu_121_accuracy: 0.7870 - re_lu_177_accuracy: 0.8723 - re_lu_233_accuracy: 0.8906 - val_loss: 157.9191 - val_re_lu_65_loss: 38.8504 - val_re_lu_121_loss: 38.8299 - val_re_lu_177_loss: 39.6415 - val_re_lu_233_loss: 40.5973 - val_re_lu_65_accuracy: 0.6419 - val_re_lu_121_accuracy: 0.7155 - val_re_lu_177_accuracy: 0.7514 - val_re_lu_233_accuracy: 0.8169\n",
      "Learning rate:  0.0005\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.1332 - re_lu_65_loss: 10.8332 - re_lu_121_loss: 5.1379 - re_lu_177_loss: 3.0102 - re_lu_233_loss: 2.1520 - re_lu_65_accuracy: 0.6261 - re_lu_121_accuracy: 0.7845 - re_lu_177_accuracy: 0.8775 - re_lu_233_accuracy: 0.8993  - ETA: 2:48 - loss: 20.5985 - re_lu_65_loss: 10.6588 - re_lu_121_loss: 4.9882 - re_lu_177_loss: 2.8693 - re_lu_233_loss: 2.0821 - re_lu_65_accuracy: 0.6592 - re_lu_121_accuracy: 0.8030 - re_lu_177_accu - ETA: 2:41 - loss: 19.2206 - re_lu_65_loss: 10.0603 - re_lu_121 - ETA: 2:10 - loss: 20.4553 - re_lu_65_loss: 10.5579 - re_lu_121_loss: 4.9162 - re_lu_177_loss: 2.8883 - re_lu_233_loss: 2.0929 - re_lu_65_accurac - ETA: 1:53 - loss: 20.6242 - re_lu_65_loss: 10.6104 - re_lu_121_loss: 4.9746 - re_lu_177_loss: 2.9208 - re_lu_233 - ETA: 7s - loss: 21.1558 - re_lu_65_loss: 10.8485 - re_lu_121_loss: 5.1435 - re_lu_177_loss: 3.0145 - re_lu_233_loss: 2.1492 - re_lu_65_accuracy: 0.6258 - re_lu_121_accuracy: 0.7843 - re_lu_177_accura\n",
      "Epoch 00045: loss improved from 21.54248 to 21.13317, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 21.1332 - re_lu_65_loss: 10.8332 - re_lu_121_loss: 5.1379 - re_lu_177_loss: 3.0102 - re_lu_233_loss: 2.1520 - re_lu_65_accuracy: 0.6261 - re_lu_121_accuracy: 0.7845 - re_lu_177_accuracy: 0.8775 - re_lu_233_accuracy: 0.8993 - val_loss: 159.5704 - val_re_lu_65_loss: 39.2717 - val_re_lu_121_loss: 38.7775 - val_re_lu_177_loss: 40.0185 - val_re_lu_233_loss: 41.5027 - val_re_lu_65_accuracy: 0.6433 - val_re_lu_121_accuracy: 0.7151 - val_re_lu_177_accuracy: 0.7265 - val_re_lu_233_accuracy: 0.7534\n",
      "Learning rate:  0.0005\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 20.6576 - re_lu_65_loss: 10.6021 - re_lu_121_loss: 5.0216 - re_lu_177_loss: 2.9390 - re_lu_233_loss: 2.0949 - re_lu_65_accuracy: 0.6431 - re_lu_121_accuracy: 0.7823 - re_lu_177_accuracy: 0.8806 - re_lu_233_accuracy: 0.9031  ETA: 2:49 - loss: 18.2622 - re_lu_65_loss: 9.2851 - re_lu_121_loss: 4.3594 - re_lu_177_loss: 2.6377 - re_lu_233_loss: 1.9800 - - ETA: 1:13 - loss: 20.5025 - ETA: 24s - loss: 20.6261 - re_lu_65_lo - ETA: 2s - loss: 20.6974 - re_lu_65_loss: 10.6140 - re_lu_121_loss: 5.0372 - re_lu_177_loss: 2.9450 - re_lu_233_loss: 2.1012 - re_lu_65_accuracy: 0.6431 - re_lu_121_accuracy: 0.7819 - re_lu_177_accuracy: 0.8804 - re_lu_233_a\n",
      "Epoch 00046: loss improved from 21.13317 to 20.65759, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 20.6576 - re_lu_65_loss: 10.6021 - re_lu_121_loss: 5.0216 - re_lu_177_loss: 2.9390 - re_lu_233_loss: 2.0949 - re_lu_65_accuracy: 0.6431 - re_lu_121_accuracy: 0.7823 - re_lu_177_accuracy: 0.8806 - re_lu_233_accuracy: 0.9031 - val_loss: 156.9909 - val_re_lu_65_loss: 38.7214 - val_re_lu_121_loss: 38.5621 - val_re_lu_177_loss: 39.4065 - val_re_lu_233_loss: 40.3009 - val_re_lu_65_accuracy: 0.6201 - val_re_lu_121_accuracy: 0.7412 - val_re_lu_177_accuracy: 0.6857 - val_re_lu_233_accuracy: 0.7505\n",
      "Learning rate:  0.0005\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 20.2590 - re_lu_65_loss: 10.4047 - re_lu_121_loss: 4.9190 - re_lu_177_loss: 2.8833 - re_lu_233_loss: 2.0520 - re_lu_65_accuracy: 0.6468 - re_lu_121_accuracy: 0.7975 - re_lu_177_accuracy: 0.8777 - re_lu_233_accuracy: 0.9013  ETA: 32s - loss: 20.2243 - re_lu_65_loss: 10.3625 - re_lu_121_loss: 4.8933 - re_lu_177_loss: 2.9001 - re_lu_233_loss: 2.0685 - re_lu_65_accuracy: 0.6462 - re_lu_121_accuracy: \n",
      "Epoch 00047: loss improved from 20.65759 to 20.25901, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 20.2590 - re_lu_65_loss: 10.4047 - re_lu_121_loss: 4.9190 - re_lu_177_loss: 2.8833 - re_lu_233_loss: 2.0520 - re_lu_65_accuracy: 0.6468 - re_lu_121_accuracy: 0.7975 - re_lu_177_accuracy: 0.8777 - re_lu_233_accuracy: 0.9013 - val_loss: 158.0874 - val_re_lu_65_loss: 39.1492 - val_re_lu_121_loss: 38.5877 - val_re_lu_177_loss: 39.7925 - val_re_lu_233_loss: 40.5580 - val_re_lu_65_accuracy: 0.6611 - val_re_lu_121_accuracy: 0.7076 - val_re_lu_177_accuracy: 0.7556 - val_re_lu_233_accuracy: 0.8197\n",
      "Learning rate:  0.0005\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.7260 - re_lu_65_loss: 10.1876 - re_lu_121_loss: 4.7702 - re_lu_177_loss: 2.7885 - re_lu_233_loss: 1.9798 - re_lu_65_accuracy: 0.6687 - re_lu_121_accuracy: 0.8011 - re_lu_177_accuracy: 0.8825 - re_lu_233_accuracy: 0.9098  - ETA: 2:09 - loss: 19.7475 - re_lu_65_loss: 10.2292 - re_lu_121_loss: 4.7951 - re_lu_177_loss: 2.7724 - re_ - ETA: 1:01 - loss: 20.0121 - re_lu_65_loss: 10.2930 - re_lu_121_loss: 4.8719 - re_lu_177_loss: 2.8408 - re_l - ETA: 48s - loss: 19.9055 - re_lu_65_loss: 10.2584 - re_lu_121_loss: 4.8274 - re_lu_177_loss: 2.8238 - re_lu_233_loss: 1.9958 - re_l - ETA: 38s - loss: 19.8123 - re_lu_65_loss: 10.2364 - re_lu_121_loss: 4.7917 - re_lu_177_loss: 2.7999 - re_lu_233_loss: 1.9844 - re_lu_ - ETA: 28s - loss: 19.8002 - re_lu_65_loss: 10.2248 - re_lu_121_loss: 4.7833 - re_lu_177_loss: 2.8009 - re_lu_233_loss: 1.9912 - re_lu_65_accuracy: 0.6676 - re_lu_121_accuracy: 0.7998 - re_lu_177_accuracy: 0.8827 - re_lu_\n",
      "Epoch 00048: loss improved from 20.25901 to 19.72603, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 19.7260 - re_lu_65_loss: 10.1876 - re_lu_121_loss: 4.7702 - re_lu_177_loss: 2.7885 - re_lu_233_loss: 1.9798 - re_lu_65_accuracy: 0.6687 - re_lu_121_accuracy: 0.8011 - re_lu_177_accuracy: 0.8825 - re_lu_233_accuracy: 0.9098 - val_loss: 158.7775 - val_re_lu_65_loss: 39.1320 - val_re_lu_121_loss: 38.8814 - val_re_lu_177_loss: 39.8742 - val_re_lu_233_loss: 40.8900 - val_re_lu_65_accuracy: 0.6857 - val_re_lu_121_accuracy: 0.7093 - val_re_lu_177_accuracy: 0.7583 - val_re_lu_233_accuracy: 0.8249\n",
      "Learning rate:  0.0005\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.2661 - re_lu_65_loss: 9.9711 - re_lu_121_loss: 4.6600 - re_lu_177_loss: 2.7120 - re_lu_233_loss: 1.9230 - re_lu_65_accuracy: 0.6825 - re_lu_121_accuracy: 0.8110 - re_lu_177_accuracy: 0.8879 - re_lu_233_accuracy: 0.9169   ETA: 2:51 - loss: 17.7092 - re_lu_65_loss: 8.8488 - re_lu_121_loss: 4.3404 - re_lu_177_loss: 2.6599 - r - ETA: 2:09 - loss: 19.1082 - re_lu_65_loss: 9.9002 - re_lu_121_loss: 4.6097 - re_lu_177_loss: 2.6647 - re_lu_233_loss: 1.9336 - re_lu_65_accuracy: 0.6905 -  - ETA: 2:01 - loss: 18.9482 - re_lu_65_loss: 9.8048 - re_lu_121_loss: 4.5722 - re_lu_177_loss: 2.6527 - re_lu_233_loss: 1.9185 - re_l - ETA: 1:52 - loss: 19.2224 - re_lu_65_loss: 9.9439 - re_lu_121_loss: 4.6504 - re_lu_177_loss: 2.6971 - re_lu_233_loss: 1.9310 - re_lu_65_accuracy: 0.6894 - re_lu_121_accuracy:  - ETA: 1:46 - loss: 19.1961 - re_lu - ETA: 1:0 - ETA: 29s - loss: 19.2948 - re_lu_65_loss: 9.9675 - re_lu_121_loss: 4.6633 - re_lu_177_loss: 2.7259 - re_lu_233_loss: 1.9381 - re_lu_65_accuracy: 0.6812 - re_lu_121_accuracy: 0.8089 - re_lu_177_accuracy: 0.8856 - re_lu_233_accuracy: 0.9 - ETA: 28s - loss: 19.3310 - re_lu_65_loss: 9.9829 - re_ - ETA: 2s - loss: 19.2836 - re_lu_65_loss: 9.9704 - re_lu_121_loss: 4.6642 - re_lu_177_loss: 2.7200 - re_lu_233_loss: 1.9291 - re_lu_65_accuracy: 0.6824 - re_lu_121_accuracy: 0.8107 - re_lu_177_accuracy: 0.8876 - \n",
      "Epoch 00049: loss improved from 19.72603 to 19.26610, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 19.2661 - re_lu_65_loss: 9.9711 - re_lu_121_loss: 4.6600 - re_lu_177_loss: 2.7120 - re_lu_233_loss: 1.9230 - re_lu_65_accuracy: 0.6825 - re_lu_121_accuracy: 0.8110 - re_lu_177_accuracy: 0.8879 - re_lu_233_accuracy: 0.9169 - val_loss: 159.0684 - val_re_lu_65_loss: 39.0026 - val_re_lu_121_loss: 38.7583 - val_re_lu_177_loss: 40.4543 - val_re_lu_233_loss: 40.8533 - val_re_lu_65_accuracy: 0.6852 - val_re_lu_121_accuracy: 0.7095 - val_re_lu_177_accuracy: 0.7206 - val_re_lu_233_accuracy: 0.8110\n",
      "Learning rate:  0.0005\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.9178 - re_lu_65_loss: 9.8061 - re_lu_121_loss: 4.5653 - re_lu_177_loss: 2.6651 - re_lu_233_loss: 1.8813 - re_lu_65_accuracy: 0.6828 - re_lu_121_accuracy: 0.8087 - re_lu_177_accuracy: 0.8872 - re_lu_233_accuracy: 0.9116   ETA: 2:37 - loss: 18.3024 - re_lu_65_loss: 9.5422 - re_lu_121_loss: 4.3241 - re_lu_177_loss:  - ETA: 2:24 - loss: 18.2746 - re_lu_65_loss: 9.4847 - re_lu_121_loss: 4.3622 - re_lu_177_loss: 2.5794 - re_lu_233_loss: 1.8484 - re_lu_65_accuracy: 0.7045 - re_lu_121_accuracy: 0.8228 - re_lu_177_accuracy: 0.8940 - re_lu_233_accu - ETA: 1:40 - loss: 18.6087 - re_lu_65_loss: 9.7055 - re_lu_121_loss: 4.4624 - re_lu_177_ - ETA: 1:26 - loss: 18.6822 - re_lu_65_loss: 9.7222 - re_lu_121_loss: 4.4987 - re_lu_177_loss: 2.6098 - re_lu_233_loss: 1.8515 - re_lu_65_accuracy: 0.6903 -  - ETA: 1:19 - loss: 18.7844 - re_lu_65_loss: 9.7875 - re_lu_121_loss: 4.5319 - re_lu_177_los - ETA: 27s - loss: 18.7290 - re_lu_65_loss: 9.7154 - re_lu_121_loss: 4.5009 - re_lu_177_loss: 2.6401 - re_lu_233_loss: 1.8727 - re_lu_65_accuracy: 0.6 - ETA: 10s - loss: 18.8488 - re_lu_65_loss: 9.7976 - re_lu_121_loss: 4.5394 - re_lu_177_loss: 2.6402 - re_lu_233_loss: 1.8716 -\n",
      "Epoch 00050: loss improved from 19.26610 to 18.91783, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 18.9178 - re_lu_65_loss: 9.8061 - re_lu_121_loss: 4.5653 - re_lu_177_loss: 2.6651 - re_lu_233_loss: 1.8813 - re_lu_65_accuracy: 0.6828 - re_lu_121_accuracy: 0.8087 - re_lu_177_accuracy: 0.8872 - re_lu_233_accuracy: 0.9116 - val_loss: 158.0211 - val_re_lu_65_loss: 38.8912 - val_re_lu_121_loss: 38.6975 - val_re_lu_177_loss: 39.6660 - val_re_lu_233_loss: 40.7663 - val_re_lu_65_accuracy: 0.6628 - val_re_lu_121_accuracy: 0.6668 - val_re_lu_177_accuracy: 0.7141 - val_re_lu_233_accuracy: 0.7719\n",
      "Learning rate:  0.0005\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.5560 - re_lu_65_loss: 9.6327 - re_lu_121_loss: 4.4743 - re_lu_177_loss: 2.6098 - re_lu_233_loss: 1.8392 - re_lu_65_accuracy: 0.6857 - re_lu_121_accuracy: 0.8083 - re_lu_177_accuracy: 0.8888 - re_lu_233_accuracy: 0.9185 - ETA: 58s - loss: 18.5239 - re_lu_65_loss: 9.5937 - re_lu_121_loss: 4.4498 - re_lu_177_loss: 2.6232 - re_lu_233_loss: 1.8573 - re_lu_65_accuracy: 0.6873 - re_lu_121_accuracy: 0.8110 - re_lu_177_accuracy: 0.8914 - re_lu_233_accura - ETA: 56s - loss: 18.4758 - re_lu_65_loss: 9.5750 - re_lu_121_loss: 4.4325 - re_lu_177_loss: 2.6141 - re_lu_233_los\n",
      "Epoch 00051: loss improved from 18.91783 to 18.55600, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 18.5560 - re_lu_65_loss: 9.6327 - re_lu_121_loss: 4.4743 - re_lu_177_loss: 2.6098 - re_lu_233_loss: 1.8392 - re_lu_65_accuracy: 0.6857 - re_lu_121_accuracy: 0.8083 - re_lu_177_accuracy: 0.8888 - re_lu_233_accuracy: 0.9185 - val_loss: 158.1274 - val_re_lu_65_loss: 38.7203 - val_re_lu_121_loss: 38.6301 - val_re_lu_177_loss: 39.9191 - val_re_lu_233_loss: 40.8580 - val_re_lu_65_accuracy: 0.6533 - val_re_lu_121_accuracy: 0.7395 - val_re_lu_177_accuracy: 0.7820 - val_re_lu_233_accuracy: 0.8504\n",
      "Learning rate:  0.0005\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.1785 - re_lu_65_loss: 9.4527 - re_lu_121_loss: 4.3740 - re_lu_177_loss: 2.5534 - re_lu_233_loss: 1.7985 - re_lu_65_accuracy: 0.7094 - re_lu_121_accuracy: 0.8070 - re_lu_177_accuracy: 0.8900 - re_lu_233_accuracy: 0.9237   ETA: 1:21 - loss: 17.8812 - re_lu_65_loss: 9.3382 - re_lu_121_loss: 4.3202 - re_lu_ - ETA: 1:07 - loss: 18.0962 - re_lu_65_loss: 9.4247 - re_lu_121_loss: 4.3894 - re_lu_177_loss: 2.5321 - re_l - ETA: 8s - loss: 18.1768 - re_lu_65_loss: 9.4516 - re_lu_121_loss: 4.3711 - re_lu_177_loss: 2.5563 - re_lu_233_loss: 1.7977 - re_lu_65_accuracy: 0.7089 - re_lu_121_accuracy: 0.8059 - ETA: 2s - loss: 18.1610 - re_lu_65_loss: 9.4438 - re_lu_121_loss: 4.3688 - re_lu_177_loss: 2.5518 - re_lu_233_loss: 1.7966 - re_lu_65_accuracy: 0.7096 - re_lu_121_accuracy: 0.8072 - re_lu_177_accuracy: 0.890\n",
      "Epoch 00052: loss improved from 18.55600 to 18.17853, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 18.1785 - re_lu_65_loss: 9.4527 - re_lu_121_loss: 4.3740 - re_lu_177_loss: 2.5534 - re_lu_233_loss: 1.7985 - re_lu_65_accuracy: 0.7094 - re_lu_121_accuracy: 0.8070 - re_lu_177_accuracy: 0.8900 - re_lu_233_accuracy: 0.9237 - val_loss: 159.8809 - val_re_lu_65_loss: 39.4100 - val_re_lu_121_loss: 39.1215 - val_re_lu_177_loss: 40.4188 - val_re_lu_233_loss: 40.9306 - val_re_lu_65_accuracy: 0.7186 - val_re_lu_121_accuracy: 0.6694 - val_re_lu_177_accuracy: 0.7500 - val_re_lu_233_accuracy: 0.8068\n",
      "Learning rate:  0.0005\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.7310 - re_lu_65_loss: 9.2581 - re_lu_121_loss: 4.2564 - re_lu_177_loss: 2.4814 - re_lu_233_loss: 1.7351 - re_lu_65_accuracy: 0.7056 - re_lu_121_accuracy: 0.8222 - re_lu_177_accuracy: 0.8924 - re_lu_233_accuracy: 0.9242 - ETA: 52s - loss: 17.5277 - re_lu_65_loss: 9.1483 - re_lu_121_loss: 4.1840 - re_lu_177_loss: 2.4639 - re_lu_233_loss: 1.7315 - re_lu_65_accuracy: 0.7114 - re_lu_121_accuracy: 0.8291 - re_lu_177_accuracy: 0.8969  - ETA: 46s - loss: 17.5598 - re_lu_65_loss: 9.1700 - re_lu_121_loss: 4.1896 - re_lu_177_loss: 2.4668 - re_lu_233_loss: 1.7334 - re_lu_65_accuracy: 0.7107 - re_lu_121_accuracy: 0.8285 - re_lu_17 - ETA: 38s - loss: 17.5503 - re_lu_65_loss: 9.1641 - re_lu_121_loss: 4.1956 - re_lu_177_loss: 2.4648 - re_lu_233_loss: 1.7257 - re_lu_65_accuracy: 0.7106 - re_lu_121_accuracy: 0.8274 - re_lu_177_ - ETA: 30s - loss: 17\n",
      "Epoch 00053: loss improved from 18.17853 to 17.73100, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 17.7310 - re_lu_65_loss: 9.2581 - re_lu_121_loss: 4.2564 - re_lu_177_loss: 2.4814 - re_lu_233_loss: 1.7351 - re_lu_65_accuracy: 0.7056 - re_lu_121_accuracy: 0.8222 - re_lu_177_accuracy: 0.8924 - re_lu_233_accuracy: 0.9242 - val_loss: 158.4864 - val_re_lu_65_loss: 39.6157 - val_re_lu_121_loss: 38.7475 - val_re_lu_177_loss: 39.7094 - val_re_lu_233_loss: 40.4139 - val_re_lu_65_accuracy: 0.6871 - val_re_lu_121_accuracy: 0.7255 - val_re_lu_177_accuracy: 0.7440 - val_re_lu_233_accuracy: 0.8114\n",
      "Learning rate:  0.0005\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.5035 - re_lu_65_loss: 9.1225 - re_lu_121_loss: 4.1999 - re_lu_177_loss: 2.4569 - re_lu_233_loss: 1.7242 - re_lu_65_accuracy: 0.7152 - re_lu_121_accuracy: 0.8207 - re_lu_177_accuracy: 0.8975 - re_lu_233_accuracy: 0.9267   ETA: 1:04 - loss: 17.4084 - re_lu_65_loss: 9.1242 - re_lu_121_loss: 4.164 - ETA: 38s - loss: 17.4388 - re_lu_65_loss: 9.1215 - re_lu_121_loss: 4.1881 - re_lu_177_loss: 2.4261 - re_lu_233_loss: 1.7030 - re_lu_65_accuracy: 0.7163 - re_lu_121_accuracy: 0.8197 - re_lu_177_accuracy: 0.8988 - re_lu_233_ - ETA: 35s - loss: 17.4161 - re_lu_65_loss: 9.1111 - re_lu_121_loss: 4.1838 - re_lu_177_loss: 2.4209 - re_lu_233_loss: 1.7003 - re_lu_65_accuracy: 0.7163 - re_lu_121_acc - ETA: 22s - loss: 17.4792 - re_lu_65_loss: 9.1124 - re_lu_121_loss: 4.2100 - re_lu_177_loss: 2.4454 - re_lu_233_loss: 1.71 - ETA: 5s - loss: 17.4109 - re_lu_65_loss: 9.0876 - re_lu_121_loss: 4.1753 - re_lu_177_loss: 2.4381 - re_lu_233_loss: 1.7100 - re_lu_65_accuracy: 0.7156 - re_lu_121_accuracy: 0.\n",
      "Epoch 00054: loss improved from 17.73100 to 17.50351, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 17.5035 - re_lu_65_loss: 9.1225 - re_lu_121_loss: 4.1999 - re_lu_177_loss: 2.4569 - re_lu_233_loss: 1.7242 - re_lu_65_accuracy: 0.7152 - re_lu_121_accuracy: 0.8207 - re_lu_177_accuracy: 0.8975 - re_lu_233_accuracy: 0.9267 - val_loss: 157.1838 - val_re_lu_65_loss: 38.7704 - val_re_lu_121_loss: 38.5534 - val_re_lu_177_loss: 39.5819 - val_re_lu_233_loss: 40.2781 - val_re_lu_65_accuracy: 0.7320 - val_re_lu_121_accuracy: 0.7092 - val_re_lu_177_accuracy: 0.7341 - val_re_lu_233_accuracy: 0.8405\n",
      "Learning rate:  0.0005\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.0235 - re_lu_65_loss: 8.9086 - re_lu_121_loss: 4.0892 - re_lu_177_loss: 2.3722 - re_lu_233_loss: 1.6535 - re_lu_65_accuracy: 0.7237 - re_lu_121_accuracy: 0.8316 - re_lu_177_accuracy: 0.9055 - re_lu_233_accuracy: 0.9292   ETA: 1:29 - loss: 17.0236 - re_lu_65_loss: 8.8358 - re_lu_121_loss: 4.0809 - re_lu_177_ - ETA: 1:16 - loss: 17.0302 - re_lu_65_loss: 8.8445 - re_lu_121_loss: 4.0903 - re_lu_177_loss: 2.4090 - re_lu_233_loss: 1.6864 - re_lu_ - ETA: 1:06 - loss: 17.2366 - re_lu_65_loss: 8.9338 - re_lu_121_loss: 4.1572 - re_lu_177_loss: 2.4414 - re_lu_233_loss: 1.7042 - re_lu_65_accura - ETA: 55s - loss: 17.0584 - re_lu_65 - ETA: 18s - loss: 17.0939 - re_lu_65_loss: 8.9309 - re_lu_121_loss: 4.1164 - re_lu_177\n",
      "Epoch 00055: loss improved from 17.50351 to 17.02349, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 17.0235 - re_lu_65_loss: 8.9086 - re_lu_121_loss: 4.0892 - re_lu_177_loss: 2.3722 - re_lu_233_loss: 1.6535 - re_lu_65_accuracy: 0.7237 - re_lu_121_accuracy: 0.8316 - re_lu_177_accuracy: 0.9055 - re_lu_233_accuracy: 0.9292 - val_loss: 157.8502 - val_re_lu_65_loss: 38.8710 - val_re_lu_121_loss: 38.8252 - val_re_lu_177_loss: 39.5076 - val_re_lu_233_loss: 40.6463 - val_re_lu_65_accuracy: 0.6889 - val_re_lu_121_accuracy: 0.7319 - val_re_lu_177_accuracy: 0.7953 - val_re_lu_233_accuracy: 0.8349\n",
      "Learning rate:  0.0005\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.7272 - re_lu_65_loss: 8.7638 - re_lu_121_loss: 4.0019 - re_lu_177_loss: 2.3344 - re_lu_233_loss: 1.6271 - re_lu_65_accuracy: 0.7254 - re_lu_121_accuracy: 0.8307 - re_lu_177_accuracy: 0.9077 - re_lu_233_accuracy: 0.9334   ETA: 2:21 - loss: 17.0274 - re_lu_65_loss: 8.8671 - re_lu_121_loss: 4.0856 - re_lu_177_loss: 2.3938 - re_ - ETA: 1:25 - loss: 16.6382 - re_lu_65_loss: 8.7403 - re_lu_121_loss: 3.9628 - re_lu_177_loss: 2.3196 - re_lu_233_loss: 1.6156 - re_lu_65_accuracy: 0.727 - ETA: 1:17 - loss: 16.6327 - re_lu_65_loss: 8.7044 - re_lu_121_loss: 3.9681 - re_lu_177_loss: 2.3381 - re_lu_233_loss: 1.6221 - re_lu_ - ETA: 1:07 - loss: 16.5671 - re_lu_65_loss: 8.6656 - re_lu_121_loss: 3.9500 - re_lu_177_loss: 2.3280 - re_lu_233_loss: 1.6236 - re_lu_65_accuracy: 0.7318 - re_lu_121_accuracy: 0.8389 - ETA: 1:02 - loss: 16.6020 - re_lu_65_loss: 8.6754 - re_lu_121_loss: 3.9583 - re_lu_177_loss: 2.3357 - re_lu_233_loss: 1.6328 - re_lu_65_accuracy: 0.7311 - re_lu_121_accuracy: 0.8377 - re_lu_177_accuracy - ETA: 58s - loss: 16.5699 - re_lu_65_loss: 8.6594 - re_lu_121_loss: 3.9507 - re_lu_177_loss: 2.3327 - re_lu_233_loss: 1.6270 - re_lu_65_accuracy: 0.7311 - re_lu_121_accuracy: 0.8374 - re_ - ETA: 49s - loss: 16.4952 - re_lu_65_loss: 8.6464 - re_lu_121_loss - ETA: 17s - loss: 16.5381 - re_lu_65_loss: 8.6787 - re_lu_121_loss: 3.9427 - re_lu_177_loss: 2.3036 - re_lu_233_loss: 1.6131 - re_lu_65_accuracy: 0.7300 - re_lu_121_accuracy:  - ETA: 7s - loss: 16.6553 - re_lu_65_loss: 8.7342 - re_lu_121_loss: 3.9799 - re_lu_177_loss: 2.3213 - re_lu_233_loss: 1.6199 - re_lu_65_accuracy: 0.7269 - re_lu_121_accuracy: 0.8327 - re_lu_177_accuracy: 0.9089 - re_l - ETA: 5s - loss: 16.6245 - re_lu_65_loss: 8.7204 - re_lu_121_loss: 3.9714 - re_lu_177_loss: 2.3165 - re_lu_233_loss: 1.6162 - re_lu_65_accuracy: 0.7270 - re_lu_121_accuracy: \n",
      "Epoch 00056: loss improved from 17.02349 to 16.72725, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 16.7272 - re_lu_65_loss: 8.7638 - re_lu_121_loss: 4.0019 - re_lu_177_loss: 2.3344 - re_lu_233_loss: 1.6271 - re_lu_65_accuracy: 0.7254 - re_lu_121_accuracy: 0.8307 - re_lu_177_accuracy: 0.9077 - re_lu_233_accuracy: 0.9334 - val_loss: 159.3148 - val_re_lu_65_loss: 39.0698 - val_re_lu_121_loss: 39.1363 - val_re_lu_177_loss: 40.1198 - val_re_lu_233_loss: 40.9891 - val_re_lu_65_accuracy: 0.7304 - val_re_lu_121_accuracy: 0.7332 - val_re_lu_177_accuracy: 0.7885 - val_re_lu_233_accuracy: 0.8585\n",
      "Learning rate:  0.0005\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.4901 - re_lu_65_loss: 8.6536 - re_lu_121_loss: 3.9395 - re_lu_177_loss: 2.2993 - re_lu_233_loss: 1.5976 - re_lu_65_accuracy: 0.7347 - re_lu_121_accuracy: 0.8309 - re_lu_177_accuracy: 0.9039 - re_lu_233_accuracy: 0.9366   ETA: 2:21 - loss: 16.4976 - re_lu_65_lo - ETA: 10s - loss: 16.4222 - re_lu_65_loss: 8.6268 - re_lu_121_loss: 3.9132 - re_lu_177_loss: 2.2866 - re_lu_233_loss: 1.5956 - r\n",
      "Epoch 00057: loss improved from 16.72725 to 16.49006, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 16.4901 - re_lu_65_loss: 8.6536 - re_lu_121_loss: 3.9395 - re_lu_177_loss: 2.2993 - re_lu_233_loss: 1.5976 - re_lu_65_accuracy: 0.7347 - re_lu_121_accuracy: 0.8309 - re_lu_177_accuracy: 0.9039 - re_lu_233_accuracy: 0.9366 - val_loss: 158.2762 - val_re_lu_65_loss: 38.8024 - val_re_lu_121_loss: 38.6444 - val_re_lu_177_loss: 39.8920 - val_re_lu_233_loss: 40.9374 - val_re_lu_65_accuracy: 0.7473 - val_re_lu_121_accuracy: 0.7308 - val_re_lu_177_accuracy: 0.7832 - val_re_lu_233_accuracy: 0.8555\n",
      "Learning rate:  0.0005\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.1270 - re_lu_65_loss: 8.4957 - re_lu_121_loss: 3.8475 - re_lu_177_loss: 2.2362 - re_lu_233_loss: 1.5476 - re_lu_65_accuracy: 0.7483 - re_lu_121_accuracy: 0.8369 - re_lu_177_accuracy: 0.9013 - re_lu_233_accuracy: 0.9396   ETA: 2:51 - loss: 16.0035 - re_lu_65_loss: 8.8549 - re_lu_121_loss: 3.7401 - re_lu_177_loss: 1.9987 - re_lu_233_loss: 1.4098 - re_lu_65_accuracy: 0.7505 - re_lu_121_accuracy: 0.8333 - re_lu_177 - ETA: 2:49 - loss: 15.6035 - re_lu_65_loss: 8.6930 - re_lu_121_loss: 3.6592 - re_lu_177_loss: 1.9282 - re_lu_233_loss: 1.3231  - ETA: 2:41 - ETA: 2:21 - loss: 16.2568 - re_lu_65_loss: 8.5553 - re_lu_121_loss: 3.9185 - re_lu_177_loss: 2.2462 - re_lu_233_loss: 1.5368 - re_lu_65_a - ETA: 2:11 - loss: 15.6925 - - ETA: 1:30 - loss: 15.6434 - re_lu_65_loss: 8.3094 - re_lu_121_loss: 3.7192 - re_lu_177_loss: 2.1293 - re_lu_233_loss: 1.4855 - ETA: 56s - loss: 15.9186 - re_lu_65_loss: 8.4190 - re_lu_121_loss: 3.8014 - re_lu_177_loss: 2.1828 - re_lu_233_loss: 1.5155 - re_lu_65_accuracy: 0.7544 - re_lu_121_accuracy: 0.8362 - re_lu_177_ac - ETA: 48s - loss: 15.9147 - re_lu_65_loss: 8.4199 - re_lu_121_loss: 3.7950 - re_lu_177_loss: 2.1852 - re_lu_233_loss: 1.5147 - re_lu_65_accuracy: 0.75 - ETA: 32s - loss: 16.0571 - re_lu_65_loss: 8.4805 - re_lu_121_loss: 3.8385 - re_lu_177_loss: 2.2081 - re_lu_233_loss: 1.5300 - re_lu_65_accuracy: 0.7510 - re_lu_121_accuracy: 0.8356 -  - ETA: 22s - loss: 16.1484 - re_lu_65_loss: 8.5191 - re_lu_121_loss: 3.8615 - re_lu_177_loss: 2.2255 - re_lu_233_loss: 1.5423 - re_lu - ETA: 6s - loss: 16.1409 - re_lu_65_loss: 8.4928 - re_lu_121_loss: 3.8588 - re_lu_177_loss: 2.2409 - re_lu_233_loss: 1.5484 - re_lu_65_accuracy: 0.7492 - re_lu_121_accura\n",
      "Epoch 00058: loss improved from 16.49006 to 16.12704, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 16.1270 - re_lu_65_loss: 8.4957 - re_lu_121_loss: 3.8475 - re_lu_177_loss: 2.2362 - re_lu_233_loss: 1.5476 - re_lu_65_accuracy: 0.7483 - re_lu_121_accuracy: 0.8369 - re_lu_177_accuracy: 0.9013 - re_lu_233_accuracy: 0.9396 - val_loss: 157.5501 - val_re_lu_65_loss: 39.2207 - val_re_lu_121_loss: 38.7173 - val_re_lu_177_loss: 39.3763 - val_re_lu_233_loss: 40.2359 - val_re_lu_65_accuracy: 0.7185 - val_re_lu_121_accuracy: 0.7703 - val_re_lu_177_accuracy: 0.7663 - val_re_lu_233_accuracy: 0.8296\n",
      "Learning rate:  0.0005\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.7860 - re_lu_65_loss: 8.3320 - re_lu_121_loss: 3.7584 - re_lu_177_loss: 2.1887 - re_lu_233_loss: 1.5070 - re_lu_65_accuracy: 0.7555 - re_lu_121_accuracy: 0.8383 - re_lu_177_accuracy: 0.9056 - re_lu_233_accuracy: 0.9354   ETA: 1:16 - loss: 15.5889 - re_lu_65_loss: 8.2461 - re_lu_121_loss: 3.6991 - re_lu_177_loss: 2.1588 - re_lu_233_loss: 1.4849 - re_lu_65_accuracy: 0.7560 - re_lu_ - ETA: 1:09 - loss: 15.69 - ETA: 39s - loss: 15.8086 - re_lu_65_loss: 8.3379 - re_lu_121_loss: 3.7701 - re_lu_177_loss: 2. - ETA: 13s - loss: 15.7686 - re_lu_65_loss: 8.3308 - re_lu_121_loss: 3.7483 - re_lu_177_loss: 2.1820 - re_lu_233_loss: 1.5075 - re_lu_65_accuracy: 0.7548 - re_lu_121_accuracy: 0.8390 - re_lu_177_ - ETA: 7s - loss: 15.7268 - re_lu_65_loss: 8.3089 - re_lu_121_loss: 3.7402 - re_lu_177_loss: 2.1745 - re_lu_233_loss: 1.5032 - re_lu_65_accuracy: 0.7557 - re_lu_121_accuracy: 0.8392 - - ETA: 2s - loss: 15.7950 - re_lu_65_loss: 8.3379 - re_lu_121_loss: 3.7575 - re_lu_177_loss: 2.1897 - re_lu_233_loss: 1.5098 - re_lu_65_accuracy: 0.7553 - re_lu_121_accuracy: 0.8383 - re_lu_177_accuracy: 0.9054 - re\n",
      "Epoch 00059: loss improved from 16.12704 to 15.78605, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 15.7860 - re_lu_65_loss: 8.3320 - re_lu_121_loss: 3.7584 - re_lu_177_loss: 2.1887 - re_lu_233_loss: 1.5070 - re_lu_65_accuracy: 0.7555 - re_lu_121_accuracy: 0.8383 - re_lu_177_accuracy: 0.9056 - re_lu_233_accuracy: 0.9354 - val_loss: 157.3324 - val_re_lu_65_loss: 38.6862 - val_re_lu_121_loss: 38.7296 - val_re_lu_177_loss: 39.6783 - val_re_lu_233_loss: 40.2383 - val_re_lu_65_accuracy: 0.7685 - val_re_lu_121_accuracy: 0.7299 - val_re_lu_177_accuracy: 0.7715 - val_re_lu_233_accuracy: 0.8527\n",
      "Learning rate:  0.0005\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.5519 - re_lu_65_loss: 8.2384 - re_lu_121_loss: 3.6912 - re_lu_177_loss: 2.1489 - re_lu_233_loss: 1.4733 - re_lu_65_accuracy: 0.7600 - re_lu_121_accuracy: 0.8350 - re_lu_177_accuracy: 0.9021 - re_lu_233_accuracy: 0.9403   ETA: 1:36 - loss: 15.4363 - re_lu_65_loss: 8.1603 - re_lu_121_loss: 3.6242 - re_lu_177_loss: 2.1525 - re_lu_233_loss: 1.4993 - re_lu_65_accuracy: 0.7673 - re_lu_121_accuracy: 0.8461 - re_lu_177_accuracy: 0.9077 - re_lu_233_accu - ETA: 1:35 - loss: 15.4031 - re_lu_65_loss: 8.1440 - re_lu_121_loss: 3.6153 - re_lu_177_loss: 2. - ETA: 1:22 - loss: 15.4553 - re_lu_65_loss: 8.1805 - re_lu_121_loss: 3.6371 - re_lu_177_loss: 2.1563 - re\n",
      "Epoch 00060: loss improved from 15.78605 to 15.55190, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 15.5519 - re_lu_65_loss: 8.2384 - re_lu_121_loss: 3.6912 - re_lu_177_loss: 2.1489 - re_lu_233_loss: 1.4733 - re_lu_65_accuracy: 0.7600 - re_lu_121_accuracy: 0.8350 - re_lu_177_accuracy: 0.9021 - re_lu_233_accuracy: 0.9403 - val_loss: 158.6599 - val_re_lu_65_loss: 38.9215 - val_re_lu_121_loss: 39.0614 - val_re_lu_177_loss: 39.9488 - val_re_lu_233_loss: 40.7282 - val_re_lu_65_accuracy: 0.7447 - val_re_lu_121_accuracy: 0.7158 - val_re_lu_177_accuracy: 0.7708 - val_re_lu_233_accuracy: 0.8261\n",
      "Learning rate:  0.0005\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.1969 - re_lu_65_loss: 8.0851 - re_lu_121_loss: 3.5961 - re_lu_177_loss: 2.0896 - re_lu_233_loss: 1.4261 - re_lu_65_accuracy: 0.7667 - re_lu_121_accuracy: 0.8374 - re_lu_177_accuracy: 0.9103 - re_lu_233_accuracy: 0.9421   ETA: 2:39 - loss: 15.6568 - re_lu_65_loss: 8.2201 - re_ - ETA: 2:23 - loss: 14.6150 - - ETA: 1:42 - loss: 14.9985 - re_lu_65_loss: 7.9488 - re_lu_121_loss: 3.5562 - re_lu_177_loss: 2.0692 - re_lu_233_loss: 1.4243 - re_lu_65_accuracy: 0.7706 - re_lu_121_ac - ETA: 1:35 - loss: 15.0631 - re_lu_65_loss: 7.9950 - re_lu_121_loss: 3.5728 - re_lu_177_loss: 2.0716 - r - ETA: 1:23 - loss: 15.2293 - re_lu_65_loss: 8.0862 - re_lu_121_loss: 3.6139 - - ETA: 32s - loss: 15.1496 - re_lu_65_loss: 8.0427 - re_lu_121_loss: 3.5758 - re_lu_177_loss: 2.0919 - re_lu_233_loss: 1.4391 - re_lu_65_accuracy: 0.7673 - re_lu_121_accuracy: 0.8376 - re_lu_177_accuracy: 0.9113 - re_lu_233_accuracy: - ETA: 30s - loss\n",
      "Epoch 00061: loss improved from 15.55190 to 15.19692, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 216s 216ms/step - loss: 15.1969 - re_lu_65_loss: 8.0851 - re_lu_121_loss: 3.5961 - re_lu_177_loss: 2.0896 - re_lu_233_loss: 1.4261 - re_lu_65_accuracy: 0.7667 - re_lu_121_accuracy: 0.8374 - re_lu_177_accuracy: 0.9103 - re_lu_233_accuracy: 0.9421 - val_loss: 158.2475 - val_re_lu_65_loss: 38.8175 - val_re_lu_121_loss: 38.9995 - val_re_lu_177_loss: 39.7502 - val_re_lu_233_loss: 40.6804 - val_re_lu_65_accuracy: 0.7449 - val_re_lu_121_accuracy: 0.7650 - val_re_lu_177_accuracy: 0.7411 - val_re_lu_233_accuracy: 0.8188\n",
      "Learning rate:  0.0005\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.9829 - re_lu_65_loss: 7.9600 - re_lu_121_loss: 3.5390 - re_lu_177_loss: 2.0714 - re_lu_233_loss: 1.4125 - re_lu_65_accuracy: 0.7712 - re_lu_121_accuracy: 0.8332 - re_lu_177_accuracy: 0.9086 - re_lu_233_accuracy: 0.9474   ETA: 1:34 - loss: 14.7028 - re_lu_65_loss: 7.8577 - re_lu_121_loss: 3.5037 - re_lu_177_loss: 1.9988 - re_lu_233_loss: 1.3427 - re_lu_65_accurac - ETA: 1:03 - loss: 14.8047 - re_lu_65_loss: 7.8962 - re_lu_121_loss: 3.5057 - re_lu_177_loss: 2.0275 - re_lu_233_loss: 1.3753 - re_lu_65_accuracy: 0.7759 - re_lu_121_accuracy: 0.8370 - re_lu_177_accuracy: 0.912 - ETA: 1:00 - loss: 14.7967 - re_l - ETA: 23s - loss: 14.7401 - re_lu_65_loss: 7.8485 - re_lu_1\n",
      "Epoch 00062: loss improved from 15.19692 to 14.98292, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 14.9829 - re_lu_65_loss: 7.9600 - re_lu_121_loss: 3.5390 - re_lu_177_loss: 2.0714 - re_lu_233_loss: 1.4125 - re_lu_65_accuracy: 0.7712 - re_lu_121_accuracy: 0.8332 - re_lu_177_accuracy: 0.9086 - re_lu_233_accuracy: 0.9474 - val_loss: 158.3286 - val_re_lu_65_loss: 38.7901 - val_re_lu_121_loss: 38.8477 - val_re_lu_177_loss: 39.9271 - val_re_lu_233_loss: 40.7637 - val_re_lu_65_accuracy: 0.7385 - val_re_lu_121_accuracy: 0.6767 - val_re_lu_177_accuracy: 0.7361 - val_re_lu_233_accuracy: 0.8775\n",
      "Learning rate:  0.0005\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.6949 - re_lu_65_loss: 7.8468 - re_lu_121_loss: 3.4702 - re_lu_177_loss: 2.0114 - re_lu_233_loss: 1.3665 - re_lu_65_accuracy: 0.7777 - re_lu_121_accuracy: 0.8455 - re_lu_177_accuracy: 0.9092 - re_lu_233_accuracy: 0.9489 - ETA: 28s - loss: 14.6127 - re_lu_65_loss: 7.8148 - re_lu_121_loss: 3.4524 - re_lu_177_loss: 1.9961 - re_lu_233_loss: 1.3493 - re_lu_65_accuracy: 0.7806 -  - ETA: 13s - loss: 14.6912 - re_lu_65_loss: 7.8400 - re_lu_121_loss: 3.4710 - re_lu_177_loss: 2.0130 - re_lu_233_loss: 1.3672 - re_lu_65_accuracy: 0.7786 - re_lu_121_accuracy: 0.8451 - re_lu_177 - ETA: 7s - loss: 14.6809 - re_lu_65_loss: 7.8321 - re_lu_121_loss: 3.4703 - re_lu_177_loss: 2.0132 - re_lu_233_loss: 1.3652 - re_lu_65_accuracy: 0.7780 - re_l\n",
      "Epoch 00063: loss improved from 14.98292 to 14.69494, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 14.6949 - re_lu_65_loss: 7.8468 - re_lu_121_loss: 3.4702 - re_lu_177_loss: 2.0114 - re_lu_233_loss: 1.3665 - re_lu_65_accuracy: 0.7777 - re_lu_121_accuracy: 0.8455 - re_lu_177_accuracy: 0.9092 - re_lu_233_accuracy: 0.9489 - val_loss: 156.5709 - val_re_lu_65_loss: 38.4051 - val_re_lu_121_loss: 38.6105 - val_re_lu_177_loss: 39.3012 - val_re_lu_233_loss: 40.2541 - val_re_lu_65_accuracy: 0.7525 - val_re_lu_121_accuracy: 0.7259 - val_re_lu_177_accuracy: 0.7316 - val_re_lu_233_accuracy: 0.8470\n",
      "Learning rate:  0.0005\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.4907 - re_lu_65_loss: 7.7374 - re_lu_121_loss: 3.4099 - re_lu_177_loss: 1.9878 - re_lu_233_loss: 1.3555 - re_lu_65_accuracy: 0.7705 - re_lu_121_accuracy: 0.8520 - re_lu_177_accuracy: 0.9168 - re_lu_233_accuracy: 0.95480  ETA: 1:02 - loss:  - ETA: 24s - loss: 14.3975 - re_lu_65_loss: 7.6920 - re_lu_121_loss: 3.3843 - re_lu_177_loss: 1.9694 - re_lu_233_loss: 1.3519 - re_lu_65_accuracy: 0.7727 - re_lu_121_accuracy: 0.8537 - re_lu_177_accuracy: 0.9170 -  - ETA: 19s - loss: 14.4681 - re_lu_65_loss: 7.7233 - re_lu_121_loss: 3.4046 - re_lu_177_loss: 1.9818 - re_lu_233_loss: 1.3585 - re_lu_65_accuracy: 0.7719 - re_lu_121_accuracy: 0.8531 - re_ - ETA: 9s - loss: 14.4892 - re_lu_65_loss: 7.7335 - re_lu_121_loss: 3.4125 - re_lu_177_loss: 1.9860 - re_lu_233_loss: 1.3572 - re_lu_65_accuracy: 0.7711 - re_lu_121_accuracy: 0.8523 - re_lu_177_accuracy: 0.9168 - re_lu_233_acc - ETA: 8s - loss: 14.4755 - re_lu_65_loss: 7.7305 - re_lu_121_loss: 3.4073 - re_lu_177_loss: 1.9832 - re_lu_233_loss: 1.3545 - re_lu_65_accuracy:\n",
      "Epoch 00064: loss improved from 14.69494 to 14.49067, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 14.4907 - re_lu_65_loss: 7.7374 - re_lu_121_loss: 3.4099 - re_lu_177_loss: 1.9878 - re_lu_233_loss: 1.3555 - re_lu_65_accuracy: 0.7705 - re_lu_121_accuracy: 0.8520 - re_lu_177_accuracy: 0.9168 - re_lu_233_accuracy: 0.9548 - val_loss: 159.2615 - val_re_lu_65_loss: 38.8616 - val_re_lu_121_loss: 39.3571 - val_re_lu_177_loss: 40.2152 - val_re_lu_233_loss: 40.8275 - val_re_lu_65_accuracy: 0.7814 - val_re_lu_121_accuracy: 0.7254 - val_re_lu_177_accuracy: 0.7740 - val_re_lu_233_accuracy: 0.8674\n",
      "Learning rate:  0.0005\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.1566 - re_lu_65_loss: 7.6239 - re_lu_121_loss: 3.3238 - re_lu_177_loss: 1.9160 - re_lu_233_loss: 1.2928 - re_lu_65_accuracy: 0.7829 - re_lu_121_accuracy: 0.8512 - re_lu_177_accuracy: 0.9117 - re_lu_233_accuracy: 0.9536   ETA: 2:24 - loss: 13.5082 - re_lu_65_loss: 7.4166 - re_lu_121_loss: 3.1302 - re_lu_177_loss: 1.7536 - re_lu_233_loss: 1.2078 - re_lu_65_accuracy: 0.7870 - re_lu_121_accuracy: 0.8549 - re_lu_177_accuracy: 0.9199 - re_lu_233_accuracy:  - ETA: 2:23 - loss: 13.4703 - re_lu_65_loss: 7.3989 - re_lu_121_loss: 3.1171 - re_lu_177_loss: 1.7469 - re_lu_233_loss: 1.2074 - re_lu_65_accuracy: 0\n",
      "Epoch 00065: loss improved from 14.49067 to 14.15655, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 14.1566 - re_lu_65_loss: 7.6239 - re_lu_121_loss: 3.3238 - re_lu_177_loss: 1.9160 - re_lu_233_loss: 1.2928 - re_lu_65_accuracy: 0.7829 - re_lu_121_accuracy: 0.8512 - re_lu_177_accuracy: 0.9117 - re_lu_233_accuracy: 0.9536 - val_loss: 158.0527 - val_re_lu_65_loss: 38.7123 - val_re_lu_121_loss: 38.9790 - val_re_lu_177_loss: 39.8642 - val_re_lu_233_loss: 40.4971 - val_re_lu_65_accuracy: 0.7975 - val_re_lu_121_accuracy: 0.7265 - val_re_lu_177_accuracy: 0.7949 - val_re_lu_233_accuracy: 0.8947\n",
      "Learning rate:  0.0005\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.8650 - re_lu_65_loss: 7.4848 - re_lu_121_loss: 3.2413 - re_lu_177_loss: 1.8766 - re_lu_233_loss: 1.2621 - re_lu_65_accuracy: 0.7805 - re_lu_121_accuracy: 0.8584 - re_lu_177_accuracy: 0.9160 - re_lu_233_accuracy: 0.9521   ETA: 1:23 - loss: 13.8131 - re_lu_65_loss: 7.4341 - re_lu_121_loss: 3.2431 - re_lu_177_loss: 1.8743 - re_lu_233_loss: 1.2617 - re_lu_65_accuracy: 0.782 - ETA: 1:15 - loss: 13.7743 - re_lu_65_loss: 7.4224 - re_lu_121_loss: 3.2247 - re_lu_177_loss: 1.8685 - re_lu_233_loss: 1.2586 - re_lu_65_accuracy: 0.7830 - re_lu_121_accuracy: 0.8579 - re_lu_177_accuracy: 0.9142 - re_lu_233_ - ETA: 1:14 - loss: 13.8319 - re_lu_65_loss: 7.4521 - re_lu_121_loss: 3.2426 - re_lu_177_loss: 1.8772 - re_lu_233_loss: 1.2600 - re_lu_65_accuracy: 0.7818 - re_lu_121_accuracy: 0.8569 - ETA: 1:09 - loss: 13.8928 - re_lu_65_loss: 7.4744 - re_lu_121_loss: 3.2646 - re_lu_177_loss: 1.8891 - re_lu_233_loss: 1.2647 - re_lu_65_a - ETA: 16s - loss: 13.9280 - re_lu_65_loss: 7.5048 - re_lu_121_loss: 3.2671 - re_lu_177_loss: 1.88\n",
      "Epoch 00066: loss improved from 14.15655 to 13.86497, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 13.8650 - re_lu_65_loss: 7.4848 - re_lu_121_loss: 3.2413 - re_lu_177_loss: 1.8766 - re_lu_233_loss: 1.2621 - re_lu_65_accuracy: 0.7805 - re_lu_121_accuracy: 0.8584 - re_lu_177_accuracy: 0.9160 - re_lu_233_accuracy: 0.9521 - val_loss: 157.9828 - val_re_lu_65_loss: 38.7040 - val_re_lu_121_loss: 38.9319 - val_re_lu_177_loss: 39.8300 - val_re_lu_233_loss: 40.5169 - val_re_lu_65_accuracy: 0.7811 - val_re_lu_121_accuracy: 0.8068 - val_re_lu_177_accuracy: 0.7918 - val_re_lu_233_accuracy: 0.8955\n",
      "Learning rate:  0.0005\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.7443 - re_lu_65_loss: 7.4201 - re_lu_121_loss: 3.2127 - re_lu_177_loss: 1.8620 - re_lu_233_loss: 1.2494 - re_lu_65_accuracy: 0.7912 - re_lu_121_accuracy: 0.8612 - re_lu_177_accuracy: 0.9207 - re_lu_233_accuracy: 0.9602 - ETA: 20s - loss: 13.6769 - re_lu_65_loss: 7.3608 - re_lu_121_loss: 3.2070 - re_lu_177_loss: 1.8625 - re_lu_233_loss: 1.2466 - re_lu_65_accuracy: 0.7929 - re_lu_121_accuracy: 0.8625 - re_lu_ - ETA: 11s - loss: 13.7151 - re_lu_65_loss: 7.3913 - re_lu_121_loss: 3.2154 - re_lu_177_loss: 1.8601 - re_lu_233_loss: 1.\n",
      "Epoch 00067: loss improved from 13.86497 to 13.74429, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 13.7443 - re_lu_65_loss: 7.4201 - re_lu_121_loss: 3.2127 - re_lu_177_loss: 1.8620 - re_lu_233_loss: 1.2494 - re_lu_65_accuracy: 0.7912 - re_lu_121_accuracy: 0.8612 - re_lu_177_accuracy: 0.9207 - re_lu_233_accuracy: 0.9602 - val_loss: 157.6368 - val_re_lu_65_loss: 38.6641 - val_re_lu_121_loss: 38.8752 - val_re_lu_177_loss: 39.7282 - val_re_lu_233_loss: 40.3693 - val_re_lu_65_accuracy: 0.7773 - val_re_lu_121_accuracy: 0.7409 - val_re_lu_177_accuracy: 0.7824 - val_re_lu_233_accuracy: 0.8678\n",
      "Learning rate:  0.0005\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.4324 - re_lu_65_loss: 7.2848 - re_lu_121_loss: 3.1323 - re_lu_177_loss: 1.8060 - re_lu_233_loss: 1.2092 - re_lu_65_accuracy: 0.7955 - re_lu_121_accuracy: 0.8586 - re_lu_177_accuracy: 0.9197 - re_lu_233_accuracy: 0.9590   ETA: 2:06 - loss: 13.3741 - re_lu_65_loss: 7.2722 - re_lu_121_loss: 3.1179 - re_lu_177_loss: 1.7912 - re_lu_233_loss: 1.1928 - re_lu_65_accuracy: 0.7972 - re_lu_121_accuracy: 0.8656 - - ETA: 2:01 - loss: 13.4557 - re_lu_65_loss: 7.3480 - re_lu_121_loss: 3.1266 - re_lu_177_loss: 1.7916 - re_lu_233_loss: 1.1896 - re_lu_65_accur - ETA: 1:52 - loss: 13.6028 - re_lu_65_loss: 7.3679 - re_lu_1 - ETA: 45s - loss: 13.5320 - re_lu_65_loss: 7.3410 - re_lu_121_loss: 3.1585 - re_lu_177_loss: 1.8269 - re_lu_233_loss: 1.2056 - re_lu_65_accuracy: 0.7937 - re_ - ETA: 30s - loss:\n",
      "Epoch 00068: loss improved from 13.74429 to 13.43244, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 13.4324 - re_lu_65_loss: 7.2848 - re_lu_121_loss: 3.1323 - re_lu_177_loss: 1.8060 - re_lu_233_loss: 1.2092 - re_lu_65_accuracy: 0.7955 - re_lu_121_accuracy: 0.8586 - re_lu_177_accuracy: 0.9197 - re_lu_233_accuracy: 0.9590 - val_loss: 158.3125 - val_re_lu_65_loss: 38.7434 - val_re_lu_121_loss: 38.9198 - val_re_lu_177_loss: 39.9176 - val_re_lu_233_loss: 40.7317 - val_re_lu_65_accuracy: 0.7933 - val_re_lu_121_accuracy: 0.7429 - val_re_lu_177_accuracy: 0.8004 - val_re_lu_233_accuracy: 0.8807\n",
      "Learning rate:  0.0005\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.2881 - re_lu_65_loss: 7.2087 - re_lu_121_loss: 3.0941 - re_lu_177_loss: 1.7806 - re_lu_233_loss: 1.2047 - re_lu_65_accuracy: 0.8003 - re_lu_121_accuracy: 0.8623 - re_lu_177_accuracy: 0.9256 - re_lu_233_accuracy: 0.9621   ETA: 2:05 - loss: 13.0348 - re_lu_65_loss:  - ETA:  - ETA: 1:26 - loss: 13.0285 - re_lu_65_loss: 7.0838 - re_lu_121_loss: 3.0343 - re_lu_177_loss: 1.7335 - re_lu_233_loss: 1.1769 - re_lu_65_accu - ETA: 8s - loss: 13.2685 - re_lu_65_loss: 7.2115 - re_lu_121_loss: 3.0808 - re_lu_177_loss: 1.7754 - re_lu_233_loss: 1.2008 - re_lu_65_accuracy: 0.8001 - re_lu_121_accuracy: 0. - ETA: 2s - loss: 13.3123 - re_lu_65_loss: 7.2211 - re_lu_121_loss: 3.0982 - re_lu_177_loss: 1.7847 - re_lu_233_loss: 1.2083 - re_lu_65_accuracy: 0.8002 - re_lu_121_accuracy: 0.8626 - re_lu_177_accuracy: 0.9\n",
      "Epoch 00069: loss improved from 13.43244 to 13.28810, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 13.2881 - re_lu_65_loss: 7.2087 - re_lu_121_loss: 3.0941 - re_lu_177_loss: 1.7806 - re_lu_233_loss: 1.2047 - re_lu_65_accuracy: 0.8003 - re_lu_121_accuracy: 0.8623 - re_lu_177_accuracy: 0.9256 - re_lu_233_accuracy: 0.9621 - val_loss: 158.8388 - val_re_lu_65_loss: 38.8156 - val_re_lu_121_loss: 39.1830 - val_re_lu_177_loss: 40.1533 - val_re_lu_233_loss: 40.6869 - val_re_lu_65_accuracy: 0.7906 - val_re_lu_121_accuracy: 0.7550 - val_re_lu_177_accuracy: 0.7603 - val_re_lu_233_accuracy: 0.8947\n",
      "Learning rate:  0.0005\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.0377 - re_lu_65_loss: 7.1004 - re_lu_121_loss: 3.0351 - re_lu_177_loss: 1.7381 - re_lu_233_loss: 1.1641 - re_lu_65_accuracy: 0.8021 - re_lu_121_accuracy: 0.8589 - re_lu_177_accuracy: 0.9218 - re_lu_233_accuracy: 0.9629   ETA: 1:11  - ETA: 41s - loss: 13.1158 - re_lu_65_loss: 7.1279 - re_lu_121_loss: 3.0593 - re_lu_177_loss: 1.7511 - re_lu_233_ - ETA: 18s - loss: 13.0748 - re_lu_65_loss: 7.1340 - re_lu_121_loss: 3.0451 - re_lu_177_loss: 1.7333 - re_lu_233_loss: 1.1625 - re_lu_65_accuracy: 0.8000 - re_lu_121_accuracy: 0.8572 - re_lu_177_accuracy: 0. - ETA: 12s - loss: 13.0899 - re_lu_65_loss: 7.1360 - re_lu_121_loss: 3.0466 - re_lu_177_loss: 1.7420 - re_lu_233_loss: 1.1654 - re_lu_65_accuracy: 0.8001 - re_lu_121_accuracy: 0.8574 - re_lu_177_accuracy: 0.9216 - re_lu_233_accuracy: - ETA: 11s - loss: 13.0756 - re_lu_65_loss: 7.1254 - re_lu_121_loss: 3.0425 - re_lu_177_loss: 1.7420 - re_lu_233_loss: 1.165\n",
      "Epoch 00070: loss improved from 13.28810 to 13.03769, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 13.0377 - re_lu_65_loss: 7.1004 - re_lu_121_loss: 3.0351 - re_lu_177_loss: 1.7381 - re_lu_233_loss: 1.1641 - re_lu_65_accuracy: 0.8021 - re_lu_121_accuracy: 0.8589 - re_lu_177_accuracy: 0.9218 - re_lu_233_accuracy: 0.9629 - val_loss: 158.8920 - val_re_lu_65_loss: 38.8084 - val_re_lu_121_loss: 39.1613 - val_re_lu_177_loss: 40.0998 - val_re_lu_233_loss: 40.8225 - val_re_lu_65_accuracy: 0.8011 - val_re_lu_121_accuracy: 0.7280 - val_re_lu_177_accuracy: 0.7549 - val_re_lu_233_accuracy: 0.9105\n",
      "Learning rate:  0.0005\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.8960 - re_lu_65_loss: 7.0401 - re_lu_121_loss: 2.9966 - re_lu_177_loss: 1.7029 - re_lu_233_loss: 1.1565 - re_lu_65_accuracy: 0.8096 - re_lu_121_accuracy: 0.8597 - re_lu_177_accuracy: 0.9219 - re_lu_233_accuracy: 0.9579   ETA: 2:36 - loss: 12.4031 - re_lu_65_loss: 6.9459 - re_lu_121_loss: 2.9122 - re_lu_177_loss: 1.5264 - re_lu_233_loss: 1.0187 - re_lu_65_accuracy: 0.8120 - re_lu_121_accuracy: 0.8667 - re_lu_177_accuracy: 0.9279 - re_lu_233_ac - ETA: 2:35 - loss: 12.2238 - re_lu_65_loss: 6.8459 - re_lu_121_loss: 2.8585 - re_lu_177_loss: 1.5052 - re_lu_233_loss: 1.0142 - re_lu_65_accuracy: 0.8152 - re_lu_121_accuracy: 0.8698 - re_lu_177_accuracy: 0 - ETA: 2:32 - loss: 12.2591 - re_lu_65_loss: 6.8396 - re_lu_121_loss: 2.8842 - re_lu_177_loss: 1.5204 - re_lu_233_loss: 1.0150 - re_lu_65_accuracy: 0.8169 - re_lu_121_ - ETA: 2:25 - loss: 12.6133 - re_lu_65_loss: 7.0346 - r - E - ETA: 1:25 - loss: 12.9373 - re_lu_65_loss: 7.1101 - re_lu_121_loss: 3.0188 - re_lu_177_loss: 1.6813 - re_lu_233_loss: 1.1270 - re_lu_65_accuracy: 0.8095 - re_lu_121_accuracy: 0.8575 - re_lu_177_accuracy: 0.9211 - re_lu_233_accuracy:  - ETA: 1:24 - loss: 12.9159 - re_lu_6 - ETA: 1:06 - loss: 12.9493 - re_lu_65_loss: 7.1207 - re_lu_121_loss: 3 - ETA: 41s - loss: 12.9841 - re_lu_65_loss: 7.0853 - re_lu_121_loss: 3.0363 - re_lu_177_loss: 1.7119 - re_lu_233_loss: 1.1505 - re_lu_65_accuracy: 0.8099 - re_lu_121_accuracy: 0.8572 - re_lu_177_accuracy - ETA: 35s - loss: 12.9640 - re_lu_65_loss: 7.0750 - re_lu_121_loss: 3.0302 - re_lu_177_loss: 1.7102 - re_ - ETA: 10s - loss: 12.9085 - re_lu_65_loss: 7.0472 - re_lu_121_loss: 2.9996 - re_lu_177_loss: 1.7042 - re_lu_233_loss: 1.1576 - \n",
      "Epoch 00071: loss improved from 13.03769 to 12.89599, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 12.8960 - re_lu_65_loss: 7.0401 - re_lu_121_loss: 2.9966 - re_lu_177_loss: 1.7029 - re_lu_233_loss: 1.1565 - re_lu_65_accuracy: 0.8096 - re_lu_121_accuracy: 0.8597 - re_lu_177_accuracy: 0.9219 - re_lu_233_accuracy: 0.9579 - val_loss: 159.9410 - val_re_lu_65_loss: 38.9370 - val_re_lu_121_loss: 39.5695 - val_re_lu_177_loss: 40.1845 - val_re_lu_233_loss: 41.2501 - val_re_lu_65_accuracy: 0.7883 - val_re_lu_121_accuracy: 0.6808 - val_re_lu_177_accuracy: 0.7556 - val_re_lu_233_accuracy: 0.8746\n",
      "Learning rate:  0.0005\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.5769 - re_lu_65_loss: 6.8943 - re_lu_121_loss: 2.9184 - re_lu_177_loss: 1.6458 - re_lu_233_loss: 1.1183 - re_lu_65_accuracy: 0.8115 - re_lu_121_accuracy: 0.8641 - re_lu_177_accuracy: 0.9271 - re_lu_233_accuracy: 0.9618 - ETA: 54s - loss: 12.5305 - re_lu_65_loss: 6.8400 - re_lu_121_loss: - ETA: 23s - loss: 12.5055 - re_lu_65_loss: 6.8418 - re_l\n",
      "Epoch 00072: loss improved from 12.89599 to 12.57686, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 12.5769 - re_lu_65_loss: 6.8943 - re_lu_121_loss: 2.9184 - re_lu_177_loss: 1.6458 - re_lu_233_loss: 1.1183 - re_lu_65_accuracy: 0.8115 - re_lu_121_accuracy: 0.8641 - re_lu_177_accuracy: 0.9271 - re_lu_233_accuracy: 0.9618 - val_loss: 159.0658 - val_re_lu_65_loss: 38.8079 - val_re_lu_121_loss: 39.3897 - val_re_lu_177_loss: 40.0924 - val_re_lu_233_loss: 40.7758 - val_re_lu_65_accuracy: 0.8004 - val_re_lu_121_accuracy: 0.7039 - val_re_lu_177_accuracy: 0.7620 - val_re_lu_233_accuracy: 0.9006\n",
      "Learning rate:  0.0005\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.4628 - re_lu_65_loss: 6.8369 - re_lu_121_loss: 2.8872 - re_lu_177_loss: 1.6281 - re_lu_233_loss: 1.1106 - re_lu_65_accuracy: 0.8162 - re_lu_121_accuracy: 0.8671 - re_lu_177_accuracy: 0.9305 - re_lu_233_accuracy: 0.9602   ETA: 1:31 - loss: 12.3408 - re_lu_65_loss: 6.7725 - re_lu_121_loss: - ETA: 1:15 - l - ETA: 49s - loss: 12.2903 - re_lu_65_loss: 6.7615 - re_lu_121_loss: 2.8236 - re_lu_177_loss: 1.6079 - re_lu_233_loss: 1.0972 - re_lu_65_accuracy: 0.8178 - - ETA: 34s - loss: 12.4484 - re_lu_65_loss: 6.8420 - re_lu_121_loss: 2.8696 - re_lu_177_loss: 1.6275 - re_lu_233_loss: 1.1093 - - ETA: 13s - loss: 12.4408 - re_lu_65_loss: 6.8269 - re_lu_121_loss: 2.8810 - re_lu_177_loss: 1.6284 - re_lu_233\n",
      "Epoch 00073: loss improved from 12.57686 to 12.46282, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 12.4628 - re_lu_65_loss: 6.8369 - re_lu_121_loss: 2.8872 - re_lu_177_loss: 1.6281 - re_lu_233_loss: 1.1106 - re_lu_65_accuracy: 0.8162 - re_lu_121_accuracy: 0.8671 - re_lu_177_accuracy: 0.9305 - re_lu_233_accuracy: 0.9602 - val_loss: 157.3168 - val_re_lu_65_loss: 38.4877 - val_re_lu_121_loss: 38.7335 - val_re_lu_177_loss: 39.6977 - val_re_lu_233_loss: 40.3979 - val_re_lu_65_accuracy: 0.8009 - val_re_lu_121_accuracy: 0.7408 - val_re_lu_177_accuracy: 0.8193 - val_re_lu_233_accuracy: 0.9009\n",
      "Learning rate:  0.0005\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.1963 - re_lu_65_loss: 6.7312 - re_lu_121_loss: 2.8138 - re_lu_177_loss: 1.5759 - re_lu_233_loss: 1.0754 - re_lu_65_accuracy: 0.8163 - re_lu_121_accuracy: 0.8714 - re_lu_177_accuracy: 0.9342 - re_lu_233_accuracy: 0.9590   ETA: 1:04 - loss: 12.0883 - re_lu_65_loss: 6.6633 - re_lu_121_loss: 2.7725 - re_lu_177_loss: 1.5770 - re_lu_233_loss: 1.0754 - re_lu_65_accuracy: 0.8203 - re_lu_121_accuracy: 0.8743 - re_lu_177_accuracy: 0.9362 - re_lu_233_accuracy - ETA: 1:04 - loss: 12.1138 - re_lu_65_loss: 6.6777 - re_lu_121_loss: 2.7778 - re_lu_177_loss: 1.5812  - ETA: 42s - loss: 12.1837 - re_lu_65_loss: 6.6890 - re_lu_121_loss: 2.8112 - re_lu_177_loss: 1.5940 - re_lu_233_loss: 1.0896 - r - ETA: 22s - loss: 12.1795 - re_lu_65_loss: 6.7067 - re_lu_121_loss: 2.8114 - re_lu_177_loss: 1.5823 - re_lu_233_loss: 1.0791 - re_lu_65_accuracy: 0.8177 - re_lu_121_accuracy: 0.8718 - re_lu_177_accuracy: 0.9345 - re_lu_233_accuracy: 0. - ETA: 21s - loss: 12.1690 - re_lu_65_loss: 6.6997 - re_lu_121_loss: 2.8097 - re_lu_177_loss: 1.5811 - re_lu_233_loss: 1.0785 - re_lu_65_accuracy: 0.8179 - re_lu_121_accuracy: 0.8719 - re_lu_177_accuracy: 0.9345 - re_lu_23 - ETA: 18s - loss: 12.2025 - re_lu_65_loss: 6.7161 - re_lu_121_loss: 2.8199 - re_lu_1\n",
      "Epoch 00074: loss improved from 12.46282 to 12.19630, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 12.1963 - re_lu_65_loss: 6.7312 - re_lu_121_loss: 2.8138 - re_lu_177_loss: 1.5759 - re_lu_233_loss: 1.0754 - re_lu_65_accuracy: 0.8163 - re_lu_121_accuracy: 0.8714 - re_lu_177_accuracy: 0.9342 - re_lu_233_accuracy: 0.9590 - val_loss: 158.3467 - val_re_lu_65_loss: 38.7866 - val_re_lu_121_loss: 39.0884 - val_re_lu_177_loss: 39.8881 - val_re_lu_233_loss: 40.5836 - val_re_lu_65_accuracy: 0.7957 - val_re_lu_121_accuracy: 0.7209 - val_re_lu_177_accuracy: 0.7165 - val_re_lu_233_accuracy: 0.8838\n",
      "Learning rate:  0.0005\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.0681 - re_lu_65_loss: 6.6559 - re_lu_121_loss: 2.7860 - re_lu_177_loss: 1.5556 - re_lu_233_loss: 1.0707 - re_lu_65_accuracy: 0.8140 - re_lu_121_accuracy: 0.8724 - re_lu_177_accuracy: 0.9310 - re_lu_233_accuracy: 0.9633   ETA: 1:12 - loss: 12.0290 - ETA: 45s - loss: 11.9418 - re_lu_65_loss: 6.6242 - re_lu - ETA: 12s - loss: 11.9877 - re_lu_65_loss: 6.6220 - re_lu_121_loss: 2.7592 - re_lu_177_loss: 1.5401 - re_lu_233_loss:\n",
      "Epoch 00075: loss improved from 12.19630 to 12.06811, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 12.0681 - re_lu_65_loss: 6.6559 - re_lu_121_loss: 2.7860 - re_lu_177_loss: 1.5556 - re_lu_233_loss: 1.0707 - re_lu_65_accuracy: 0.8140 - re_lu_121_accuracy: 0.8724 - re_lu_177_accuracy: 0.9310 - re_lu_233_accuracy: 0.9633 - val_loss: 159.1497 - val_re_lu_65_loss: 39.0059 - val_re_lu_121_loss: 39.1240 - val_re_lu_177_loss: 40.2114 - val_re_lu_233_loss: 40.8084 - val_re_lu_65_accuracy: 0.7942 - val_re_lu_121_accuracy: 0.7596 - val_re_lu_177_accuracy: 0.7991 - val_re_lu_233_accuracy: 0.9060\n",
      "Learning rate:  0.0005\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.8631 - re_lu_65_loss: 6.5714 - re_lu_121_loss: 2.7305 - re_lu_177_loss: 1.5146 - re_lu_233_loss: 1.0466 - re_lu_65_accuracy: 0.8223 - re_lu_121_accuracy: 0.8711 - re_lu_177_accuracy: 0.9383 - re_lu_233_accuracy: 0.9643   ETA: 1:00 - loss: 11.7381 - re_lu_65_loss: 6.5388 - re_lu_121_loss: 2.6825 - re_lu_177_loss: 1.4888 - re_lu_233_loss: 1.0279 - re_lu_65_accurac - ETA: 42s - loss: 11.8473 - re_lu_65_loss: 6.5999 - re_lu_121_loss: 2.7104 - re_lu_177_loss: 1.5013 - re_lu_233 - ETA: 19s - loss: 11.7737 - re_lu_65_loss: 6.5435 - re_lu_121_loss: 2.6933 - re_lu_177_loss: 1.4993 - re_lu_ - ETA: 2s - loss: 11.8893 - re_lu_65_loss: 6.5829 - re_lu_121_loss: 2.7374 - re_lu_177_loss: 1.5192 - re_lu_233_loss: 1.0498 - re_lu_65_accuracy: 0.8220 - re_lu_121_accuracy: 0.8708 - re_lu_177_accuracy: 0.9383 - \n",
      "Epoch 00076: loss improved from 12.06811 to 11.86308, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 11.8631 - re_lu_65_loss: 6.5714 - re_lu_121_loss: 2.7305 - re_lu_177_loss: 1.5146 - re_lu_233_loss: 1.0466 - re_lu_65_accuracy: 0.8223 - re_lu_121_accuracy: 0.8711 - re_lu_177_accuracy: 0.9383 - re_lu_233_accuracy: 0.9643 - val_loss: 157.8396 - val_re_lu_65_loss: 38.6155 - val_re_lu_121_loss: 39.0740 - val_re_lu_177_loss: 39.7170 - val_re_lu_233_loss: 40.4330 - val_re_lu_65_accuracy: 0.8107 - val_re_lu_121_accuracy: 0.7047 - val_re_lu_177_accuracy: 0.7751 - val_re_lu_233_accuracy: 0.9088\n",
      "Learning rate:  0.0005\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.6470 - re_lu_65_loss: 6.4863 - re_lu_121_loss: 2.6716 - re_lu_177_loss: 1.4718 - re_lu_233_loss: 1.0173 - re_lu_65_accuracy: 0.8253 - re_lu_121_accuracy: 0.8801 - re_lu_177_accuracy: 0.9362 - re_lu_233_accuracy: 0.9619   ETA: 1:25 - loss: 11.5982 - re_lu_65_loss: 6.4091 - re_lu_121_loss: 2.6738 - re_lu_177_loss: 1.4788 - re_lu_233_loss: 1.0366  - ETA: 44s - loss: 11.6124 - re_lu_65_loss: 6.4487 - re_lu_121_loss: 2.6593 - re_lu_177_loss: 1.4761 - re_lu_233_loss: 1.0282 - re_lu_65_accuracy: 0.8263 - re_lu_121_accuracy: 0.8821 - re_l - ETA: 0s - loss: 11.6534 - re_lu_65_loss: 6.4898 - re_lu_121_loss: 2.6729 - re_lu_177_loss: 1.4727 - re_lu_233_loss: 1.0180 - re_lu_65_accuracy: 0.8253 - re_lu_121_accuracy: 0.8802 - re_lu_177_accuracy: 0.9363 - re_lu_233_accuracy: 0.\n",
      "Epoch 00077: loss improved from 11.86308 to 11.64705, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 11.6470 - re_lu_65_loss: 6.4863 - re_lu_121_loss: 2.6716 - re_lu_177_loss: 1.4718 - re_lu_233_loss: 1.0173 - re_lu_65_accuracy: 0.8253 - re_lu_121_accuracy: 0.8801 - re_lu_177_accuracy: 0.9362 - re_lu_233_accuracy: 0.9619 - val_loss: 158.7915 - val_re_lu_65_loss: 38.7140 - val_re_lu_121_loss: 39.1128 - val_re_lu_177_loss: 40.1388 - val_re_lu_233_loss: 40.8259 - val_re_lu_65_accuracy: 0.8004 - val_re_lu_121_accuracy: 0.7183 - val_re_lu_177_accuracy: 0.7853 - val_re_lu_233_accuracy: 0.9148\n",
      "Learning rate:  0.0005\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.5022 - re_lu_65_loss: 6.4120 - re_lu_121_loss: 2.6327 - re_lu_177_loss: 1.4501 - re_lu_233_loss: 1.0073 - re_lu_65_accuracy: 0.8269 - re_lu_121_accuracy: 0.8804 - re_lu_177_accuracy: 0.9400 - re_lu_233_accuracy: 0.9660   ETA: 2:35 - loss: 9.3393 - re_lu_65_loss: 4.9373 - re_lu_121_loss: 2.0083 - re_lu_177_loss: 1.4702 - re_lu_233_lo - ETA: 2:47 - loss: 11.8264 - re_lu_65_loss: 6.4858 - re_lu_121_loss: 2.7318 - re_lu_177_loss: 1.5958 - re_lu_233_loss: 1.0131 - re_lu_65_accuracy: 0.8353  - ETA: 42s - loss: 11.4284 - re_lu_65_loss: 6.3859 - re_lu_121_loss: 2.6046 - re_lu_177_loss: 1.4383 - re_lu_233_loss: 0.9996 - re_lu_65_accuracy: 0.8277 - re_lu_121_accuracy: 0.8817 - re_lu_177_accuracy: 0.9407 - re_lu_ - ETA: 39s - loss: 11.4053 - re_lu_65_loss: 6.3746 - re_lu_121_loss: 2.5993 - re_lu_177_loss: 1.4328 - re_lu_233_loss: 0.9986 - re_lu_65_accuracy: 0.8280 - re_lu_121_ac - ETA: 25s - loss: 11.4271 - re_lu_65_loss: 6\n",
      "Epoch 00078: loss improved from 11.64705 to 11.50220, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 11.5022 - re_lu_65_loss: 6.4120 - re_lu_121_loss: 2.6327 - re_lu_177_loss: 1.4501 - re_lu_233_loss: 1.0073 - re_lu_65_accuracy: 0.8269 - re_lu_121_accuracy: 0.8804 - re_lu_177_accuracy: 0.9400 - re_lu_233_accuracy: 0.9660 - val_loss: 158.8811 - val_re_lu_65_loss: 38.4709 - val_re_lu_121_loss: 39.1772 - val_re_lu_177_loss: 40.1727 - val_re_lu_233_loss: 41.0603 - val_re_lu_65_accuracy: 0.8180 - val_re_lu_121_accuracy: 0.7718 - val_re_lu_177_accuracy: 0.8025 - val_re_lu_233_accuracy: 0.9155\n",
      "Learning rate:  0.0005\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.3922 - re_lu_65_loss: 6.3456 - re_lu_121_loss: 2.6034 - re_lu_177_loss: 1.4357 - re_lu_233_loss: 1.0075 - re_lu_65_accuracy: 0.8328 - re_lu_121_accuracy: 0.8821 - re_lu_177_accuracy: 0.9405 - re_lu_233_accuracy: 0.9628   ETA:  - ETA: 2:37 - loss: 11.8184 - re_lu_65_loss: 6.6104 - re_lu_121_loss: 2.6923 - re_lu_177_loss: 1.47 - ETA: 2:25 - loss: 11.4043 - re_lu_65_loss: 6.4292 - re_lu_121_loss: 2.5865 - re_lu_177_loss: 1.4051 - re - ETA: 32s \n",
      "Epoch 00079: loss improved from 11.50220 to 11.39223, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 11.3922 - re_lu_65_loss: 6.3456 - re_lu_121_loss: 2.6034 - re_lu_177_loss: 1.4357 - re_lu_233_loss: 1.0075 - re_lu_65_accuracy: 0.8328 - re_lu_121_accuracy: 0.8821 - re_lu_177_accuracy: 0.9405 - re_lu_233_accuracy: 0.9628 - val_loss: 158.8553 - val_re_lu_65_loss: 38.7622 - val_re_lu_121_loss: 39.2482 - val_re_lu_177_loss: 40.1597 - val_re_lu_233_loss: 40.6852 - val_re_lu_65_accuracy: 0.7967 - val_re_lu_121_accuracy: 0.7736 - val_re_lu_177_accuracy: 0.8247 - val_re_lu_233_accuracy: 0.9082\n",
      "Learning rate:  0.0005\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.1489 - re_lu_65_loss: 6.2586 - re_lu_121_loss: 2.5406 - re_lu_177_loss: 1.3817 - re_lu_233_loss: 0.9680 - re_lu_65_accuracy: 0.8283 - re_lu_121_accuracy: 0.8842 - re_lu_177_accuracy: 0.9449 - re_lu_233_accuracy: 0.9653   ETA: 1:18 - loss: 11.2354 - re_lu_65_loss: 6.3542 - re_lu_121_loss: 2.5663 - re_lu_177_loss: 1.3754 - re_lu_233_loss: 0.9394 - re_lu_65_accuracy: 0.8262 - re_lu_121_accuracy:  - ETA: 1:12 - loss: 11.2171 - re_lu_65_loss: 6.3326 - re_lu_121_loss: 2.5714 - re_lu_177_loss: 1.3715 - re_lu_233_loss: 0.9417 - re_lu_65_accuracy: 0.8261 - re_lu_121_accuracy: 0.8793 - re_lu_177_accuracy: 0.943 - ETA: 1:09 - loss: 11.1794 - re_lu_65_loss: 6.3100 - re_lu_ - ETA: 46s - loss: 11.1223 - re_lu_65_loss: 6.2607 - re_lu_121_loss: 2.5383 - re_lu_177_loss: 1.3725 - re_lu_233_loss: 0.9509 - re_lu_65_accuracy: 0.8278 - re_lu_121_accuracy: 0.8815 - re_lu_177_accuracy: 0 - ETA: 40s - loss: 11.1346 - re_lu_65_loss: 6.2663 - re_lu_121_loss: 2.5434 - re_lu_177_loss: 1.3730 - re_lu_233_loss: 0.9519 - re_lu_65_accuracy: 0.8280 - re_lu_121_accuracy: 0 - ETA: 28s - loss: 11.1210 - re_lu_65_loss: 6.2519 - re_lu_121_loss: 2.5330 - re_lu_177_loss: 1.3765 - re_lu_233_loss: 0.9597 - re_lu_65_accuracy: 0.8283 - re_lu_121_accuracy: 0.8828 - re_lu_177_ac - ETA: 20s - loss: 11.1031 - re_lu_65_loss: 6.2307 - re_lu_121_loss: 2.5348 - re_lu - ETA: 0s - loss: 11.1425 - re_lu_65_loss: 6.2538 - re_lu_121_loss: 2.5394 - re_lu_177_loss: 1.3815 - re_lu_233_loss: 0.9678 - re_lu_65_accuracy: 0.8284 - re_lu_121_accuracy: 0.8844 - re_lu_177_accuracy: 0.9450 - re_lu_233_accura\n",
      "Epoch 00080: loss improved from 11.39223 to 11.14890, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 11.1489 - re_lu_65_loss: 6.2586 - re_lu_121_loss: 2.5406 - re_lu_177_loss: 1.3817 - re_lu_233_loss: 0.9680 - re_lu_65_accuracy: 0.8283 - re_lu_121_accuracy: 0.8842 - re_lu_177_accuracy: 0.9449 - re_lu_233_accuracy: 0.9653 - val_loss: 157.8399 - val_re_lu_65_loss: 38.4476 - val_re_lu_121_loss: 38.9323 - val_re_lu_177_loss: 39.6757 - val_re_lu_233_loss: 40.7844 - val_re_lu_65_accuracy: 0.8113 - val_re_lu_121_accuracy: 0.7775 - val_re_lu_177_accuracy: 0.8259 - val_re_lu_233_accuracy: 0.9131\n",
      "Learning rate:  0.0005\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.0519 - re_lu_65_loss: 6.1890 - re_lu_121_loss: 2.5189 - re_lu_177_loss: 1.3739 - re_lu_233_loss: 0.9701 - re_lu_65_accuracy: 0.8333 - re_lu_121_accuracy: 0.8817 - re_lu_177_accuracy: 0.9440 - re_lu_233_accuracy: 0.9655   ETA: 1:17 - loss: 10.7149 - re_lu_65_loss: 6.0241 - re_lu_121_loss: 2.4109 - re_lu_177_loss: 1.3323 - re_lu_233_loss: 0.9477 - re_lu_65_accuracy: 0.8405 - re_lu_121_accuracy: 0. - ETA: 1:12 - loss: 10.6940 - re_lu_65_loss: 6.0317 - re_lu_121_loss: 2.4027  - ETA: 54s - loss: 10.6883 - re_lu_65_loss: 6.0200 - re_ - ETA: 20s - loss: 10.9322 - re_lu_65_loss: 6.1227 - re_lu_121_loss: 2.488\n",
      "Epoch 00081: loss improved from 11.14890 to 11.05188, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 11.0519 - re_lu_65_loss: 6.1890 - re_lu_121_loss: 2.5189 - re_lu_177_loss: 1.3739 - re_lu_233_loss: 0.9701 - re_lu_65_accuracy: 0.8333 - re_lu_121_accuracy: 0.8817 - re_lu_177_accuracy: 0.9440 - re_lu_233_accuracy: 0.9655 - val_loss: 158.5468 - val_re_lu_65_loss: 38.6695 - val_re_lu_121_loss: 39.0834 - val_re_lu_177_loss: 40.0891 - val_re_lu_233_loss: 40.7048 - val_re_lu_65_accuracy: 0.7916 - val_re_lu_121_accuracy: 0.6917 - val_re_lu_177_accuracy: 0.8293 - val_re_lu_233_accuracy: 0.9098\n",
      "Learning rate:  5e-05\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.7863 - re_lu_65_loss: 5.6316 - re_lu_121_loss: 2.2322 - re_lu_177_loss: 1.1458 - re_lu_233_loss: 0.7768 - re_lu_65_accuracy: 0.8510 - re_lu_121_accuracy: 0.8939 - re_lu_177_accuracy: 0.9549 - re_lu_233_accuracy: 0.9739- ETA: 5s - loss: 9.8245 - re_lu_65_loss: 5.6556 - re_lu_121_loss: 2.2418 - re_lu_177_loss: 1.1477 - re_lu_233_loss: 0.7795 - re_lu_65_accuracy: 0.8501 - re_lu_121_accuracy: 0.8932 - re_lu_177_accuracy: 0.9548\n",
      "Epoch 00082: loss improved from 11.05188 to 9.78632, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 9.7863 - re_lu_65_loss: 5.6316 - re_lu_121_loss: 2.2322 - re_lu_177_loss: 1.1458 - re_lu_233_loss: 0.7768 - re_lu_65_accuracy: 0.8510 - re_lu_121_accuracy: 0.8939 - re_lu_177_accuracy: 0.9549 - re_lu_233_accuracy: 0.9739 - val_loss: 155.5097 - val_re_lu_65_loss: 37.9053 - val_re_lu_121_loss: 38.3544 - val_re_lu_177_loss: 39.2664 - val_re_lu_233_loss: 39.9835 - val_re_lu_65_accuracy: 0.8328 - val_re_lu_121_accuracy: 0.7586 - val_re_lu_177_accuracy: 0.8229 - val_re_lu_233_accuracy: 0.9183\n",
      "Learning rate:  5e-05\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.7745 - re_lu_65_loss: 5.2281 - re_lu_121_loss: 2.0002 - re_lu_177_loss: 0.9486 - re_lu_233_loss: 0.5976 - re_lu_65_accuracy: 0.8572 - re_lu_121_accuracy: 0.8977 - re_lu_177_accuracy: 0.9562 - re_lu_233_accuracy: 0.9733  - ETA: 1:39 - loss: 8.8233 - re_lu_65_loss: 5.2996 - re_lu_121_ - ETA: 41s - loss: 8.7332 - re_lu_65_loss: 5.2214 - re_lu_121_loss: 1.9808 - re_lu_177_loss: 0.9368 - re_lu_233_loss: 0.5943 -  - ETA: 9s - loss: 8.7903 - re_lu_65_loss: 5.2394 - re_lu_121_loss: 2.0072 - re_lu_177_loss: 0.9473 - re_lu_233_loss: 0.5963 - re_lu_65_accuracy: 0.8573 - re_lu_121_accuracy: 0.8979 - re_\n",
      "Epoch 00083: loss improved from 9.78632 to 8.77446, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 8.7745 - re_lu_65_loss: 5.2281 - re_lu_121_loss: 2.0002 - re_lu_177_loss: 0.9486 - re_lu_233_loss: 0.5976 - re_lu_65_accuracy: 0.8572 - re_lu_121_accuracy: 0.8977 - re_lu_177_accuracy: 0.9562 - re_lu_233_accuracy: 0.9733 - val_loss: 155.1609 - val_re_lu_65_loss: 37.8325 - val_re_lu_121_loss: 38.2605 - val_re_lu_177_loss: 39.1575 - val_re_lu_233_loss: 39.9104 - val_re_lu_65_accuracy: 0.8323 - val_re_lu_121_accuracy: 0.7399 - val_re_lu_177_accuracy: 0.8095 - val_re_lu_233_accuracy: 0.9150\n",
      "Learning rate:  5e-05\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.2160 - re_lu_65_loss: 5.0049 - re_lu_121_loss: 1.8699 - re_lu_177_loss: 0.8392 - re_lu_233_loss: 0.5020 - re_lu_65_accuracy: 0.8580 - re_lu_121_accuracy: 0.8974 - re_lu_177_accuracy: 0.9549 - re_lu_233_accuracy: 0.9713\n",
      "Epoch 00084: loss improved from 8.77446 to 8.21596, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 8.2160 - re_lu_65_loss: 5.0049 - re_lu_121_loss: 1.8699 - re_lu_177_loss: 0.8392 - re_lu_233_loss: 0.5020 - re_lu_65_accuracy: 0.8580 - re_lu_121_accuracy: 0.8974 - re_lu_177_accuracy: 0.9549 - re_lu_233_accuracy: 0.9713 - val_loss: 155.1281 - val_re_lu_65_loss: 37.8588 - val_re_lu_121_loss: 38.2709 - val_re_lu_177_loss: 39.1277 - val_re_lu_233_loss: 39.8706 - val_re_lu_65_accuracy: 0.8299 - val_re_lu_121_accuracy: 0.7319 - val_re_lu_177_accuracy: 0.8045 - val_re_lu_233_accuracy: 0.9121\n",
      "Learning rate:  5e-05\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.8720 - re_lu_65_loss: 4.8609 - re_lu_121_loss: 1.7885 - re_lu_177_loss: 0.7743 - re_lu_233_loss: 0.4484 - re_lu_65_accuracy: 0.8596 - re_lu_121_accuracy: 0.8982 - re_lu_177_accuracy: 0.9547 - re_lu_233_accuracy: 0.9709  - ETA: 2:26 - loss: 8.2053 - re_lu_65_loss: 5.0727 - re_lu_121_loss: 1.8994 - re_lu_177_loss: 0.7933 - re_lu_233_loss: 0.4400 - re_lu_65_accuracy:  - ETA: 2:10 - loss: 8.0273 - re_lu_65_loss: 4.937 - ETA: 1:35 - loss: 7.9267 - re_lu_65_loss: 4.9141 - re_lu_121_loss: 1.7931 - re_lu_177_loss: 0.7692 - re_lu_233_ - ETA: 1:12 - loss: 7.956 - ETA: 24s - loss: 7.9113 - re_lu_65_loss: 4.8942 - re_lu_121_loss: 1.7986 - re_lu_177_loss: 0.7695 - re_lu_233_loss: 0.4489 - re_lu_65_accuracy: 0.8588 -  - ETA: 17s - loss: 7.9338 - re_lu_65_loss: 4.8980 - re_lu_121_loss: 1.8028 - re_lu_177_loss: 0.7792 - re_lu_233_loss: 0.4538 - re_lu_65_accuracy: 0.859 - ETA: 8s - loss: 7.8816 - re_lu_65_loss: 4.8684 - re_lu_121_loss: 1.7948 - re_lu_177_loss: 0.7711 - re_lu_233_loss: 0.4473 - re_lu_65_accuracy: 0.8592 - re_lu_121_accuracy: 0.8978 - re_lu_177_accuracy: 0.9 - ETA: 2s - loss: 7.8656 - re_lu_65_loss: 4.8590 - re_lu_121_loss: 1.7881 - re_lu_177_loss: 0.7719 - re_lu_233_loss: 0.4467 - re_lu_65_accuracy: 0.8598 - re_lu_121_accuracy: 0.8983 - re_lu_177_accuracy: 0.9548 - re_lu_233_accu\n",
      "Epoch 00085: loss improved from 8.21596 to 7.87204, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 7.8720 - re_lu_65_loss: 4.8609 - re_lu_121_loss: 1.7885 - re_lu_177_loss: 0.7743 - re_lu_233_loss: 0.4484 - re_lu_65_accuracy: 0.8596 - re_lu_121_accuracy: 0.8982 - re_lu_177_accuracy: 0.9547 - re_lu_233_accuracy: 0.9709 - val_loss: 155.2632 - val_re_lu_65_loss: 37.8800 - val_re_lu_121_loss: 38.2648 - val_re_lu_177_loss: 39.1720 - val_re_lu_233_loss: 39.9465 - val_re_lu_65_accuracy: 0.8350 - val_re_lu_121_accuracy: 0.7239 - val_re_lu_177_accuracy: 0.7978 - val_re_lu_233_accuracy: 0.9098\n",
      "Learning rate:  5e-05\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.6109 - re_lu_65_loss: 4.7473 - re_lu_121_loss: 1.7285 - re_lu_177_loss: 0.7258 - re_lu_233_loss: 0.4092 - re_lu_65_accuracy: 0.8597 - re_lu_121_accuracy: 0.8959 - re_lu_177_accuracy: 0.9524 - re_lu_233_accuracy: 0.9695  - - ETA: 18s - loss: 7.5932 - re_lu_65_loss: 4.7265 - re_lu_121_loss: 1.7336 - re_lu_177_loss: \n",
      "Epoch 00086: loss improved from 7.87204 to 7.61086, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 7.6109 - re_lu_65_loss: 4.7473 - re_lu_121_loss: 1.7285 - re_lu_177_loss: 0.7258 - re_lu_233_loss: 0.4092 - re_lu_65_accuracy: 0.8597 - re_lu_121_accuracy: 0.8959 - re_lu_177_accuracy: 0.9524 - re_lu_233_accuracy: 0.9695 - val_loss: 155.0992 - val_re_lu_65_loss: 37.8612 - val_re_lu_121_loss: 38.2381 - val_re_lu_177_loss: 39.1319 - val_re_lu_233_loss: 39.8680 - val_re_lu_65_accuracy: 0.8282 - val_re_lu_121_accuracy: 0.7293 - val_re_lu_177_accuracy: 0.8034 - val_re_lu_233_accuracy: 0.9097\n",
      "Learning rate:  5e-05\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.4433 - re_lu_65_loss: 4.6674 - re_lu_121_loss: 1.6889 - re_lu_177_loss: 0.6986 - re_lu_233_loss: 0.3884 - re_lu_65_accuracy: 0.8593 - re_lu_121_accuracy: 0.8938 - re_lu_177_accuracy: 0.9516 - re_lu_233_accuracy: 0.9702  - ETA: 2:52 - loss: 7.6158 - re_lu_65_loss: 4.5577 - re_lu_121_loss: 1.7306 - re_lu_177_loss: 0.8493 - re_lu_233_loss: 0.4782 - re_lu_65_accuracy: 0.8643 - re_lu_121_accuracy: 0.9001 - re_lu_177_ac - ETA: 2:46 - loss: 7.3767 - re_lu_65_loss: 4.4819 - re_lu_121_loss: 1.7514 - re_lu_1 - ETA: 2:18 - loss: 7.4131 - re_lu_65_loss: 4.5613 - re_lu_121_loss: 1.7736 - re_lu_177_loss: 0.7052 - re_lu_233_loss: 0.3730 - re_lu_65_accuracy: 0.8614 - re_lu_121_accuracy: 0.8930 - re_lu_177_accuracy: 0.9516 - re - ETA: 2:14 - loss: 7.3808 - re_lu_65_loss: 4.5584 - re_lu_121_loss: 1.7 - ETA: 1:43 - loss: 7.5665 - re_lu_65_loss: 4.7018 - re_lu_121_loss: 1.7765 - re_lu_177_loss: 0.7131 - re_lu_233_loss: 0.3751 - re_lu_65_accuracy: 0.8576 - re_lu_121_accuracy: 0.8902 - re_lu_177_ac - ETA: 1:35 - loss: 7.5816 - re_l - ETA: 14s - loss: 7.4714 - re_lu_65_loss: 4.6741 - re_lu_121_loss: 1.7046 - re_lu_177_loss: 0.7044 - re_lu_233_loss: 0.3883 - re_lu_65_accuracy: 0.85 - ETA: 3s - loss: 7.4653 - re_lu_65_loss: 4.6796 - re_lu_121_loss: 1.6969 - re_lu_177_loss: 0.7000 - re_lu_233_loss: 0.3887 - re_lu_65_accuracy: 0.8592 - re_lu_121_accuracy: 0.8935 - re_lu_177_accuracy: 0.9515 - re_lu_233\n",
      "Epoch 00087: loss improved from 7.61086 to 7.44332, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 7.4433 - re_lu_65_loss: 4.6674 - re_lu_121_loss: 1.6889 - re_lu_177_loss: 0.6986 - re_lu_233_loss: 0.3884 - re_lu_65_accuracy: 0.8593 - re_lu_121_accuracy: 0.8938 - re_lu_177_accuracy: 0.9516 - re_lu_233_accuracy: 0.9702 - val_loss: 155.1777 - val_re_lu_65_loss: 37.8410 - val_re_lu_121_loss: 38.2574 - val_re_lu_177_loss: 39.1834 - val_re_lu_233_loss: 39.8959 - val_re_lu_65_accuracy: 0.8311 - val_re_lu_121_accuracy: 0.7212 - val_re_lu_177_accuracy: 0.7936 - val_re_lu_233_accuracy: 0.9078\n",
      "Learning rate:  5e-05\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.2915 - re_lu_65_loss: 4.5948 - re_lu_121_loss: 1.6534 - re_lu_177_loss: 0.6735 - re_lu_233_loss: 0.3699 - re_lu_65_accuracy: 0.8612 - re_lu_121_accuracy: 0.8948 - re_lu_177_accuracy: 0.9529 - re_lu_233_accuracy: 0.9716  ETA: 32s - loss: 7.2529 - re_lu_65_loss: 4.5831 - re_lu_121_loss: 1.6413 - re_lu_177_loss: 0.6687 - re_lu_233_loss: 0.3598 - re_lu_65_accuracy: 0.8619 - re_lu_121_accuracy: 0.\n",
      "Epoch 00088: loss improved from 7.44332 to 7.29154, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 7.2915 - re_lu_65_loss: 4.5948 - re_lu_121_loss: 1.6534 - re_lu_177_loss: 0.6735 - re_lu_233_loss: 0.3699 - re_lu_65_accuracy: 0.8612 - re_lu_121_accuracy: 0.8948 - re_lu_177_accuracy: 0.9529 - re_lu_233_accuracy: 0.9716 - val_loss: 155.1249 - val_re_lu_65_loss: 37.8566 - val_re_lu_121_loss: 38.2554 - val_re_lu_177_loss: 39.1477 - val_re_lu_233_loss: 39.8651 - val_re_lu_65_accuracy: 0.8313 - val_re_lu_121_accuracy: 0.7205 - val_re_lu_177_accuracy: 0.8002 - val_re_lu_233_accuracy: 0.9061\n",
      "Learning rate:  5e-05\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.1964 - re_lu_65_loss: 4.5419 - re_lu_121_loss: 1.6311 - re_lu_177_loss: 0.6603 - re_lu_233_loss: 0.3632 - re_lu_65_accuracy: 0.8603 - re_lu_121_accuracy: 0.8923 - re_lu_177_accuracy: 0.9513 - re_lu_233_accuracy: 0.9702  - ETA: 2:50 - loss: 6.8522 - re_lu_65_loss: 4.4705 - re_lu_121_loss: 1.4516 - re_lu_177_loss: 0.5791 - re_lu_233_loss: 0.3511 - re_lu_65_accuracy: 0.8646 - re_lu_121_accu - ETA: 2:41 - loss: 7.1919 -  - ETA: 26s - loss: 7.2278 - re_lu_65_loss: 4.5475 - re_lu_121_loss: 1.6401 - re_lu_177_loss: 0.6680 - re_lu_233_loss: 0.3722 - re_lu_65_accuracy: 0.8605 - re_lu_121_accuracy: 0.8922 - re_lu_177_accuracy: 0.951 - ETA: 23s - loss: 7.2524 - re_lu_65_loss: 4.5650 - re_lu_121_loss: 1.6484 - re_lu_177_loss: 0.6682 - re_lu_233_loss: 0.3708 - re_lu_65_accuracy: 0.8603 - re_lu_121_accuracy: 0.8920 - re_lu_177_accuracy: 0.9510 - re_lu_233_accu - ETA: 22s - loss: 7.2632 - re_lu_65_loss: 4.5717 - r - ETA: 1s - loss: 7.2051 - re_lu_65_loss: 4.5467 - re_lu_121_loss: 1.6334 - re_lu_177_loss: 0.6614 - re_lu_233_loss: 0.3636 - re_lu_65_accuracy: 0.8603 - re_lu_121_accuracy: 0.8924 - re_lu_177_accuracy: 0.9514 - re_lu_233_accuracy: 0.9 - ETA: 0s - loss: 7.1949 - re_lu_65_loss: 4.5420 - re_lu_121_loss: 1.6297 - re_lu_177_loss: 0.6601 - re_lu_233_loss: 0.3631 - re_lu_65_accuracy: 0.8604 - re_lu_121_accuracy: 0.8925 - re_lu_177_accuracy: 0.9514 - re_lu_233_accuracy: 0.9\n",
      "Epoch 00089: loss improved from 7.29154 to 7.19645, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 7.1964 - re_lu_65_loss: 4.5419 - re_lu_121_loss: 1.6311 - re_lu_177_loss: 0.6603 - re_lu_233_loss: 0.3632 - re_lu_65_accuracy: 0.8603 - re_lu_121_accuracy: 0.8923 - re_lu_177_accuracy: 0.9513 - re_lu_233_accuracy: 0.9702 - val_loss: 155.1046 - val_re_lu_65_loss: 37.8311 - val_re_lu_121_loss: 38.2541 - val_re_lu_177_loss: 39.1502 - val_re_lu_233_loss: 39.8693 - val_re_lu_65_accuracy: 0.8287 - val_re_lu_121_accuracy: 0.7205 - val_re_lu_177_accuracy: 0.7914 - val_re_lu_233_accuracy: 0.9067\n",
      "Learning rate:  5e-05\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.0979 - re_lu_65_loss: 4.4953 - re_lu_121_loss: 1.6077 - re_lu_177_loss: 0.6429 - re_lu_233_loss: 0.3520 - re_lu_65_accuracy: 0.8616 - re_lu_121_accuracy: 0.8929 - re_lu_177_accuracy: 0.9530 - re_lu_233_accuracy: 0.9688  - ETA: 2:48 - loss: 6.7464 - re_lu_65_loss: 4.3151 - re_lu_121_loss: 1.4731 - re_lu_177_loss: 0.6235 - re_lu_23 - ETA: 2:26 - loss: 6.4861 - re_lu_65_loss: 4.1425 - re_lu_121_loss: 1.4503 - re_lu_177_loss: 0.5768 - re_lu_233_loss: 0.3165 - re_lu_65_accuracy: 0.8640 - re_lu_121_accuracy: 0.8972 - re_lu_177_accuracy: 0.9542 - re_lu_233_accuracy:  - ETA: 2:25 - loss: 6.4544 - re_lu_65_loss: 4.1209 - re_lu_121_loss: 1.4360 - re_lu_177_ - ETA: 1:14 - loss: 6.8903 - re_ - ETA: 26s - loss: 7.0856 - re_lu_65_loss: 4.4837 - re_lu_121_loss: 1.6078 - re_lu_177_loss: 0.6402 - re_lu_233_loss: - ETA: 15s - loss: 7.0893 - re_lu_65_loss: 4.4839 - re_lu_121_loss: 1.6074 - re_lu_177_loss: 0.6442 - re_lu_233_loss: 0.3537 - \n",
      "Epoch 00090: loss improved from 7.19645 to 7.09787, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 7.0979 - re_lu_65_loss: 4.4953 - re_lu_121_loss: 1.6077 - re_lu_177_loss: 0.6429 - re_lu_233_loss: 0.3520 - re_lu_65_accuracy: 0.8616 - re_lu_121_accuracy: 0.8929 - re_lu_177_accuracy: 0.9530 - re_lu_233_accuracy: 0.9688 - val_loss: 155.3983 - val_re_lu_65_loss: 37.8614 - val_re_lu_121_loss: 38.3030 - val_re_lu_177_loss: 39.2593 - val_re_lu_233_loss: 39.9745 - val_re_lu_65_accuracy: 0.8347 - val_re_lu_121_accuracy: 0.7244 - val_re_lu_177_accuracy: 0.7934 - val_re_lu_233_accuracy: 0.9051\n",
      "Learning rate:  5e-05\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.0156 - re_lu_65_loss: 4.4545 - re_lu_121_loss: 1.5848 - re_lu_177_loss: 0.6312 - re_lu_233_loss: 0.3451 - re_lu_65_accuracy: 0.8614 - re_lu_121_accuracy: 0.8930 - re_lu_177_accuracy: 0.9531 - re_lu_233_accuracy: 0.9696  - ETA: 2:49 - loss: 6.1911 - re_lu_65_loss: 4.1896 - re_lu_121_loss: 1.3113 - re_lu_177_loss: 0.4906 - re_lu_233_loss: 0.1997 - re_lu_65_accuracy: 0.8539 - re_lu_121_accuracy: 0.8822 - re_lu_177_accuracy: 0.9503 - re_lu_233_accuracy: 0.9 - ETA: 2:50 - loss: 7.5807  - ETA: 11s - loss: 7.0029 - re_lu_65_loss: 4.4547 - re_lu_121_loss: 1.5814 - re_lu_177_loss: 0.6255 - re_lu_233_loss: 0.3413 - re_lu_65_accuracy: 0.8609 - re_lu_12\n",
      "Epoch 00091: loss improved from 7.09787 to 7.01556, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 7.0156 - re_lu_65_loss: 4.4545 - re_lu_121_loss: 1.5848 - re_lu_177_loss: 0.6312 - re_lu_233_loss: 0.3451 - re_lu_65_accuracy: 0.8614 - re_lu_121_accuracy: 0.8930 - re_lu_177_accuracy: 0.9531 - re_lu_233_accuracy: 0.9696 - val_loss: 155.2298 - val_re_lu_65_loss: 37.8504 - val_re_lu_121_loss: 38.2388 - val_re_lu_177_loss: 39.1971 - val_re_lu_233_loss: 39.9435 - val_re_lu_65_accuracy: 0.8342 - val_re_lu_121_accuracy: 0.7251 - val_re_lu_177_accuracy: 0.7951 - val_re_lu_233_accuracy: 0.9018\n",
      "Learning rate:  5e-05\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.9356 - re_lu_65_loss: 4.4104 - re_lu_121_loss: 1.5675 - re_lu_177_loss: 0.6183 - re_lu_233_loss: 0.3392 - re_lu_65_accuracy: 0.8617 - re_lu_121_accuracy: 0.8918 - re_lu_177_accuracy: 0.9532 - re_lu_233_accuracy: 0.9684  - ETA: 2:41 - loss: 8.0881 - re_lu_65_loss: 5.1045 - re_lu_121_loss: 1.8750 - re_lu_177_loss: 0.7413 - re_lu_233_loss: 0.3673 - re_lu_65_accuracy: 0.8504 - re_lu_121_accuracy: 0.880 - ETA: 2:31 - loss: 7.5257 - re_lu_65_loss: 4.7801 - re_lu_121_loss: 1.7398 - re_lu_177_ - ETA: 2:04 - loss: 7.1826 - re_lu_65_loss: 4.5822  - ETA: 8s - loss: 6.8963 - re_lu_65_loss: 4.3872 - re_lu_121_loss: 1.5587 - re_lu_177_loss: 0.6142 - re_lu_233_loss: 0.3362 - re_lu_65_accuracy: 0.8620 - re_lu_121_accuracy: 0.8922 - re_lu_177\n",
      "Epoch 00092: loss improved from 7.01556 to 6.93558, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.9356 - re_lu_65_loss: 4.4104 - re_lu_121_loss: 1.5675 - re_lu_177_loss: 0.6183 - re_lu_233_loss: 0.3392 - re_lu_65_accuracy: 0.8617 - re_lu_121_accuracy: 0.8918 - re_lu_177_accuracy: 0.9532 - re_lu_233_accuracy: 0.9684 - val_loss: 155.2980 - val_re_lu_65_loss: 37.8465 - val_re_lu_121_loss: 38.2835 - val_re_lu_177_loss: 39.2270 - val_re_lu_233_loss: 39.9409 - val_re_lu_65_accuracy: 0.8345 - val_re_lu_121_accuracy: 0.7229 - val_re_lu_177_accuracy: 0.8078 - val_re_lu_233_accuracy: 0.9027\n",
      "Learning rate:  5e-05\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.8672 - re_lu_65_loss: 4.3802 - re_lu_121_loss: 1.5482 - re_lu_177_loss: 0.6062 - re_lu_233_loss: 0.3327 - re_lu_65_accuracy: 0.8616 - re_lu_121_accuracy: 0.8933 - re_lu_177_accuracy: 0.9525 - re_lu_233_accuracy: 0.9686  - ETA: 2:38 - loss: 6.2493 - re_lu_65_loss: 4.1302 - ETA: 1:21 - loss: 6.8061 - re_lu_65_loss: 4.3744 - re_lu_121_loss: 1.5062 - re_lu_177_loss: 0.6016 - re_lu_233_loss: 0.3239 - re_ - ETA: 38s - loss: 6.9565 - re_lu_65_loss: 4.4170 - re_lu_121_loss: 1.5736 - re_lu_177_loss: 0.6280 - re_lu_233_loss: 0.3379 - re_lu_65_accuracy: 0.8614 - re_lu_121_accuracy: 0.8927 - re_lu_177_accuracy: 0.9518 - re_lu_233_ac - ETA: 37s - loss: 6.9482 - re_lu_65_loss: 4.4156 - re_lu_121_los - ETA: 21s - loss: 6.9592 - re_lu_65_loss: 4.4256 - re_lu_121_loss: 1.5793 - re_lu_177_loss: 0.6174 - re_lu_233_loss: 0.3369 - re_lu_65_accuracy: 0.8609 - re_lu_121_accuracy: 0.8921 - re_lu_177_accuracy: 0.9520 - re_lu_233_ac - ETA: 20s - loss: 6.9487 - re_lu_65_loss: 4.4273 - re_lu_121_loss: 1.5\n",
      "Epoch 00093: loss improved from 6.93558 to 6.86717, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.8672 - re_lu_65_loss: 4.3802 - re_lu_121_loss: 1.5482 - re_lu_177_loss: 0.6062 - re_lu_233_loss: 0.3327 - re_lu_65_accuracy: 0.8616 - re_lu_121_accuracy: 0.8933 - re_lu_177_accuracy: 0.9525 - re_lu_233_accuracy: 0.9686 - val_loss: 155.1762 - val_re_lu_65_loss: 37.8133 - val_re_lu_121_loss: 38.2521 - val_re_lu_177_loss: 39.2037 - val_re_lu_233_loss: 39.9069 - val_re_lu_65_accuracy: 0.8293 - val_re_lu_121_accuracy: 0.7365 - val_re_lu_177_accuracy: 0.8056 - val_re_lu_233_accuracy: 0.9021\n",
      "Learning rate:  5e-05\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.8125 - re_lu_65_loss: 4.3482 - re_lu_121_loss: 1.5359 - re_lu_177_loss: 0.5993 - re_lu_233_loss: 0.3291 - re_lu_65_accuracy: 0.8628 - re_lu_121_accuracy: 0.8940 - re_lu_177_accuracy: 0.9533 - re_lu_233_accuracy: 0.9687  - ETA: 2:45 - loss: 5.9833 - re_lu_65_loss: 3.8292 - re_lu_121_loss: 1.3594 - re_lu_177_loss: 0.5153 - re_lu - ETA: 2:22 - loss: 6.4505 - re_lu_65_loss: 4.1073 - re_lu_121_loss: 1.4844 - re_lu_177_loss: 0.5709 - re_lu_233_loss: 0 - ETA: 2:00 - loss: 6.7268 - re_lu_65_loss: 4.3006 - re_lu_121_loss: 1.5433 - re_lu_177_loss: 0.5795 - re_lu_233_loss: 0.3035 - re_lu_65_accuracy: 0.8623 - re_lu_121_accuracy: 0.8923 - re_lu_177_accuracy: 0.9526 - re_lu_233_accuracy - ETA: 1:58 - loss: 6.8079 - re_lu_65_loss: 4.3472 - re_lu_121_loss: 1.5727 - re_lu_177_loss: 0.5850 - re_lu_233_loss: 0.3030 - re_lu_65_accuracy: 0.8613 - re_lu_121_accuracy: 0.8913 - re_lu_177_accuracy:  - ETA: 1:52 - loss: 6.7848 - re_lu_65_loss: 4.3414 - re_lu_121_loss: 1.5472 - re_lu_177_loss: 0.5872 - re_lu_233_loss: 0.3090 - re_lu_65_accuracy: 0.8617 - re_lu_121_accuracy: 0.8922 - re_lu_177_accuracy: 0.9524 - re_lu_233_accuracy - ETA: 1:51 - loss - ETA: 43s - loss: 6.7498 - re_lu_65_loss: 4.3123 - re_lu_121_l\n",
      "Epoch 00094: loss improved from 6.86717 to 6.81252, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.8125 - re_lu_65_loss: 4.3482 - re_lu_121_loss: 1.5359 - re_lu_177_loss: 0.5993 - re_lu_233_loss: 0.3291 - re_lu_65_accuracy: 0.8628 - re_lu_121_accuracy: 0.8940 - re_lu_177_accuracy: 0.9533 - re_lu_233_accuracy: 0.9687 - val_loss: 155.1676 - val_re_lu_65_loss: 37.8219 - val_re_lu_121_loss: 38.2585 - val_re_lu_177_loss: 39.1848 - val_re_lu_233_loss: 39.9024 - val_re_lu_65_accuracy: 0.8294 - val_re_lu_121_accuracy: 0.7229 - val_re_lu_177_accuracy: 0.8059 - val_re_lu_233_accuracy: 0.9025\n",
      "Learning rate:  5e-05\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.7535 - re_lu_65_loss: 4.3191 - re_lu_121_loss: 1.5197 - re_lu_177_loss: 0.5903 - re_lu_233_loss: 0.3244 - re_lu_65_accuracy: 0.8623 - re_lu_121_accuracy: 0.8952 - re_lu_177_accuracy: 0.9540 - re_lu_233_accuracy: 0.9699  - ETA: 2:50 - loss: 6.1062 - re_lu_65_loss: 3.9195 - re_lu_121_loss: 1.4208 - re_lu_177_loss: 0.5027 - re_lu_233_loss: 0.263 - ETA: 1:49 - loss: 6.7021 - re_lu_65_loss: 4.2484 - re_lu_121_loss: 1.5197 - re_lu_177_loss: 0.5909 - re_lu_233_loss: 0.3430 - re_lu_65_accuracy: 0.8657 - re_lu_121_accuracy: 0.8970 - re_lu_177_accuracy: 0.9548 - re_lu_233_accuracy: 0.9 - ETA: 1:48 - loss: 6.6970 - re_lu_65_loss: 4.2513 - re_lu_121_loss: 1.5156 - re_lu_177_loss: 0.5883 - re_lu_233_loss: 0.34 - ETA: 1:27 - loss: 6.8168 - re_lu_65_loss: 4.3391 - re_lu_121_loss: 1.5512 - re_lu_177_loss: 0.5977 - re_lu_ - ETA: 39s - loss: 6.8199 - re_lu_65_loss: 4.3647 - re_lu_121_loss: 1.5403 - re_lu_177_loss: 0.5933 - re_lu_233_loss: 0.3215 - re_lu_65_accuracy: 0.8616 - re_lu_ - ETA: 32s - loss: 6.8825 - re_lu_65_lo - ETA: 14s - loss: 6.8238 - re_lu_65_loss: 4.3530 - re_lu_121_loss: 1.5437 - re_lu_177_loss: 0.5979 - re_lu_233_loss: 0.3292 - re_lu_65_accuracy: 0.8616 - - ETA: 3s - loss: 6.7560 - re_lu_65_loss: 4.3239 - re_lu_121_loss: 1.5187 - re_lu_177_loss: 0.5895 - re_lu_233_loss: 0.3239 - re_lu_65_accuracy: 0.8623 - re_lu_121_accuracy: 0.8954 - re_lu_177_accuracy: 0.9543 - re_lu_2\n",
      "Epoch 00095: loss improved from 6.81252 to 6.75350, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.7535 - re_lu_65_loss: 4.3191 - re_lu_121_loss: 1.5197 - re_lu_177_loss: 0.5903 - re_lu_233_loss: 0.3244 - re_lu_65_accuracy: 0.8623 - re_lu_121_accuracy: 0.8952 - re_lu_177_accuracy: 0.9540 - re_lu_233_accuracy: 0.9699 - val_loss: 155.3130 - val_re_lu_65_loss: 37.8367 - val_re_lu_121_loss: 38.2704 - val_re_lu_177_loss: 39.2503 - val_re_lu_233_loss: 39.9555 - val_re_lu_65_accuracy: 0.8365 - val_re_lu_121_accuracy: 0.7308 - val_re_lu_177_accuracy: 0.8095 - val_re_lu_233_accuracy: 0.9037\n",
      "Learning rate:  5e-05\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.6887 - re_lu_65_loss: 4.2848 - re_lu_121_loss: 1.5046 - re_lu_177_loss: 0.5800 - re_lu_233_loss: 0.3192 - re_lu_65_accuracy: 0.8634 - re_lu_121_accuracy: 0.8935 - re_lu_177_accuracy: 0.9528 - re_lu_233_accuracy: 0.9675  - ETA: 2:41 - loss: 6.5437 - re_lu_65_loss: 3.8832 - re_lu_121_loss: 1.4535 - re_lu_177_loss: 0.7424 - re_lu_233_loss: 0.4645 - re_lu_65_accuracy: 0.8588 - - ETA: 2:44 - loss: 6.2351 - re_lu_65_loss: 4.0908 - re_lu_121_loss: 1.3644 - re_lu_177_loss: 0.4969 - re_lu_233_loss: 0.2830 - re_lu_65_accuracy: 0.8 - ETA: 2 - ETA: 1:46 - loss: 6.4866 - re_lu_65_loss: 4 - ETA: 21s - loss: 6.7495 - re_lu_65_loss: 4.3307 - re_lu\n",
      "Epoch 00096: loss improved from 6.75350 to 6.68868, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.6887 - re_lu_65_loss: 4.2848 - re_lu_121_loss: 1.5046 - re_lu_177_loss: 0.5800 - re_lu_233_loss: 0.3192 - re_lu_65_accuracy: 0.8634 - re_lu_121_accuracy: 0.8935 - re_lu_177_accuracy: 0.9528 - re_lu_233_accuracy: 0.9675 - val_loss: 155.5191 - val_re_lu_65_loss: 37.8300 - val_re_lu_121_loss: 38.3101 - val_re_lu_177_loss: 39.3192 - val_re_lu_233_loss: 40.0597 - val_re_lu_65_accuracy: 0.8307 - val_re_lu_121_accuracy: 0.7176 - val_re_lu_177_accuracy: 0.8041 - val_re_lu_233_accuracy: 0.9021\n",
      "Learning rate:  5e-05\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.6480 - re_lu_65_loss: 4.2652 - re_lu_121_loss: 1.4909 - re_lu_177_loss: 0.5747 - re_lu_233_loss: 0.3172 - re_lu_65_accuracy: 0.8631 - re_lu_121_accuracy: 0.8924 - re_lu_177_accuracy: 0.9523 - re_lu_233_accuracy: 0.9691\n",
      "Epoch 00097: loss improved from 6.68868 to 6.64801, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.6480 - re_lu_65_loss: 4.2652 - re_lu_121_loss: 1.4909 - re_lu_177_loss: 0.5747 - re_lu_233_loss: 0.3172 - re_lu_65_accuracy: 0.8631 - re_lu_121_accuracy: 0.8924 - re_lu_177_accuracy: 0.9523 - re_lu_233_accuracy: 0.9691 - val_loss: 155.1994 - val_re_lu_65_loss: 37.7917 - val_re_lu_121_loss: 38.2378 - val_re_lu_177_loss: 39.2221 - val_re_lu_233_loss: 39.9478 - val_re_lu_65_accuracy: 0.8352 - val_re_lu_121_accuracy: 0.7308 - val_re_lu_177_accuracy: 0.8192 - val_re_lu_233_accuracy: 0.9053\n",
      "Learning rate:  5e-05\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.5868 - re_lu_65_loss: 4.2313 - re_lu_121_loss: 1.4774 - re_lu_177_loss: 0.5657 - re_lu_233_loss: 0.3124 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8957 - re_lu_177_accuracy: 0.9542 - re_lu_233_accuracy: 0.9692  - ETA: 2:49 - loss: 6.9523 - re_lu_65_loss: 4.3452 - re_lu_121_loss: 1.6591 - re_lu_177_loss: 0.5917 - re_lu_233_loss: 0.3563 - re_lu_65_accuracy: 0.8590 - re_lu_121_accuracy: 0.8840 - re_lu_177_accuracy: 0.9500 - re_lu_2 - ETA: 2:47 - loss: 6.7437 - re_lu_65_loss: 4.2148 - re_lu_121_loss: 1.5971 - re_lu_177_loss: 0.5877 - re_lu_233_loss: 0.3441 - re_lu_65_accuracy: 0.8630 - re_lu_121_accuracy: 0.8876 - re_lu_177_accuracy: 0.9504 - re_lu_233_accurac - ETA: 2:45 - loss: 6.9206 - re_lu_65_loss: 4.2651 - re_lu_121_loss: 1.6262 - re_lu_177_loss: 0.6532 - re_lu_233_loss: 0.3760 - re_lu_65_accuracy: 0.8619 - re_lu_121_accuracy: 0.8870 - re_lu_177_accuracy: 0.9505 - ETA: 2:40 - loss: 6.3028 - re_lu_65_loss: \n",
      "Epoch 00098: loss improved from 6.64801 to 6.58681, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 6.5868 - re_lu_65_loss: 4.2313 - re_lu_121_loss: 1.4774 - re_lu_177_loss: 0.5657 - re_lu_233_loss: 0.3124 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8957 - re_lu_177_accuracy: 0.9542 - re_lu_233_accuracy: 0.9692 - val_loss: 155.4874 - val_re_lu_65_loss: 37.8603 - val_re_lu_121_loss: 38.2969 - val_re_lu_177_loss: 39.3083 - val_re_lu_233_loss: 40.0218 - val_re_lu_65_accuracy: 0.8329 - val_re_lu_121_accuracy: 0.7369 - val_re_lu_177_accuracy: 0.8214 - val_re_lu_233_accuracy: 0.9025\n",
      "Learning rate:  5e-05\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.5478 - re_lu_65_loss: 4.2121 - re_lu_121_loss: 1.4655 - re_lu_177_loss: 0.5595 - re_lu_233_loss: 0.3107 - re_lu_65_accuracy: 0.8653 - re_lu_121_accuracy: 0.8969 - re_lu_177_accuracy: 0.9547 - re_lu_233_accuracy: 0.9692  - ETA: 1:38 - loss: 6.1363 - re_lu_ - ETA: 1:00 - loss: 6.2615 - re_lu_65_loss: 4.0642 - re_lu_121_loss: 1.3802 - re_lu_177_loss: 0. - ETA: 25s - loss: 6.4815 - re_lu_65_loss: 4.1888 - re_lu_121_loss: 1.4402 - re_lu_177_loss: 0.5476 - re_lu_233_loss: 0.3048 - re_lu_65_accurac - ETA: 16s - loss: 6.5495 - re_lu_65_loss: 4.2143 - re_lu_121_loss: 1.4651 - re_lu_177_loss: 0.5603 - re_lu_233_loss: 0 - ETA: 0s - loss: 6.5404 - re_lu_65_loss: 4.2067 - re_lu_121_loss: 1.4641 - re_lu_177_loss: 0.5596 - re_lu_233_loss: 0.3101 - re_lu_65_accuracy: 0.8654 - re_lu_121_accuracy: 0.8970 - re_lu_177_accuracy: 0.9548 - re_lu_233_accuracy: 0.\n",
      "Epoch 00099: loss improved from 6.58681 to 6.54779, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.5478 - re_lu_65_loss: 4.2121 - re_lu_121_loss: 1.4655 - re_lu_177_loss: 0.5595 - re_lu_233_loss: 0.3107 - re_lu_65_accuracy: 0.8653 - re_lu_121_accuracy: 0.8969 - re_lu_177_accuracy: 0.9547 - re_lu_233_accuracy: 0.9692 - val_loss: 155.5532 - val_re_lu_65_loss: 37.8549 - val_re_lu_121_loss: 38.3026 - val_re_lu_177_loss: 39.3352 - val_re_lu_233_loss: 40.0606 - val_re_lu_65_accuracy: 0.8275 - val_re_lu_121_accuracy: 0.7104 - val_re_lu_177_accuracy: 0.8114 - val_re_lu_233_accuracy: 0.8987\n",
      "Learning rate:  5e-05\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.4940 - re_lu_65_loss: 4.1848 - re_lu_121_loss: 1.4505 - re_lu_177_loss: 0.5517 - re_lu_233_loss: 0.3070 - re_lu_65_accuracy: 0.8652 - re_lu_121_accuracy: 0.8960 - re_lu_177_accuracy: 0.9539 - re_lu_233_accuracy: 0.9683  - ETA: 2:27 - loss: 6.6046 - re_lu_65_loss: 4.6272 - re_lu_121_loss: 1.3796 - re_lu_177_loss: 0.4207 - re_lu_233_loss: 0.1771 - re_lu_65_accuracy: 0.8441 - re_lu_121_accuracy: 0.8888 - re_lu_177_accuracy: 0. - ETA: 2:50 - loss: 7.3293 - re_lu_65_loss: 4.9109 - re_lu_121_loss: 1.5006 - re_lu_177_loss: 0.6161 - re_lu_233_loss: 0.3017 - re_lu_65_accuracy: 0.8628 - re_lu_121_accuracy: 0.8994 - re_lu_177 - ETA: 2:44 - loss: 7.3615 - re_lu_65_loss: 4.7086 - re_lu_121_loss: 1.6628 - re_lu_177_loss: 0.6445 - re_lu_233_loss: 0.3455 - re_lu_65_accuracy: 0.8639 - re_lu_121_accuracy: 0.891 - ETA: 2:34 - loss: 7.0465 - re_lu_65_loss: 4.5275 - re_lu_121_loss: 1.6199 - re_lu_177_loss: 0 - ETA: 2:10 - loss: 6.6651 - re_lu_65_loss: 4.3353 - re_lu_121_loss: 1.4774 - re_lu_177_loss: 0.5511 - re_lu_233_loss: 0.3012 - re_lu_65_accuracy - ETA: 1:53 - loss: 6.6917 - re_lu_65_loss: 4.3257 - re_lu_121_loss: 1.5000 - re_lu_177_loss: 0.5558 - re_lu_233_loss: 0.3103 - re_lu_65_accuracy: 0.8622 - re_lu_121_accuracy: 0.8915 - re_lu_177_accuracy: 0.9520 - re_lu_233_accuracy:  - ETA: 1:52 - loss: 6.6693 - re_lu_65_loss: 4.3151 - re_lu_121_loss: 1.4901 - re_lu_177_loss: 0.5543 - re_lu_233_loss: 0.3099 - re_lu_65_accuracy: 0. - ETA: 33s - loss: 6.4579 - re_lu_65_loss: 4.1867 - re_lu_121_loss: 1.4256 - re_lu_177_loss: 0.5413 - re_lu_233_loss: 0.3043 - re_lu_65_accuracy: 0.8651 - re_lu_121_accu\n",
      "Epoch 00100: loss improved from 6.54779 to 6.49398, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 6.4940 - re_lu_65_loss: 4.1848 - re_lu_121_loss: 1.4505 - re_lu_177_loss: 0.5517 - re_lu_233_loss: 0.3070 - re_lu_65_accuracy: 0.8652 - re_lu_121_accuracy: 0.8960 - re_lu_177_accuracy: 0.9539 - re_lu_233_accuracy: 0.9683 - val_loss: 155.4250 - val_re_lu_65_loss: 37.8357 - val_re_lu_121_loss: 38.2852 - val_re_lu_177_loss: 39.3023 - val_re_lu_233_loss: 40.0019 - val_re_lu_65_accuracy: 0.8318 - val_re_lu_121_accuracy: 0.7185 - val_re_lu_177_accuracy: 0.8280 - val_re_lu_233_accuracy: 0.9028\n",
      "Learning rate:  5e-05\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.4580 - re_lu_65_loss: 4.1650 - re_lu_121_loss: 1.4394 - re_lu_177_loss: 0.5474 - re_lu_233_loss: 0.3062 - re_lu_65_accuracy: 0.8655 - re_lu_121_accuracy: 0.8949 - re_lu_177_accuracy: 0.9547 - re_lu_233_accuracy: 0.9689  - ETA: 2:50 - loss: 6.8627 - re_lu_65_loss: 4.3003 - re_lu_121_loss: 1.6418 - re_lu_177_loss: 0.5664 - re_lu_233_loss: 0.3543 - re_lu_65_accuracy: 0.8591 - re_lu_121_accuracy: 0.8866 - re_\n",
      "Epoch 00101: loss improved from 6.49398 to 6.45798, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 6.4580 - re_lu_65_loss: 4.1650 - re_lu_121_loss: 1.4394 - re_lu_177_loss: 0.5474 - re_lu_233_loss: 0.3062 - re_lu_65_accuracy: 0.8655 - re_lu_121_accuracy: 0.8949 - re_lu_177_accuracy: 0.9547 - re_lu_233_accuracy: 0.9689 - val_loss: 155.4960 - val_re_lu_65_loss: 37.8430 - val_re_lu_121_loss: 38.2975 - val_re_lu_177_loss: 39.3275 - val_re_lu_233_loss: 40.0279 - val_re_lu_65_accuracy: 0.8268 - val_re_lu_121_accuracy: 0.7250 - val_re_lu_177_accuracy: 0.8257 - val_re_lu_233_accuracy: 0.8982\n",
      "Learning rate:  5e-05\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.4176 - re_lu_65_loss: 4.1432 - re_lu_121_loss: 1.4267 - re_lu_177_loss: 0.5440 - re_lu_233_loss: 0.3037 - re_lu_65_accuracy: 0.8661 - re_lu_121_accuracy: 0.8972 - re_lu_177_accuracy: 0.9550 - re_lu_233_accuracy: 0.9693  - ETA: 2:29 - loss: 6.7614 - re_lu_65_loss: 4.3688 - re_lu_121_loss: 1.5023 - re_lu_177_loss: 0.5741 - r -\n",
      "Epoch 00102: loss improved from 6.45798 to 6.41763, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 6.4176 - re_lu_65_loss: 4.1432 - re_lu_121_loss: 1.4267 - re_lu_177_loss: 0.5440 - re_lu_233_loss: 0.3037 - re_lu_65_accuracy: 0.8661 - re_lu_121_accuracy: 0.8972 - re_lu_177_accuracy: 0.9550 - re_lu_233_accuracy: 0.9693 - val_loss: 155.7697 - val_re_lu_65_loss: 37.8797 - val_re_lu_121_loss: 38.3495 - val_re_lu_177_loss: 39.4220 - val_re_lu_233_loss: 40.1185 - val_re_lu_65_accuracy: 0.8293 - val_re_lu_121_accuracy: 0.7210 - val_re_lu_177_accuracy: 0.8205 - val_re_lu_233_accuracy: 0.8934\n",
      "Learning rate:  5e-05\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.3681 - re_lu_65_loss: 4.1183 - re_lu_121_loss: 1.4151 - re_lu_177_loss: 0.5349 - re_lu_233_loss: 0.2999 - re_lu_65_accuracy: 0.8661 - re_lu_121_accuracy: 0.8970 - re_lu_177_accuracy: 0.9565 - re_lu_233_accuracy: 0.9700  - ETA: 2:44 - loss: 3.8201 - re_lu_65_loss: 2.8097 - re_lu_121_loss: 0.6025 - re_lu_177_loss: 0.2648 - re_lu_233_loss: 0.1430 - re_lu_65_accuracy: 0.8887 - re_lu_121_accuracy: 0.9163 - re_lu_177_accuracy: 0.9650 - re_lu_233_accuracy: 0 - ETA: 2:49 - loss: 3.9277 - re_lu_65_loss: 2.8133 - re_lu_121_loss: 0.7002 - re_lu_177_loss: 0.2752 - re_lu_233_loss: 0.1390 - re_lu_65_accuracy: 0.8903 - re_lu_121_accuracy: 0.9153 - re_ - ETA: 2:48 - loss: 5.9989 - re_lu_65_loss: 4.0633 - re_lu_121_loss: 1.2249 - re_lu_177_loss: 0.4316 - re_lu_233_loss: 0.2792 - re_lu_65_accuracy: 0.8573 - - ETA: 1:50 - loss: 5.9436 - re_lu_65_loss: 3.9388 - re_lu_121_loss: 1.2852 - re_lu_177_loss: 0.4475 - re_lu_233_lo - ETA: 1:27 - loss: 6.0149 - re_lu_65_loss: 3.9937 - re_lu_121_loss: 1.2987 - re_lu_177_loss: 0.4526 - re_lu_233_loss: 0.2700 - re_lu_65_accuracy: 0.8666 - re_lu_121_accuracy: 0.89 - ETA: 1:16 - loss: 6.00\n",
      "Epoch 00103: loss improved from 6.41763 to 6.36813, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 6.3681 - re_lu_65_loss: 4.1183 - re_lu_121_loss: 1.4151 - re_lu_177_loss: 0.5349 - re_lu_233_loss: 0.2999 - re_lu_65_accuracy: 0.8661 - re_lu_121_accuracy: 0.8970 - re_lu_177_accuracy: 0.9565 - re_lu_233_accuracy: 0.9700 - val_loss: 155.6096 - val_re_lu_65_loss: 37.8467 - val_re_lu_121_loss: 38.3021 - val_re_lu_177_loss: 39.3665 - val_re_lu_233_loss: 40.0943 - val_re_lu_65_accuracy: 0.8316 - val_re_lu_121_accuracy: 0.7229 - val_re_lu_177_accuracy: 0.8264 - val_re_lu_233_accuracy: 0.9010\n",
      "Learning rate:  5e-05\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.3441 - re_lu_65_loss: 4.1028 - re_lu_121_loss: 1.4064 - re_lu_177_loss: 0.5334 - re_lu_233_loss: 0.3014 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8962 - re_lu_177_accuracy: 0.9556 - re_lu_233_accuracy: 0.9686\n",
      "Epoch 00104: loss improved from 6.36813 to 6.34406, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.3441 - re_lu_65_loss: 4.1028 - re_lu_121_loss: 1.4064 - re_lu_177_loss: 0.5334 - re_lu_233_loss: 0.3014 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8962 - re_lu_177_accuracy: 0.9556 - re_lu_233_accuracy: 0.9686 - val_loss: 155.4557 - val_re_lu_65_loss: 37.8376 - val_re_lu_121_loss: 38.2517 - val_re_lu_177_loss: 39.3273 - val_re_lu_233_loss: 40.0390 - val_re_lu_65_accuracy: 0.8300 - val_re_lu_121_accuracy: 0.7287 - val_re_lu_177_accuracy: 0.8269 - val_re_lu_233_accuracy: 0.8982\n",
      "Learning rate:  5e-05\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.2936 - re_lu_65_loss: 4.0839 - re_lu_121_loss: 1.3896 - re_lu_177_loss: 0.5244 - re_lu_233_loss: 0.2957 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8964 - re_lu_177_accuracy: 0.9565 - re_lu_233_accuracy: 0.9703  ETA: 55s - loss: 6.4776 - re_lu_65_loss: 4.1867 - re_lu_121_loss: 1.4551 - re_lu_177_loss: 0.5405 - re_lu_233_los - ETA: 22s - loss: 6.3437 - re_lu_65_loss: 4.1070 - re_lu_121_loss: 1.4092 - re_lu_177_loss: 0.5322 - re_lu_233_loss: 0.2953 - re_lu_65_acc - ETA: 13s - loss: 6.3307 - re_lu_65_loss: 4.0959 - re_lu_121_loss: 1.4031 - re_lu_177_loss: 0.5316 - re_lu_233_loss: 0.3001 - re_lu_65_accuracy: 0.8648 - re_lu_121_accuracy: 0.8965 - re_lu_177_accuracy: 0.9564  - ETA: 10s - loss: 6.3232 - re_lu_65_loss: 4.0938 - re_lu_121_loss: 1.4005 - re_lu_177_loss: 0.5301 - re_lu_233_loss: 0.2989 - re_lu_65_accuracy: 0.8645 - re_lu_121_accuracy: 0.\n",
      "Epoch 00105: loss improved from 6.34406 to 6.29361, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.2936 - re_lu_65_loss: 4.0839 - re_lu_121_loss: 1.3896 - re_lu_177_loss: 0.5244 - re_lu_233_loss: 0.2957 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8964 - re_lu_177_accuracy: 0.9565 - re_lu_233_accuracy: 0.9703 - val_loss: 155.6263 - val_re_lu_65_loss: 37.8528 - val_re_lu_121_loss: 38.2952 - val_re_lu_177_loss: 39.3899 - val_re_lu_233_loss: 40.0885 - val_re_lu_65_accuracy: 0.8329 - val_re_lu_121_accuracy: 0.7292 - val_re_lu_177_accuracy: 0.8310 - val_re_lu_233_accuracy: 0.8969\n",
      "Learning rate:  5e-05\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.2487 - re_lu_65_loss: 4.0576 - re_lu_121_loss: 1.3796 - re_lu_177_loss: 0.5188 - re_lu_233_loss: 0.2927 - re_lu_65_accuracy: 0.8655 - re_lu_121_accuracy: 0.8977 - re_lu_177_accuracy: 0.9562 - re_lu_233_accuracy: 0.9715  - ETA: 2:23 - loss: 6.4150 - re_lu_65_loss: 4.1324 - re_lu_121_loss: 1.3969 - re_lu_177_loss: 0.5694 - re_lu_233_loss: 0.3163 - re_lu_65_accuracy: 0.8660 - re_lu_121_accuracy: 0.8982 - re_lu_177_accuracy: 0.9547  - ETA: 2:18 - loss: 6.4979 - re_lu_65_loss: 4.1450 - re_lu_121_loss: 1.4491 - re_lu_177_loss: 0.5819 - re_lu_233_loss: 0.3219 - re_l - ETA: 1:59 - loss: 6.5106 - re_lu_65_loss: 4.1974 - re_lu_121_loss: 1.4416 - re_lu_177_loss: 0.5611 - re_lu_233_loss: 0.3106 - re_lu_65_accuracy: 0.8644 - re_lu_121_accuracy: 0.8966 - re_lu_177_accuracy: 0.9548 - re_lu_233_accuracy - ETA: 1:57 - loss: 6.4699 - re_lu_65_loss: 4.1746 - re_lu_121_loss: 1.4303 - re_lu_177_loss: 0.5571 - re_lu_233_loss: 0.3079 - re - ETA: 1:37 - loss: 6.3193 - re_lu_65_loss: 4.0881 - re_lu_121_loss: 1.3976 - re_lu_177_loss: 0.5328 - re_lu_233_loss: 0.3007 - re_lu_65_accuracy: 0.8670 - re_lu_121_accuracy: 0.8983 - re_lu_177_accu - ETA: 1:30 - loss: 6.2543 - re_lu_65_loss: 4.0571 - re_lu_121_loss: 1.378 - ETA: 16s - loss: 6.2386 - re_lu_65_loss: 4.0368 - re_lu_121_loss: 1.3791 - re_lu_177_loss: 0.5256 - re_lu_233_los\n",
      "Epoch 00106: loss improved from 6.29361 to 6.24869, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.2487 - re_lu_65_loss: 4.0576 - re_lu_121_loss: 1.3796 - re_lu_177_loss: 0.5188 - re_lu_233_loss: 0.2927 - re_lu_65_accuracy: 0.8655 - re_lu_121_accuracy: 0.8977 - re_lu_177_accuracy: 0.9562 - re_lu_233_accuracy: 0.9715 - val_loss: 155.5939 - val_re_lu_65_loss: 37.8607 - val_re_lu_121_loss: 38.3192 - val_re_lu_177_loss: 39.3676 - val_re_lu_233_loss: 40.0463 - val_re_lu_65_accuracy: 0.8283 - val_re_lu_121_accuracy: 0.7307 - val_re_lu_177_accuracy: 0.8311 - val_re_lu_233_accuracy: 0.8946\n",
      "Learning rate:  5e-05\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.2067 - re_lu_65_loss: 4.0358 - re_lu_121_loss: 1.3674 - re_lu_177_loss: 0.5126 - re_lu_233_loss: 0.2909 - re_lu_65_accuracy: 0.8645 - re_lu_121_accuracy: 0.8966 - re_lu_177_accuracy: 0.9559 - re_lu_233_accuracy: 0.9720  - ETA: 2:17 - loss: 6.4322 - re_lu_65_loss: 4.1285 - re_lu_121_loss: 1.4021 - re_lu_177_loss: 0.5764 - - ETA: 1:53 - loss: 6.2550 - re_lu_65_loss: 4.0376 - re_lu_121_loss: 1.3812 - re_lu_177_loss: 0.5346 - re_lu_233_loss: 0.3016 - re_lu_65_accuracy: 0.8664 - re_lu_ - ETA: 1:38 - loss: 6.3896 - re_lu_65_loss: 4.1420 - re_lu_121_loss: 1.4054 - re - ETA: 1:09 - loss: 6.3131 - re_lu_65_loss: 4.0993 - re_lu_121_loss: 1.3941 - re_lu_177_loss: 0.5229 - re_lu_233_loss: 0.2968 - re_lu_65_accuracy: 0.8647 - re_lu_121_accuracy: 0.8 - ETA: 59s - loss: 6.3407 - re_lu_65_loss: 4.1172 - re_lu_121_loss: 1.3997 - re_lu_177_loss: 0.5225 - re_lu_233_loss: 0.3013 - re_lu_65_accuracy: 0.8639 - re_lu_121_accuracy: 0.8960 - re_ - ETA: 54s - loss: 6.3609 - re_lu_65_loss: 4.1326 - re_lu_121_loss: 1.4048 - re_lu_177_loss: 0.5220 - re_lu_233_loss: 0.3015 - re_lu_65_accuracy: 0.8633 - re_lu_121_accuracy: 0.8956 - re_lu_177_accuracy: 0.9556 - re - ETA: 52s - loss: 6.3637 - re_lu_65_loss: 4.1376 - re_lu_121_loss: 1.4055  - ETA: 15s - loss: 6.2859 - re_lu_65_loss: 4.0786 - re_lu_121_loss: 1.3926 - re_lu_177_loss: 0.5193 - re_lu_233_loss: 0.2954 - re_lu_65_accuracy: 0.8636 - re_lu_121_acc - ETA: 8s - loss: 6.2646 - re_lu_65_loss: 4.0706 - re_lu_121_loss: 1.3834 - re_lu_177_loss: 0.5163 - re_lu_233_loss: 0.2943 - re_lu_65_accuracy: 0.8640 - re_lu_121_accuracy: 0.8961 - re_lu_17\n",
      "Epoch 00107: loss improved from 6.24869 to 6.20665, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.2067 - re_lu_65_loss: 4.0358 - re_lu_121_loss: 1.3674 - re_lu_177_loss: 0.5126 - re_lu_233_loss: 0.2909 - re_lu_65_accuracy: 0.8645 - re_lu_121_accuracy: 0.8966 - re_lu_177_accuracy: 0.9559 - re_lu_233_accuracy: 0.9720 - val_loss: 155.6926 - val_re_lu_65_loss: 37.8796 - val_re_lu_121_loss: 38.3443 - val_re_lu_177_loss: 39.3932 - val_re_lu_233_loss: 40.0755 - val_re_lu_65_accuracy: 0.8268 - val_re_lu_121_accuracy: 0.7243 - val_re_lu_177_accuracy: 0.8301 - val_re_lu_233_accuracy: 0.8959\n",
      "Learning rate:  5e-05\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.1825 - re_lu_65_loss: 4.0241 - re_lu_121_loss: 1.3583 - re_lu_177_loss: 0.5095 - re_lu_233_loss: 0.2906 - re_lu_65_accuracy: 0.8655 - re_lu_121_accuracy: 0.8977 - re_lu_177_accuracy: 0.9570 - re_lu_233_accuracy: 0.9719  - ETA: 2:50 - loss: 6.8624 - re_lu_65_loss: 4.4900 - re_lu_121_loss: 1.5061 - re_lu_177_loss: 0.5146 - re_lu_233_loss: 0.3517 - re_lu_65_accuracy: 0.8587 - re_lu_121_accuracy: 0.8983 - re_lu_177_accuracy: 0.9577 - re_lu_233_accuracy: 0.9 - ETA: 2:50 - loss: 6.1994 - re_lu_65_loss: 4.0628 - re_lu_121_loss: 1.3442 - re_lu_177_loss: 0.4693 - re_lu_233_loss: 0.3232 - re_lu_65_accuracy: 0.8670 - re_lu_121_accurac - ETA: 2:44 - loss: 6.6862 - re_lu_65_loss: 4.4226 - re_lu_121_loss: 1.4216 - re_lu_177_loss: 0.5184 - re_lu_233_loss: 0.3237 - re_lu_65_accuracy: 0.8627 - re_lu_121_accuracy: 0.8966 - re_lu_177_accuracy: 0.9571 - re_lu_233_accu - ETA: 2:42 - loss: 6.7016 - re_lu_65_loss: 4.4028 - re_lu_121_loss: 1.4300 - re_lu_177_loss: 0.5340 - re_lu_233_loss: 0.3348 - re_lu_65_accuracy: 0.8618 - re_lu_121_accuracy: 0.8956 - re_lu_177_accuracy: 0.9564 - re_ - ETA: 2:38 - loss: 6.5524 - re_lu_65_loss: 4.3592 - re_lu_121_loss: 1.3823 - re_lu_177_loss: 0.5059 - re_lu_233_loss: 0.3050 - re_lu_65_accuracy: 0.8620 - re_lu_121_accuracy: 0.8959 - re_lu_177_accurac - ETA: 2:31 - loss: 6.8572 - re_lu_65_loss: 4.5007 - re_lu_121_loss: 1.5121 - re_lu_177_loss: 0.5490 - re_lu_233_loss: 0. - ETA: 4s - loss: 6.1577 - re_lu_65_loss: 4.0041 - re_lu_121_loss: 1.3514 - re_lu_177_loss: 0.5112 - re_lu_233_loss: 0.2909 - re_lu_65_accuracy: 0.8656 - re_lu_121_accuracy: 0.8978 - re_lu_177_accuracy: 0.9570 - \n",
      "Epoch 00108: loss improved from 6.20665 to 6.18251, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 6.1825 - re_lu_65_loss: 4.0241 - re_lu_121_loss: 1.3583 - re_lu_177_loss: 0.5095 - re_lu_233_loss: 0.2906 - re_lu_65_accuracy: 0.8655 - re_lu_121_accuracy: 0.8977 - re_lu_177_accuracy: 0.9570 - re_lu_233_accuracy: 0.9719 - val_loss: 155.7221 - val_re_lu_65_loss: 37.8582 - val_re_lu_121_loss: 38.3210 - val_re_lu_177_loss: 39.4247 - val_re_lu_233_loss: 40.1181 - val_re_lu_65_accuracy: 0.8289 - val_re_lu_121_accuracy: 0.7276 - val_re_lu_177_accuracy: 0.8379 - val_re_lu_233_accuracy: 0.8932\n",
      "Learning rate:  5e-05\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.1477 - re_lu_65_loss: 4.0102 - re_lu_121_loss: 1.3451 - re_lu_177_loss: 0.5038 - re_lu_233_loss: 0.2886 - re_lu_65_accuracy: 0.8662 - re_lu_121_accuracy: 0.8982 - re_lu_177_accuracy: 0.9564 - re_lu_233_accuracy: 0.9710  - ETA: 2:46 - loss: 6.2113 - re_lu_65_loss: 4.0568 - re_lu_121_loss: 1.3846 - re_lu_177_loss: 0.5076 - re_lu_233_loss: 0.2622 - re_lu_65_accuracy: 0.8589 - re_lu_121_accuracy: 0.8908 - re_lu_1 - ETA: 2:37 - loss: 6.6314 - re_lu_65_loss: 4.3152 - re_lu_121_loss: 1.4709 - re_lu_177_loss: 0.5437 - re_lu_233_loss: 0.3016 - re_lu_65_accuracy: 0.8562 - re_lu_121_accuracy: 0.8889 - re_lu_1 - ETA: 2:28 - l - ETA: 1:47 - loss: 6.1985 - re_l - ETA: 1:10 - loss: 6.1489 - re_lu_65_loss: 3.9839 - re_lu_121_loss: 1.3445 - re_lu_177_loss: 0.5171 - re_lu - ETA: 53s - loss: 6.2292 - re_lu_65_loss: 4.0470 - re_lu_121_loss: 1.3600 - re_lu_177_loss: 0.5222 - re_lu_2 - ETA: 41s - loss: 6.1816 - re_lu_65_loss: 4.0263 - re_lu_121_loss: 1.3438 - re_l\n",
      "Epoch 00109: loss improved from 6.18251 to 6.14774, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.1477 - re_lu_65_loss: 4.0102 - re_lu_121_loss: 1.3451 - re_lu_177_loss: 0.5038 - re_lu_233_loss: 0.2886 - re_lu_65_accuracy: 0.8662 - re_lu_121_accuracy: 0.8982 - re_lu_177_accuracy: 0.9564 - re_lu_233_accuracy: 0.9710 - val_loss: 155.6310 - val_re_lu_65_loss: 37.8429 - val_re_lu_121_loss: 38.3090 - val_re_lu_177_loss: 39.3971 - val_re_lu_233_loss: 40.0820 - val_re_lu_65_accuracy: 0.8304 - val_re_lu_121_accuracy: 0.7249 - val_re_lu_177_accuracy: 0.8404 - val_re_lu_233_accuracy: 0.8909\n",
      "Learning rate:  5e-05\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.1008 - re_lu_65_loss: 3.9838 - re_lu_121_loss: 1.3315 - re_lu_177_loss: 0.4991 - re_lu_233_loss: 0.2864 - re_lu_65_accuracy: 0.8661 - re_lu_121_accuracy: 0.8974 - re_lu_177_accuracy: 0.9571 - re_lu_233_accuracy: 0.9707  - ETA: 2:37 - loss: 5.9740 - re_lu_65_loss: 4.1105 - re_lu_121_loss: 1.0642 - re_lu_177_loss: 0.4805 - re_lu_233_loss: 0.3187 - re_lu_65_accuracy: 0.8615 - re_lu_121_accuracy: 0.8878 - re_lu_177_accuracy: 0.9576 - re_ - ETA: 2:51 - loss: 5.6306 - re_lu_65_loss: 3.7371 - re_lu_121_loss: 1.0626 - re_lu_177_loss: 0.5278 - re_lu_233_loss: 0.3031 - re_lu_65_accuracy: 0.8615 - re_lu_121_accuracy: 0.8940 - re_lu_177_ac - ETA: 2:47 - loss: 6.2398 - re_lu_65_loss: 3.9789 - re_lu_121_loss: 1.2945 - re_lu_177_loss: 0.5848 - re_lu_233_loss: 0.3816 - re_lu_65_accurac - ETA: 2:30 - loss: 6.4822 - re_lu_65_loss: 4.0641 - re_lu_121_loss: 1.4292 - re_lu_177_loss: 0.6087 - re_l - ETA: 2:07 - loss: 6.2580 - re_lu_65_loss: 4.0322 - re_lu_121_loss: 1.3539 - re_lu_177_loss: 0.5493 - re_lu_233_loss: 0.3227 - re_lu_65_accuracy: 0.8632 - re_lu_121_accuracy: 0.8925 - re_lu_177_accuracy: 0.9547 - re_lu_233_accura - ETA: 2:05 - loss: 6.2571 - re_lu_65_loss: 4.0442 - re_lu_121_loss: 1.3504  - ETA: 1:35 - loss: 6.1653 - re_lu_65_loss: 4.0096 - ETA: 16s - loss: 6.1456 - re_lu_65_loss: 4.0058 - re_lu_121_loss: 1.3448 - re_lu_177_loss: 0.5051 - re_lu_233_l\n",
      "Epoch 00110: loss improved from 6.14774 to 6.10075, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 6.1008 - re_lu_65_loss: 3.9838 - re_lu_121_loss: 1.3315 - re_lu_177_loss: 0.4991 - re_lu_233_loss: 0.2864 - re_lu_65_accuracy: 0.8661 - re_lu_121_accuracy: 0.8974 - re_lu_177_accuracy: 0.9571 - re_lu_233_accuracy: 0.9707 - val_loss: 155.7566 - val_re_lu_65_loss: 37.8880 - val_re_lu_121_loss: 38.3515 - val_re_lu_177_loss: 39.4123 - val_re_lu_233_loss: 40.1048 - val_re_lu_65_accuracy: 0.8246 - val_re_lu_121_accuracy: 0.7288 - val_re_lu_177_accuracy: 0.8415 - val_re_lu_233_accuracy: 0.8913\n",
      "Learning rate:  5e-05\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.0558 - re_lu_65_loss: 3.9646 - re_lu_121_loss: 1.3198 - re_lu_177_loss: 0.4910 - re_lu_233_loss: 0.2804 - re_lu_65_accuracy: 0.8668 - re_lu_121_accuracy: 0.8992 - re_lu_177_accuracy: 0.9576 - re_lu_233_accuracy: 0.9719  ETA: 16s - loss: 6.0862 - re_lu_65_loss: 3.9821 - re_lu_121_loss: 1.3279 - re_lu_177_loss: 0.4945 - re_lu_233_loss: 0.2817 - re_lu_65_accuracy: - ETA: 5s - loss: 6.0729 - re_lu_65_loss: 3.9689 - re_lu_121_loss: 1.3278 - re_lu_177_loss: 0.4941 - re_lu_233_loss: 0.2821 - re_lu_65_accuracy: 0.8668 - re_lu_121_accuracy: 0.8990 - re_lu_177_accuracy: 0.957\n",
      "Epoch 00111: loss improved from 6.10075 to 6.05578, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.0558 - re_lu_65_loss: 3.9646 - re_lu_121_loss: 1.3198 - re_lu_177_loss: 0.4910 - re_lu_233_loss: 0.2804 - re_lu_65_accuracy: 0.8668 - re_lu_121_accuracy: 0.8992 - re_lu_177_accuracy: 0.9576 - re_lu_233_accuracy: 0.9719 - val_loss: 155.5813 - val_re_lu_65_loss: 37.8807 - val_re_lu_121_loss: 38.3111 - val_re_lu_177_loss: 39.3512 - val_re_lu_233_loss: 40.0384 - val_re_lu_65_accuracy: 0.8290 - val_re_lu_121_accuracy: 0.7256 - val_re_lu_177_accuracy: 0.8429 - val_re_lu_233_accuracy: 0.8875\n",
      "Learning rate:  5e-05\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.0165 - re_lu_65_loss: 3.9440 - re_lu_121_loss: 1.3084 - re_lu_177_loss: 0.4861 - re_lu_233_loss: 0.2779 - re_lu_65_accuracy: 0.8648 - re_lu_121_accuracy: 0.8964 - re_lu_177_accuracy: 0.9578 - re_lu_233_accuracy: 0.9710  - ETA: 2:04 - loss: 6.2630 - re_lu_65_loss: 4.0693 - re_lu_121_loss: 1.4124 - re_lu_177_loss: 0.5039 - re_lu_233_loss: 0.2773 - re_lu_65_accuracy: 0.8637 - re_lu_121_accuracy: 0.8920 - re_lu_177_accuracy:  - ETA: 1:58 - loss: 6.2367 - re_lu_65\n",
      "Epoch 00112: loss improved from 6.05578 to 6.01654, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 6.0165 - re_lu_65_loss: 3.9440 - re_lu_121_loss: 1.3084 - re_lu_177_loss: 0.4861 - re_lu_233_loss: 0.2779 - re_lu_65_accuracy: 0.8648 - re_lu_121_accuracy: 0.8964 - re_lu_177_accuracy: 0.9578 - re_lu_233_accuracy: 0.9710 - val_loss: 155.8129 - val_re_lu_65_loss: 37.9085 - val_re_lu_121_loss: 38.3585 - val_re_lu_177_loss: 39.4557 - val_re_lu_233_loss: 40.0903 - val_re_lu_65_accuracy: 0.8314 - val_re_lu_121_accuracy: 0.7295 - val_re_lu_177_accuracy: 0.8498 - val_re_lu_233_accuracy: 0.8903\n",
      "Learning rate:  5e-05\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.9795 - re_lu_65_loss: 3.9273 - re_lu_121_loss: 1.2955 - re_lu_177_loss: 0.4811 - re_lu_233_loss: 0.2755 - re_lu_65_accuracy: 0.8667 - re_lu_121_accuracy: 0.8990 - re_lu_177_accuracy: 0.9581 - re_lu_233_accuracy: 0.9704  - ETA: 2:40 - loss:  - ETA: 2:01 - loss: 6.0629 - re_lu_65_loss: 3.9569 - re_lu_121_loss: 1.2982 - re_lu_177_loss: 0.5008 - re_lu_233_loss: 0.3070 - re_lu_65_accuracy: 0.8681 - re_lu_121_accuracy: 0.9014 - re_lu_177_accuracy: 0.9591 - re_lu_233_accuracy: 0.9 - ETA: 2:00 - loss: 6.0394 - re_lu_65_loss: 3.9475 - re_lu_121_loss: 1.2890 - re_lu_177_lo - ETA: 54s - loss: 5.9147 - re_lu_65_loss: 3.8914 - re_lu_121_loss: 1.2685 - re_lu_177_loss: 0.4771 - re_lu_233_loss: 0.2778 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9014 - re_lu_177_accuracy: 0.9590  - ETA: 52s - loss: 5.9091 - re_lu - ETA: 33s - loss: 5.9541 - re_lu_65_loss: 3.9338 - re_lu_121_loss: 1.2690 - re_lu_177_loss: 0.4748 - re_lu_233_loss: 0.2765 - re_lu_65_accurac - ETA: 24s - loss: 5.9674\n",
      "Epoch 00113: loss improved from 6.01654 to 5.97949, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.9795 - re_lu_65_loss: 3.9273 - re_lu_121_loss: 1.2955 - re_lu_177_loss: 0.4811 - re_lu_233_loss: 0.2755 - re_lu_65_accuracy: 0.8667 - re_lu_121_accuracy: 0.8990 - re_lu_177_accuracy: 0.9581 - re_lu_233_accuracy: 0.9704 - val_loss: 155.4659 - val_re_lu_65_loss: 37.8435 - val_re_lu_121_loss: 38.2816 - val_re_lu_177_loss: 39.3524 - val_re_lu_233_loss: 39.9884 - val_re_lu_65_accuracy: 0.8345 - val_re_lu_121_accuracy: 0.7332 - val_re_lu_177_accuracy: 0.8479 - val_re_lu_233_accuracy: 0.8883\n",
      "Learning rate:  5e-05\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.9379 - re_lu_65_loss: 3.9049 - re_lu_121_loss: 1.2826 - re_lu_177_loss: 0.4766 - re_lu_233_loss: 0.2738 - re_lu_65_accuracy: 0.8654 - re_lu_121_accuracy: 0.9000 - re_lu_177_accuracy: 0.9587 - re_lu_233_accuracy: 0.9731  - ETA: 2:29 - loss: 5.8912 - re_lu_65_loss: 3.8633 - re_ - ETA: 1:57 - loss: 5.6182 - re_lu_65_loss: 3.7004 - re_lu_121_loss: 1.2148 - ETA: 1:27 - loss: 5.8020 - re_lu_65_loss: 3.8139 - re_l - ETA: 56s - lo - ETA: 36s - loss: 5.9815 - re_lu_65_lo - ETA: 18s - loss: 5.9476 - re_lu_65_loss: 3.9183 - re_lu_121_loss: 1.2838 - re_lu_177_loss: 0.\n",
      "Epoch 00114: loss improved from 5.97949 to 5.93790, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.9379 - re_lu_65_loss: 3.9049 - re_lu_121_loss: 1.2826 - re_lu_177_loss: 0.4766 - re_lu_233_loss: 0.2738 - re_lu_65_accuracy: 0.8654 - re_lu_121_accuracy: 0.9000 - re_lu_177_accuracy: 0.9587 - re_lu_233_accuracy: 0.9731 - val_loss: 155.7318 - val_re_lu_65_loss: 37.8964 - val_re_lu_121_loss: 38.3609 - val_re_lu_177_loss: 39.3986 - val_re_lu_233_loss: 40.0759 - val_re_lu_65_accuracy: 0.8223 - val_re_lu_121_accuracy: 0.7320 - val_re_lu_177_accuracy: 0.8546 - val_re_lu_233_accuracy: 0.8907\n",
      "Learning rate:  5e-05\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.9206 - re_lu_65_loss: 3.8976 - re_lu_121_loss: 1.2766 - re_lu_177_loss: 0.4735 - re_lu_233_loss: 0.2728 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9010 - re_lu_177_accuracy: 0.9584 - re_lu_233_accuracy: 0.9721  - ETA: 2:40 - loss: 5.7723 - re_lu_65_loss: 3.7445 - re_lu_121_loss: 1.2840 - re_lu_177_loss: 0.4720 - re_lu_233_loss: 0.2718 - re_lu_65_accuracy: 0.8694 - re_lu_121_accuracy:  - ETA: 17s - loss: 5.8185 - re_lu_65_loss: 3.8442 - re_lu_121_loss: 1.2367 - re_lu_177_loss: 0.4659 - re_lu_233_loss: 0.2717 - re_lu_6 - ETA: 6s - loss: 5.8942 - re_lu_65_loss: 3.8836 - re_lu_121_loss: 1.2623 - re_lu_177_loss: 0.4756 - re_lu_233_loss: 0.2727 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy:\n",
      "Epoch 00115: loss improved from 5.93790 to 5.92057, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.9206 - re_lu_65_loss: 3.8976 - re_lu_121_loss: 1.2766 - re_lu_177_loss: 0.4735 - re_lu_233_loss: 0.2728 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9010 - re_lu_177_accuracy: 0.9584 - re_lu_233_accuracy: 0.9721 - val_loss: 155.7349 - val_re_lu_65_loss: 37.9181 - val_re_lu_121_loss: 38.3712 - val_re_lu_177_loss: 39.4032 - val_re_lu_233_loss: 40.0424 - val_re_lu_65_accuracy: 0.8224 - val_re_lu_121_accuracy: 0.7272 - val_re_lu_177_accuracy: 0.8539 - val_re_lu_233_accuracy: 0.8901\n",
      "Learning rate:  5e-05\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8797 - re_lu_65_loss: 3.8754 - re_lu_121_loss: 1.2633 - re_lu_177_loss: 0.4695 - re_lu_233_loss: 0.2716 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9010 - re_lu_177_accuracy: 0.9593 - re_lu_233_accuracy: 0.9696  - ETA: 2:43 - loss: 6.1112 - re_lu_65_loss: 3.8989 - ETA: 4s - loss: 5.8721 - re_lu_65_loss: 3.8688 - re_lu_121_loss: 1.2639 - re_lu_177_loss: 0.4670 - re_lu_233_loss: 0.2723 - re_lu_65_accuracy: 0.8681 - re_lu_121_accuracy: 0.9011 - re_lu_177_accuracy: 0.9593 - r\n",
      "Epoch 00116: loss improved from 5.92057 to 5.87966, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.8797 - re_lu_65_loss: 3.8754 - re_lu_121_loss: 1.2633 - re_lu_177_loss: 0.4695 - re_lu_233_loss: 0.2716 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9010 - re_lu_177_accuracy: 0.9593 - re_lu_233_accuracy: 0.9696 - val_loss: 155.5517 - val_re_lu_65_loss: 37.8745 - val_re_lu_121_loss: 38.3255 - val_re_lu_177_loss: 39.3365 - val_re_lu_233_loss: 40.0151 - val_re_lu_65_accuracy: 0.8271 - val_re_lu_121_accuracy: 0.7334 - val_re_lu_177_accuracy: 0.8598 - val_re_lu_233_accuracy: 0.8897\n",
      "Learning rate:  5e-05\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8350 - re_lu_65_loss: 3.8574 - re_lu_121_loss: 1.2493 - re_lu_177_loss: 0.4605 - re_lu_233_loss: 0.2677 - re_lu_65_accuracy: 0.8670 - re_lu_121_accuracy: 0.9031 - re_lu_177_accuracy: 0.9607 - re_lu_233_accuracy: 0.9726  - ETA: 2:50 - loss: 7.1724 - re_lu_65_loss: 4.6002 - re_lu_121_loss: 1.6455 - re_lu_177_loss: 0.5580 - re_lu_233_loss: 0.3687 - re_lu_65_accuracy: 0.8649 - re_lu_121_accuracy: 0.8951 - re_lu_177_accuracy: 0.9578 - re_lu_233_a - ETA: 2:48 - loss: 6.7702 - re_lu_65_loss: 4.4028 - re_lu_121_loss: 1.4816 - re_lu_177_loss: - ETA: 2:26 - loss: 6.5081 - re_lu_65_loss: 4.2456 - re_lu_121_loss: 1.4146 - re_lu_177_loss: 0.5364 - re_lu_233_loss - ETA: 2:04 - \n",
      "Epoch 00117: loss improved from 5.87966 to 5.83498, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 5.8350 - re_lu_65_loss: 3.8574 - re_lu_121_loss: 1.2493 - re_lu_177_loss: 0.4605 - re_lu_233_loss: 0.2677 - re_lu_65_accuracy: 0.8670 - re_lu_121_accuracy: 0.9031 - re_lu_177_accuracy: 0.9607 - re_lu_233_accuracy: 0.9726 - val_loss: 155.6503 - val_re_lu_65_loss: 37.8923 - val_re_lu_121_loss: 38.3615 - val_re_lu_177_loss: 39.3737 - val_re_lu_233_loss: 40.0229 - val_re_lu_65_accuracy: 0.8298 - val_re_lu_121_accuracy: 0.7574 - val_re_lu_177_accuracy: 0.8605 - val_re_lu_233_accuracy: 0.8889\n",
      "Learning rate:  5e-05\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8045 - re_lu_65_loss: 3.8409 - re_lu_121_loss: 1.2383 - re_lu_177_loss: 0.4577 - re_lu_233_loss: 0.2676 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9603 - re_lu_233_accuracy: 0.9719  - ETA: 2:13 - loss: 5.7538 - re_lu_65_loss: 3.8320 - re_lu_121_loss: 1.2198 - re_lu_177_loss: 0.4532 - re_lu_233_loss: 0.2488 - r - ETA: 1:53 - loss: 5.8217 - re_lu_65_los - ETA: 1:17 - loss - E\n",
      "Epoch 00118: loss improved from 5.83498 to 5.80448, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.8045 - re_lu_65_loss: 3.8409 - re_lu_121_loss: 1.2383 - re_lu_177_loss: 0.4577 - re_lu_233_loss: 0.2676 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9603 - re_lu_233_accuracy: 0.9719 - val_loss: 155.6804 - val_re_lu_65_loss: 37.8888 - val_re_lu_121_loss: 38.3594 - val_re_lu_177_loss: 39.3855 - val_re_lu_233_loss: 40.0468 - val_re_lu_65_accuracy: 0.8293 - val_re_lu_121_accuracy: 0.7346 - val_re_lu_177_accuracy: 0.8529 - val_re_lu_233_accuracy: 0.8889\n",
      "Learning rate:  5e-05\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7691 - re_lu_65_loss: 3.8218 - re_lu_121_loss: 1.2304 - re_lu_177_loss: 0.4534 - re_lu_233_loss: 0.2635 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9614 - re_lu_233_accuracy: 0.9715  - ETA: 1:50 - loss: 5.6352 - re_lu_65_loss: 3.7316 - re_lu_121_loss: 1.1970 - re_lu_177_loss: 0.4523 - re_lu_233_loss: 0.2543 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9032 - re_lu_177_accur - ETA: 1:43 - loss: 5.6045 - re_lu_65_loss: 3.7329 - re_lu_121_loss: 1.1808 - re_lu_177_loss: 0.4389 - re_lu_233_loss: \n",
      "Epoch 00119: loss improved from 5.80448 to 5.76910, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.7691 - re_lu_65_loss: 3.8218 - re_lu_121_loss: 1.2304 - re_lu_177_loss: 0.4534 - re_lu_233_loss: 0.2635 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9614 - re_lu_233_accuracy: 0.9715 - val_loss: 155.7103 - val_re_lu_65_loss: 37.9074 - val_re_lu_121_loss: 38.3801 - val_re_lu_177_loss: 39.3793 - val_re_lu_233_loss: 40.0434 - val_re_lu_65_accuracy: 0.8296 - val_re_lu_121_accuracy: 0.7540 - val_re_lu_177_accuracy: 0.8643 - val_re_lu_233_accuracy: 0.8914\n",
      "Learning rate:  5e-05\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7390 - re_lu_65_loss: 3.8121 - re_lu_121_loss: 1.2146 - re_lu_177_loss: 0.4492 - re_lu_233_loss: 0.2631 - re_lu_65_accuracy: 0.8667 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9722\n",
      "Epoch 00120: loss improved from 5.76910 to 5.73896, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 5.7390 - re_lu_65_loss: 3.8121 - re_lu_121_loss: 1.2146 - re_lu_177_loss: 0.4492 - re_lu_233_loss: 0.2631 - re_lu_65_accuracy: 0.8667 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9722 - val_loss: 155.9138 - val_re_lu_65_loss: 37.9065 - val_re_lu_121_loss: 38.4387 - val_re_lu_177_loss: 39.4526 - val_re_lu_233_loss: 40.1160 - val_re_lu_65_accuracy: 0.8282 - val_re_lu_121_accuracy: 0.7485 - val_re_lu_177_accuracy: 0.8614 - val_re_lu_233_accuracy: 0.8951\n",
      "Learning rate:  5e-05\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.6983 - re_lu_65_loss: 3.7948 - re_lu_121_loss: 1.2031 - re_lu_177_loss: 0.4417 - re_lu_233_loss: 0.2587 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9044 - re_lu_177_accuracy: 0.9615 - re_lu_233_accuracy: 0.9727- ETA: 8s - loss: 5.7316 - re_lu_65_loss: 3.8166 - re_lu_121_loss: 1.2110 - re_lu_177_loss: 0.4440 - re_lu_233_loss: 0.2600 - re_lu_65_accuracy: 0.8667 - re_lu_121_accuracy: 0.9040 - re_lu_177_accuracy: 0.9613 - re_lu_233_accu - ETA: 6s - loss: 5.7073 - re_lu_65_loss: 3.8051 - re_lu_121_loss: 1.2024 - re_lu_177_loss: 0.4413 - re_lu_233_loss: 0.2585 - re_lu_65_accuracy: 0.8670 - re_lu_121_accuracy: 0.9042 - re_lu_177_accuracy: 0.\n",
      "Epoch 00121: loss improved from 5.73896 to 5.69826, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.6983 - re_lu_65_loss: 3.7948 - re_lu_121_loss: 1.2031 - re_lu_177_loss: 0.4417 - re_lu_233_loss: 0.2587 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9044 - re_lu_177_accuracy: 0.9615 - re_lu_233_accuracy: 0.9727 - val_loss: 155.8667 - val_re_lu_65_loss: 37.9245 - val_re_lu_121_loss: 38.4212 - val_re_lu_177_loss: 39.4268 - val_re_lu_233_loss: 40.0941 - val_re_lu_65_accuracy: 0.8347 - val_re_lu_121_accuracy: 0.7466 - val_re_lu_177_accuracy: 0.8602 - val_re_lu_233_accuracy: 0.8941\n",
      "Learning rate:  5e-06\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.6213 - re_lu_65_loss: 3.7546 - re_lu_121_loss: 1.1845 - re_lu_177_loss: 0.4317 - re_lu_233_loss: 0.2507 - re_lu_65_accuracy: 0.8688 - re_lu_121_accuracy: 0.9038 - re_lu_177_accuracy: 0.9617 - re_lu_233_accuracy: 0.9730  - ETA: 1:49 - loss: 5.4419 - re_lu_65_loss: 3.6611 - re_lu_121_loss: 1.1021 - re_lu_177_loss: 0.4298 - re_lu_233_loss: 0.2489 - re_lu_65_accuracy: 0.8678 - ETA: 1:33 - loss: 5.4451 - re_lu_65_loss: 3.6735 - re_lu_121_loss: 1.0969 - re_lu_177_loss: 0.4281 - re_lu_233_loss: 0.2466 - re_l - ETA: 23s - loss: 5.6125 - re_lu_65_loss: 3.7665 - re_lu_121_loss: 1.1727 - re_lu_177_loss: 0.4312 - re_lu_233_los - ETA: 12s - loss: 5.6275 - re_lu_65_loss: 3.7721 - re_lu_121_loss: 1.1808 - re_lu_177_loss: 0.4311 - re_lu_233_loss: 0.2435 - re_lu_65_accuracy: 0.8681 - re_lu_\n",
      "Epoch 00122: loss improved from 5.69826 to 5.62133, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.6213 - re_lu_65_loss: 3.7546 - re_lu_121_loss: 1.1845 - re_lu_177_loss: 0.4317 - re_lu_233_loss: 0.2507 - re_lu_65_accuracy: 0.8688 - re_lu_121_accuracy: 0.9038 - re_lu_177_accuracy: 0.9617 - re_lu_233_accuracy: 0.9730 - val_loss: 155.8357 - val_re_lu_65_loss: 37.9206 - val_re_lu_121_loss: 38.4192 - val_re_lu_177_loss: 39.4133 - val_re_lu_233_loss: 40.0825 - val_re_lu_65_accuracy: 0.8316 - val_re_lu_121_accuracy: 0.7467 - val_re_lu_177_accuracy: 0.8608 - val_re_lu_233_accuracy: 0.8907\n",
      "Learning rate:  5e-06\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.6044 - re_lu_65_loss: 3.7494 - re_lu_121_loss: 1.1796 - re_lu_177_loss: 0.4278 - re_lu_233_loss: 0.2476 - re_lu_65_accuracy: 0.8687 - re_lu_121_accuracy: 0.9036 - re_lu_177_accuracy: 0.9619 - re_lu_233_accuracy: 0.9728\n",
      "Epoch 00123: loss improved from 5.62133 to 5.60441, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 5.6044 - re_lu_65_loss: 3.7494 - re_lu_121_loss: 1.1796 - re_lu_177_loss: 0.4278 - re_lu_233_loss: 0.2476 - re_lu_65_accuracy: 0.8687 - re_lu_121_accuracy: 0.9036 - re_lu_177_accuracy: 0.9619 - re_lu_233_accuracy: 0.9728 - val_loss: 155.9055 - val_re_lu_65_loss: 37.9155 - val_re_lu_121_loss: 38.4234 - val_re_lu_177_loss: 39.4532 - val_re_lu_233_loss: 40.1134 - val_re_lu_65_accuracy: 0.8317 - val_re_lu_121_accuracy: 0.7494 - val_re_lu_177_accuracy: 0.8602 - val_re_lu_233_accuracy: 0.8917\n",
      "Learning rate:  5e-06\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5768 - re_lu_65_loss: 3.7348 - re_lu_121_loss: 1.1754 - re_lu_177_loss: 0.4231 - re_lu_233_loss: 0.2435 - re_lu_65_accuracy: 0.8687 - re_lu_121_accuracy: 0.9030 - re_lu_177_accuracy: 0.9620 - re_lu_233_accuracy: 0.9729  - ETA: 2:41 - loss: 5.6150 - re_lu_65_loss: 3.8968 - \n",
      "Epoch 00124: loss improved from 5.60441 to 5.57682, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 5.5768 - re_lu_65_loss: 3.7348 - re_lu_121_loss: 1.1754 - re_lu_177_loss: 0.4231 - re_lu_233_loss: 0.2435 - re_lu_65_accuracy: 0.8687 - re_lu_121_accuracy: 0.9030 - re_lu_177_accuracy: 0.9620 - re_lu_233_accuracy: 0.9729 - val_loss: 155.8548 - val_re_lu_65_loss: 37.9129 - val_re_lu_121_loss: 38.4176 - val_re_lu_177_loss: 39.4287 - val_re_lu_233_loss: 40.0955 - val_re_lu_65_accuracy: 0.8320 - val_re_lu_121_accuracy: 0.7489 - val_re_lu_177_accuracy: 0.8621 - val_re_lu_233_accuracy: 0.8899\n",
      "Learning rate:  5e-06\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5726 - re_lu_65_loss: 3.7360 - re_lu_121_loss: 1.1717 - re_lu_177_loss: 0.4221 - re_lu_233_loss: 0.2428 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9027 - re_lu_177_accuracy: 0.9618 - re_lu_233_accuracy: 0.9725\n",
      "Epoch 00125: loss improved from 5.57682 to 5.57261, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 5.5726 - re_lu_65_loss: 3.7360 - re_lu_121_loss: 1.1717 - re_lu_177_loss: 0.4221 - re_lu_233_loss: 0.2428 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9027 - re_lu_177_accuracy: 0.9618 - re_lu_233_accuracy: 0.9725 - val_loss: 155.7969 - val_re_lu_65_loss: 37.8970 - val_re_lu_121_loss: 38.4091 - val_re_lu_177_loss: 39.4199 - val_re_lu_233_loss: 40.0710 - val_re_lu_65_accuracy: 0.8306 - val_re_lu_121_accuracy: 0.7445 - val_re_lu_177_accuracy: 0.8581 - val_re_lu_233_accuracy: 0.8891\n",
      "Learning rate:  5e-06\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5655 - re_lu_65_loss: 3.7335 - re_lu_121_loss: 1.1708 - re_lu_177_loss: 0.4200 - re_lu_233_loss: 0.2411 - re_lu_65_accuracy: 0.8684 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9712  ETA: 34s - loss: 5.5856 - re_lu_65_loss: 3.7376 - re_lu_121_loss: 1.1692 - re_lu_177_loss: 0.4299 - re_lu_233_loss: 0.2488 - re_lu_65_accuracy: 0.8683 - re_lu_121_accuracy: 0.9024 - re_lu_1 - ETA: 30s - loss: 5.5957 - re_lu_65_loss: 3.7394 - re_lu_121_loss: 1.1777 - re_lu_177_loss: 0.4303 - re_lu_233_loss: 0.2483 - re_lu_65_accuracy: 0.8684 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: - ETA: 27s - loss: 5.5879 - re_lu_65_loss: 3.7359 - re_lu_121_loss: 1.1764 - re_lu_177_loss: 0.4290 - re_lu_233_loss: 0.2466 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9608 - re_lu_233_ac - ETA: 25\n",
      "Epoch 00126: loss improved from 5.57261 to 5.56547, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.5655 - re_lu_65_loss: 3.7335 - re_lu_121_loss: 1.1708 - re_lu_177_loss: 0.4200 - re_lu_233_loss: 0.2411 - re_lu_65_accuracy: 0.8684 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9712 - val_loss: 155.8543 - val_re_lu_65_loss: 37.9109 - val_re_lu_121_loss: 38.4217 - val_re_lu_177_loss: 39.4290 - val_re_lu_233_loss: 40.0926 - val_re_lu_65_accuracy: 0.8307 - val_re_lu_121_accuracy: 0.7495 - val_re_lu_177_accuracy: 0.8602 - val_re_lu_233_accuracy: 0.8909\n",
      "Learning rate:  5e-06\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5559 - re_lu_65_loss: 3.7288 - re_lu_121_loss: 1.1669 - re_lu_177_loss: 0.4192 - re_lu_233_loss: 0.2410 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy: 0.9024 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9716  - ETA: 2:46 - loss: 6.2089 - re_lu_65_loss: 3.9030 - re_lu_121_loss: 1.4333 - re_lu_177_loss: 0.5977 - re_lu_233_loss: 0.2749 - re_lu_65_accuracy: 0.8700 - re_lu_121 - ETA: 2:44 - loss: 5.3851 - re_lu_65_loss: 3.6583 - re_lu_121_loss: 1.0862 - re_lu_177_loss: 0.4062 - re_lu_233_loss: 0.2344 - re_lu_65_accuracy: 0.8711 - re_lu_121_accuracy: 0.9043 - re_lu_177_accuracy: 0 - ETA: 2:38 - loss: 5.3309 - re_lu_65_loss: 3.5846 - re_lu_121_loss: 1.1407 - re_lu_177_loss: 0.3922 - re_lu_233_loss: 0.2134 - re_lu_6 - ETA: 2:20 - loss: 5.6476 - re_lu_65_loss: 3.7559 - re_lu_121_loss: 1.2200 - re_lu_177_loss:  - ETA: 1:54 - loss: 5.6702 - re_lu_65_loss: 3.7823 - re_lu_121_loss: 1.2166 - re_lu_177_loss: 0.4289 - re_lu_233_loss: 0.2424 - re_lu_65_accuracy: 0.8672 - ETA: 1:38 - loss: 5.6702 - re_lu_65_loss: 3.7905 - re_lu_121_loss: 1.2177 - re_lu_177_loss: 0.4215 - re_lu_233_loss: 0.2406  - ETA: 1:17 - loss:\n",
      "Epoch 00127: loss improved from 5.56547 to 5.55592, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.5559 - re_lu_65_loss: 3.7288 - re_lu_121_loss: 1.1669 - re_lu_177_loss: 0.4192 - re_lu_233_loss: 0.2410 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy: 0.9024 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9716 - val_loss: 155.8290 - val_re_lu_65_loss: 37.9091 - val_re_lu_121_loss: 38.4171 - val_re_lu_177_loss: 39.4189 - val_re_lu_233_loss: 40.0839 - val_re_lu_65_accuracy: 0.8313 - val_re_lu_121_accuracy: 0.7474 - val_re_lu_177_accuracy: 0.8612 - val_re_lu_233_accuracy: 0.8910\n",
      "Learning rate:  5e-06\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5285 - re_lu_65_loss: 3.7147 - re_lu_121_loss: 1.1610 - re_lu_177_loss: 0.4154 - re_lu_233_loss: 0.2374 - re_lu_65_accuracy: 0.8689 - re_lu_121_accuracy: 0.9029 - re_lu_177_accuracy: 0.9616 - re_lu_233_accuracy: 0.9714  - ETA: 2:41 - loss: 5.0112 - re_lu_65_loss: 3.4480 - re_lu_121_loss: 1.0245 - re_lu_177_loss: 0.3578 - - ETA: 2:17 - loss: 5.5982 - re_lu_65_loss: 3.7474 - re_lu_121_loss: 1.2046 - re_lu_177_loss: 0.4124 - re_l - ETA: 1:53 - loss: 5.5594 - re_lu_65_loss: 3.7514 - re_lu_121_loss: 1.1855 - re_lu_177_loss: 0.3987 - re_lu_233_loss: 0.2237 - re_lu_65_ - ETA:  - ETA: 12s - loss: 5.4311 - re_lu_65_loss: 3.6613 - re_lu_121_loss: 1.1352 - re_lu_177_loss: 0.4021 - re_lu_233_loss: 0.2326 - re_lu_65_accuracy: 0.8702 - \n",
      "Epoch 00128: loss improved from 5.55592 to 5.52853, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.5285 - re_lu_65_loss: 3.7147 - re_lu_121_loss: 1.1610 - re_lu_177_loss: 0.4154 - re_lu_233_loss: 0.2374 - re_lu_65_accuracy: 0.8689 - re_lu_121_accuracy: 0.9029 - re_lu_177_accuracy: 0.9616 - re_lu_233_accuracy: 0.9714 - val_loss: 155.8504 - val_re_lu_65_loss: 37.9134 - val_re_lu_121_loss: 38.4174 - val_re_lu_177_loss: 39.4341 - val_re_lu_233_loss: 40.0855 - val_re_lu_65_accuracy: 0.8268 - val_re_lu_121_accuracy: 0.7454 - val_re_lu_177_accuracy: 0.8600 - val_re_lu_233_accuracy: 0.8900\n",
      "Learning rate:  5e-06\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5248 - re_lu_65_loss: 3.7174 - re_lu_121_loss: 1.1577 - re_lu_177_loss: 0.4132 - re_lu_233_loss: 0.2366 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9029 - re_lu_177_accuracy: 0.9615 - re_lu_233_accuracy: 0.9726  - ETA: 2:13 - loss: 5.3892 - re_lu_65_loss: 3.5970 - re_lu_121_loss: 1.0989 - re_lu_177_loss: 0.4272 - re_lu_233_loss: 0.2660 - re_lu_65_accuracy: 0.8697 - re_lu_121_accuracy: - ETA: 2:01 - loss: 5.4796 - re_lu_65_loss: 3.6854 - re_lu_121_loss: 1.1203 - re_lu_177_loss: 0.4218 - re_lu_233 - ETA: 1:38 - loss: 5.6859 - re_lu_65_loss: 3.8029 - re_lu_121_loss: 1.1917 - re_lu_177_loss: 0.4355 - re_lu_233_loss: 0.2558 - re_lu_65_accuracy: 0.8671 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy:  - ETA: 1:31 - loss: 5.7329 - re_lu_65_loss: 3.8326 - re_lu_121_loss: 1.2108 - re_lu_177_loss: 0.4353 - re_lu_233_loss: 0.2543 - re_lu_65_accuracy: 0.8660  - ETA: 1:16 - loss: 5.592\n",
      "Epoch 00129: loss improved from 5.52853 to 5.52485, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.5248 - re_lu_65_loss: 3.7174 - re_lu_121_loss: 1.1577 - re_lu_177_loss: 0.4132 - re_lu_233_loss: 0.2366 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9029 - re_lu_177_accuracy: 0.9615 - re_lu_233_accuracy: 0.9726 - val_loss: 155.8320 - val_re_lu_65_loss: 37.9089 - val_re_lu_121_loss: 38.4073 - val_re_lu_177_loss: 39.4275 - val_re_lu_233_loss: 40.0883 - val_re_lu_65_accuracy: 0.8308 - val_re_lu_121_accuracy: 0.7482 - val_re_lu_177_accuracy: 0.8581 - val_re_lu_233_accuracy: 0.8906\n",
      "Learning rate:  5e-06\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5162 - re_lu_65_loss: 3.7108 - re_lu_121_loss: 1.1562 - re_lu_177_loss: 0.4126 - re_lu_233_loss: 0.2366 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9611 - re_lu_233_accuracy: 0.9719  - ETA: 1:49 - loss: 5.2235 - re_lu_65_loss: 3.5070 - re_lu_121_loss: 1.0946 - re_lu_177_loss: 0.3871 - re_lu_233_loss: 0.2348 - re_lu_65_accuracy: 0.8722 - re_lu_121_accuracy: 0.9046 - re_lu_177_accuracy: 0.9624 - re_lu_ - ETA: 1:45 - loss: 5.2357 - re_lu_65_loss: 3.4965 - re_lu_121_loss: 1.0977 - re_lu_177_loss: 0.3990 -  - ETA: 48s - loss: 5.4818 - re_lu_65_loss: 3.6708 - re_lu_121_loss: 1.1418 - re_lu_177_loss: 0.4225 - re_lu_233_loss: 0.2467 - re_l - ETA: 38s - loss: 5. - ETA: 18s - loss: 5.4611 - re_lu_65_loss: 3.6612 - re_lu_121_loss: 1.1450 - re_lu_177_loss\n",
      "Epoch 00130: loss improved from 5.52485 to 5.51623, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.5162 - re_lu_65_loss: 3.7108 - re_lu_121_loss: 1.1562 - re_lu_177_loss: 0.4126 - re_lu_233_loss: 0.2366 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9611 - re_lu_233_accuracy: 0.9719 - val_loss: 155.8097 - val_re_lu_65_loss: 37.9163 - val_re_lu_121_loss: 38.4115 - val_re_lu_177_loss: 39.4180 - val_re_lu_233_loss: 40.0638 - val_re_lu_65_accuracy: 0.8267 - val_re_lu_121_accuracy: 0.7444 - val_re_lu_177_accuracy: 0.8605 - val_re_lu_233_accuracy: 0.8901\n",
      "Learning rate:  5e-06\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5058 - re_lu_65_loss: 3.7094 - re_lu_121_loss: 1.1529 - re_lu_177_loss: 0.4094 - re_lu_233_loss: 0.2341 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9614 - re_lu_233_accuracy: 0.9724  - ETA: 2:27 - loss: 5.7931 - re_lu_65_loss: 3.8821 - re_lu_121_loss: 1.2115 - re_lu_177_loss: 0.4352 - re_lu_233_lo - ETA: 2:04 - loss: 5.5303 - re_lu_65_loss: 3.7335 - re_lu_121_loss: 1.1324 - re_lu_177_loss: 0.4123 - re_lu_233_loss: 0.2521 - re_lu_65_accuracy: 0.8671 - re_lu_121_accuracy: 0.9008 - re - ETA: 1:55 - loss: 5.6179 - re_lu_65_loss: 3.7836 - re_lu_121_loss: 1.1665 - re_lu_177_loss: 0.4181 - re_lu_233_loss: 0.2498 - re_lu_65_accuracy: 0.8663 - re_lu_121_accuracy: 0.8997 - re_lu_177_accuracy: - ETA: 1:48 - loss: 5.6440 - re_lu_65_loss: 3.7983 - re_lu_121_loss: 1.1790 - re_lu_177_loss: 0.4191 - re_lu_233_loss: 0.2476 - re_lu_65_accuracy: 0.8666 - re_lu_121_accuracy: 0.9001 - re_lu_1 - ETA: 14s - loss: 5.5188 - re_lu_65_loss: 3.7205 - re_lu_121_loss: 1.1583 - re_lu_177_loss: 0.4078 - re_lu_233_loss: 0.2321 - re_lu_6\n",
      "Epoch 00131: loss improved from 5.51623 to 5.50581, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.5058 - re_lu_65_loss: 3.7094 - re_lu_121_loss: 1.1529 - re_lu_177_loss: 0.4094 - re_lu_233_loss: 0.2341 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9614 - re_lu_233_accuracy: 0.9724 - val_loss: 155.8535 - val_re_lu_65_loss: 37.9101 - val_re_lu_121_loss: 38.4226 - val_re_lu_177_loss: 39.4338 - val_re_lu_233_loss: 40.0871 - val_re_lu_65_accuracy: 0.8317 - val_re_lu_121_accuracy: 0.7462 - val_re_lu_177_accuracy: 0.8627 - val_re_lu_233_accuracy: 0.8912\n",
      "Learning rate:  5e-06\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4975 - re_lu_65_loss: 3.7033 - re_lu_121_loss: 1.1517 - re_lu_177_loss: 0.4088 - re_lu_233_loss: 0.2337 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9730  ETA: 35s - loss: 5.4538 - re_lu_65_loss: 3.6529 - re_lu - ETA: 18s - loss: 5.4353 - re_lu_65_loss: 3.6454 - re_lu_121_loss: 1.1347 - re_lu_177\n",
      "Epoch 00132: loss improved from 5.50581 to 5.49755, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.4975 - re_lu_65_loss: 3.7033 - re_lu_121_loss: 1.1517 - re_lu_177_loss: 0.4088 - re_lu_233_loss: 0.2337 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9730 - val_loss: 155.8445 - val_re_lu_65_loss: 37.9059 - val_re_lu_121_loss: 38.4199 - val_re_lu_177_loss: 39.4346 - val_re_lu_233_loss: 40.0841 - val_re_lu_65_accuracy: 0.8280 - val_re_lu_121_accuracy: 0.7487 - val_re_lu_177_accuracy: 0.8625 - val_re_lu_233_accuracy: 0.8910\n",
      "Learning rate:  5e-06\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5018 - re_lu_65_loss: 3.7054 - re_lu_121_loss: 1.1515 - re_lu_177_loss: 0.4105 - re_lu_233_loss: 0.2344 - re_lu_65_accuracy: 0.8668 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9610 - re_lu_233_accuracy: 0.9723  ETA: 13s - loss: 5.5256 - re_lu_65_loss: 3.7178 - re_lu_121_loss: 1.1569 - re_lu_177_loss: 0.4135 - re_lu_233_loss: 0.2373 - re_lu_65_accuracy: 0.8667 - re_lu_121_accuracy: 0.9014 - re_lu_177_accuracy: 0 - ETA: 10s - loss: 5.5043 - re_lu_65_loss: 3.7079 - re_lu_121_loss: 1.1506 - re_lu_177_loss: 0.4107 - re_lu_233_loss: 0.2351 - re_lu_65_accuracy: 0.8668 - re_lu_121_accuracy: \n",
      "Epoch 00133: loss did not improve from 5.49755\n",
      "1000/1000 [==============================] - 193s 193ms/step - loss: 5.5018 - re_lu_65_loss: 3.7054 - re_lu_121_loss: 1.1515 - re_lu_177_loss: 0.4105 - re_lu_233_loss: 0.2344 - re_lu_65_accuracy: 0.8668 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9610 - re_lu_233_accuracy: 0.9723 - val_loss: 155.8367 - val_re_lu_65_loss: 37.8950 - val_re_lu_121_loss: 38.4199 - val_re_lu_177_loss: 39.4365 - val_re_lu_233_loss: 40.0854 - val_re_lu_65_accuracy: 0.8302 - val_re_lu_121_accuracy: 0.7427 - val_re_lu_177_accuracy: 0.8610 - val_re_lu_233_accuracy: 0.8908\n",
      "Learning rate:  5e-06\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4833 - re_lu_65_loss: 3.6963 - re_lu_121_loss: 1.1483 - re_lu_177_loss: 0.4069 - re_lu_233_loss: 0.2318 - re_lu_65_accuracy: 0.8675 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9610 - re_lu_233_accuracy: 0.9725  - ETA: 2:41 - loss: 5.9668 - re_lu_65_loss: 4.1190 - re_lu_121_loss: 1.2063 - re_lu_177_loss: 0.4163 - re_lu_233_loss: 0.2251 - re_lu_65_accuracy: 0.8618 - re_lu_121_accuracy: 0.8962 - re_lu_177_accuracy: 0.9 - ETA: 2:35 - loss: 6.0805 - re_lu_65_loss: 4.1767 - re_lu_121_loss: 1.2828 - re_lu_177_loss: 0.4081 - re_lu_233_loss: 0.2130 - re - ETA: 1:32 - loss: 5.5195 - re_lu_65_loss: 3.7386 - re_lu_121_loss: 1.1514 - re_lu_177_loss: 0.4019 - re_lu_233_loss: 0.2277 - re_lu_65_accuracy:  - ETA: 1:15 - loss: 5.5004 - re_lu_65_loss: 3.6987 - re_lu_121_loss: 1.1551 - re_lu_177_loss: 0.4121 - re_lu_233_loss: 0.2344 - re_lu_65_accuracy: 0.8665 - re_lu_121_accuracy: 0.9010 - re_lu_177_acc - ETA: 1:08 - loss: 5.4947 - re_lu_65_los - ETA: 45s - loss: 5.5136 - re_lu_65_loss: 3.7203 - re_lu_121_loss: 1.1564 - re_lu_177_loss: 0.4055 - re_lu_233_loss: 0.2314 - re_lu_65_accuracy: 0.8670 - re_lu_121_accuracy: 0.9018 - re_lu_177_acc - ETA: 42s - loss: 5.5226 - re_lu_65_loss - ETA: 24s - loss: 5.4738 - re_lu_65_loss: 3.6947 - re_lu_ - ETA: 5s - loss: 5.4871 - re_lu_65_loss: 3.7005 - re_lu_121_loss: 1.1513 - re_lu_177_loss: 0.4052 - re_lu_233_loss: 0.2301 - re_lu_65_accuracy: 0.8675 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9610\n",
      "Epoch 00134: loss improved from 5.49755 to 5.48333, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.4833 - re_lu_65_loss: 3.6963 - re_lu_121_loss: 1.1483 - re_lu_177_loss: 0.4069 - re_lu_233_loss: 0.2318 - re_lu_65_accuracy: 0.8675 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9610 - re_lu_233_accuracy: 0.9725 - val_loss: 155.8029 - val_re_lu_65_loss: 37.8984 - val_re_lu_121_loss: 38.4118 - val_re_lu_177_loss: 39.4235 - val_re_lu_233_loss: 40.0693 - val_re_lu_65_accuracy: 0.8299 - val_re_lu_121_accuracy: 0.7420 - val_re_lu_177_accuracy: 0.8589 - val_re_lu_233_accuracy: 0.8901\n",
      "Learning rate:  5e-06\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4776 - re_lu_65_loss: 3.6943 - re_lu_121_loss: 1.1455 - re_lu_177_loss: 0.4058 - re_lu_233_loss: 0.2319 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9020 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9727  - ETA: 2:28 - loss: 5.7879 - re_lu_65_loss: 3.8 - ETA: 1:53 - loss: 5.5441 - re_lu_65_loss: 3.7150 - re_lu_121_loss: 1.1715 - re_lu_177_loss: 0.4184 - re_lu_233_loss: 0.2393 - re_lu_65_accura - ETA: 11s - loss: 5.5007 - re_lu_65_loss: 3.7034 - re_lu_121_loss: 1.1552 - re_lu_177_loss: 0.4103 - re_lu_233_loss: 0.2319 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9 - ETA: 2s - loss: 5.4765 - re_lu_65_loss: 3.6897 - re_lu_121_loss: 1.1473 - re_lu_177_loss: 0.4067 - re_lu_233_loss: 0.2328 - re_lu_65_accuracy: 0.8681 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9610 - re_lu_233_a\n",
      "Epoch 00135: loss improved from 5.48333 to 5.47755, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.4776 - re_lu_65_loss: 3.6943 - re_lu_121_loss: 1.1455 - re_lu_177_loss: 0.4058 - re_lu_233_loss: 0.2319 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9020 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9727 - val_loss: 155.8557 - val_re_lu_65_loss: 37.9046 - val_re_lu_121_loss: 38.4280 - val_re_lu_177_loss: 39.4372 - val_re_lu_233_loss: 40.0859 - val_re_lu_65_accuracy: 0.8287 - val_re_lu_121_accuracy: 0.7456 - val_re_lu_177_accuracy: 0.8607 - val_re_lu_233_accuracy: 0.8905\n",
      "Learning rate:  5e-06\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4725 - re_lu_65_loss: 3.6935 - re_lu_121_loss: 1.1426 - re_lu_177_loss: 0.4051 - re_lu_233_loss: 0.2312 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9611 - re_lu_233_accuracy: 0.9725  - ETA: 2:12 - loss: 5.6269 - re_lu_65_loss: 3.7975 - re_lu_121_loss: 1.1830 - re_lu_177_loss: 0.4197 - re_lu_233_loss: 0.2266 - re_lu_65_accuracy: 0.8670  - ETA: 1:56 - loss: 5.5702 - re_lu_65_loss: 3.7577 - re_lu_121_loss: 1.1715 - re_lu_177_loss: 0.4064 - re_lu_233_loss: 0.2346 - re_lu_65_accuracy: 0.8674 - - ETA: 1: - ETA: 15s - loss: 5.5883 - re_lu_65_loss: 3.7709 - re_lu_121_loss: 1.1703 - re_lu_177_loss: 0.4100 - re_lu_233_loss: 0.2370 - re_lu_65_accuracy: 0.8664 - re_lu_121_accuracy: 0.9009 - re_lu_177 - ETA: 11s - loss: 5.5591 - re_lu_65_loss: 3.7461 - re_lu_121_loss: 1.1656 - re_lu_177_loss: 0.4108 - re_lu_233_loss: 0.2367 - re_lu_65_accuracy: 0.8669 - re_lu_121_\n",
      "Epoch 00136: loss improved from 5.47755 to 5.47247, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.4725 - re_lu_65_loss: 3.6935 - re_lu_121_loss: 1.1426 - re_lu_177_loss: 0.4051 - re_lu_233_loss: 0.2312 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9611 - re_lu_233_accuracy: 0.9725 - val_loss: 155.8821 - val_re_lu_65_loss: 37.9052 - val_re_lu_121_loss: 38.4303 - val_re_lu_177_loss: 39.4498 - val_re_lu_233_loss: 40.0969 - val_re_lu_65_accuracy: 0.8306 - val_re_lu_121_accuracy: 0.7432 - val_re_lu_177_accuracy: 0.8600 - val_re_lu_233_accuracy: 0.8899\n",
      "Learning rate:  5e-06\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4701 - re_lu_65_loss: 3.6907 - re_lu_121_loss: 1.1436 - re_lu_177_loss: 0.4053 - re_lu_233_loss: 0.2305 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9607 - re_lu_233_accuracy: 0.9721  - ETA: 2:07 - loss: 2.9917 - re_lu_65_loss: 2.0164 - re_lu_121_loss: 0.4815 - re_lu_177_loss: 0.3960 - re_lu_233_loss: 0.0977 - re_lu_65_accuracy: 0.8899 - re_lu_121_accuracy: 0.9254 - re_lu_177_accuracy: 0.9646 - - ETA: 2:52 - loss: 7.2120 - re_lu_65_loss: 4.5287 - re_lu_121_loss: 1.7504 - re_lu_177_loss: 0.6204 - re_lu_233_loss: 0.3124 - re_lu_65_accuracy: 0.8585 - re_lu_121_accuracy: 0.8896 - re_lu_177_accuracy: - ETA: 49s - loss: 5.4979 - re_lu_65_loss: 3.7134 - re_lu_121_loss: 1.1446 - re_l - ETA: 34s - loss: 5.5423 - re_lu_65_ - ETA: 16s - loss: 5.4686 - re_lu_65_loss: 3.6856 - re_lu_121_loss: 1.1412 - re_lu_177_loss: 0.4093 - re_lu_233_loss: 0.2325 - re_lu_65_accuracy: 0.8680 - re - ETA: 7s - loss: 5.4622 - re_lu_65_loss: 3.6844 - re_lu_121_loss: 1.1403 - re_lu_177_loss: 0.4067 - re_lu_233_loss: 0.2308 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9011 - re_lu_177_accuracy: 0.9604 - re_lu_233_a - ETA: 4s - loss: 5.4754 - re_lu_65_loss: 3.6928 - re_lu_121_loss: 1.1431 - re_lu_177_loss: 0.4080 - re_lu_233_loss: 0.2315 - re_lu_65_accuracy: 0.8681 - re_lu_121_accuracy: 0.9012 - re_lu_177_accuracy: 0.9605 -\n",
      "Epoch 00137: loss improved from 5.47247 to 5.47013, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.4701 - re_lu_65_loss: 3.6907 - re_lu_121_loss: 1.1436 - re_lu_177_loss: 0.4053 - re_lu_233_loss: 0.2305 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9607 - re_lu_233_accuracy: 0.9721 - val_loss: 155.9074 - val_re_lu_65_loss: 37.9168 - val_re_lu_121_loss: 38.4366 - val_re_lu_177_loss: 39.4542 - val_re_lu_233_loss: 40.0998 - val_re_lu_65_accuracy: 0.8314 - val_re_lu_121_accuracy: 0.7452 - val_re_lu_177_accuracy: 0.8613 - val_re_lu_233_accuracy: 0.8911\n",
      "Learning rate:  5e-06\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4594 - re_lu_65_loss: 3.6849 - re_lu_121_loss: 1.1418 - re_lu_177_loss: 0.4030 - re_lu_233_loss: 0.2298 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9612 - re_lu_233_accuracy: 0.9737  - ETA: 2:21 - loss: 5.5225 - re_lu_65_loss: 3.6288 - re_lu_121_loss: 1.2070 - re_lu_177_loss: 0.4302 - re_lu_233_loss: 0.2566 - re_lu_65_accuracy: 0. - ETA: 2:05 - loss: 5.8496 - re_lu_65_loss: 3.8672 - re_lu_121_loss: 1.2590 - re_lu_177_loss: 0.4598 - re_lu_233_loss: 0.2635 - re_lu_65_accuracy: 0.8648 - re_lu_121_accuracy: 0.8981 - re_lu_177_accuracy: 0.9596 - re_lu_233_accuracy: 0. - ETA: 2:04 - loss: 5.8291 - re_lu_65_loss: 3.8577 - re_lu_121_loss: 1.2540 - re_lu_177_loss: 0.4559 - re_lu_233_loss: 0.2615 - re_lu_65_accuracy: 0.8652 - re_lu_121_accuracy: 0.8984 - re_lu_177_accuracy: 0.9598 - re_lu_233 - ETA: 2:01 - loss: 5.7577 - re_lu_65_loss: 3.8082 - re_lu_121_loss: 1.2431 - re_lu_177_loss: 0.4529 - re_lu_233_loss: 0.2534 - re_lu_65_accuracy: 0.8662 - re_lu_121_accuracy: 0.8995 - re_lu_177_accuracy: 0.9601 - re_lu_233_accuracy: - ETA: 2:00 - loss: 5.7382 - re_lu_65_loss: 3.8004 - re_lu_121_loss: 1.2343 - re_lu_177_loss: 0.4528 - re_lu_233_loss: 0.2507 - re_lu_65_accuracy: 0.8664 - re_lu_121_accuracy: 0.899 - ETA: 1:05 - loss: 5.5460 - re_lu_65_loss: 3.7019 - re_lu_121_loss: 1.1640 - re_lu_177_loss: 0.4333 - re_lu_233_loss: 0.2468 - re_lu_65_accuracy: 0.8660 - re_lu_121_accura - ETA: 56s - loss: 5.4953 - re_lu_65_loss: 3.6715 - re_lu_121_loss: 1.158 - ETA: 41s - loss: 5.4882 - re_lu_65_loss: 3.6829 - re_lu_121_loss: 1.1548 - re_lu_177_loss: 0.4132 - re_lu_233_loss: 0.2372 - re_lu_65_accuracy: 0.8671 - re_lu_121_accuracy: 0.9007 - re_lu_177_a - ETA: 15s - loss: 5.5114 - re_lu_65_loss: 3.7090 - re_lu_121_loss: 1.1539 - re_lu_177_loss: 0.4141 - re_lu_233_loss: 0.234\n",
      "Epoch 00138: loss improved from 5.47013 to 5.45942, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.4594 - re_lu_65_loss: 3.6849 - re_lu_121_loss: 1.1418 - re_lu_177_loss: 0.4030 - re_lu_233_loss: 0.2298 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9612 - re_lu_233_accuracy: 0.9737 - val_loss: 155.8297 - val_re_lu_65_loss: 37.9021 - val_re_lu_121_loss: 38.4138 - val_re_lu_177_loss: 39.4298 - val_re_lu_233_loss: 40.0839 - val_re_lu_65_accuracy: 0.8316 - val_re_lu_121_accuracy: 0.7455 - val_re_lu_177_accuracy: 0.8618 - val_re_lu_233_accuracy: 0.8903\n",
      "Learning rate:  5e-06\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4578 - re_lu_65_loss: 3.6830 - re_lu_121_loss: 1.1406 - re_lu_177_loss: 0.4036 - re_lu_233_loss: 0.2306 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9732  - ETA: 2:35 - loss: 5.1865 - re_lu_65_loss: 3.5377 - re_lu_121_loss: 1.0603 - re_lu_177_loss: 0.3670 - re_lu_233_loss: 0.2216 - re_lu_65_accuracy: 0.8691 - re_lu_121_accuracy: 0.9038 - re_lu_177_accuracy: 0.9621 - re_lu_233_accuracy:  - ETA: 2:34 - loss: 5.1439 - re_lu_65_loss: 3.5 - ETA: 1:59 - loss: 5.1065 - re_lu_65_loss: 3.4825 - re_lu_121_loss: 1.0452 - re_lu_177_loss: 0.3618 - re_lu_233_loss: 0.2170 - re_lu_65_accuracy: 0.8710 - re_lu_121_accuracy: 0.9062 - re_lu_177_accuracy: 0.9623 - re_lu_233_accuracy - - ETA: 23s - loss: 5.4373 - re_lu_65_\n",
      "Epoch 00139: loss improved from 5.45942 to 5.45781, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 5.4578 - re_lu_65_loss: 3.6830 - re_lu_121_loss: 1.1406 - re_lu_177_loss: 0.4036 - re_lu_233_loss: 0.2306 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9732 - val_loss: 155.8357 - val_re_lu_65_loss: 37.8947 - val_re_lu_121_loss: 38.4227 - val_re_lu_177_loss: 39.4394 - val_re_lu_233_loss: 40.0790 - val_re_lu_65_accuracy: 0.8295 - val_re_lu_121_accuracy: 0.7429 - val_re_lu_177_accuracy: 0.8624 - val_re_lu_233_accuracy: 0.8896\n",
      "Learning rate:  5e-06\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4482 - re_lu_65_loss: 3.6787 - re_lu_121_loss: 1.1369 - re_lu_177_loss: 0.4025 - re_lu_233_loss: 0.2301 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9721  - ETA: 2:35 - loss: 5.4337 - re_lu_65_loss: 3.7235 - re_lu_121_loss: 1.1270 - re_lu_177_loss: 0.3762 - re_lu_233_loss: 0.2071 - re_lu_65_accuracy: 0.8641 - re_lu_121_accuracy: 0.9004 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9 - ETA: 2:34 - loss: 5.4672 - re_lu_65_loss: 3.7369 - re_lu_121_loss: 1.1419\n",
      "Epoch 00140: loss improved from 5.45781 to 5.44817, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.4482 - re_lu_65_loss: 3.6787 - re_lu_121_loss: 1.1369 - re_lu_177_loss: 0.4025 - re_lu_233_loss: 0.2301 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9721 - val_loss: 155.9047 - val_re_lu_65_loss: 37.9079 - val_re_lu_121_loss: 38.4351 - val_re_lu_177_loss: 39.4577 - val_re_lu_233_loss: 40.1040 - val_re_lu_65_accuracy: 0.8313 - val_re_lu_121_accuracy: 0.7477 - val_re_lu_177_accuracy: 0.8614 - val_re_lu_233_accuracy: 0.8908\n",
      "Learning rate:  5e-06\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4500 - re_lu_65_loss: 3.6842 - re_lu_121_loss: 1.1360 - re_lu_177_loss: 0.4011 - re_lu_233_loss: 0.2287 - re_lu_65_accuracy: 0.8672 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9725  - ETA: 1:49 - loss: 5.4441 - re_lu_65_loss: 3.6999 - re_lu_121_loss: 1.1486 - re_lu_177_loss: 0.3852 - re_lu_233_loss: 0.2104 - re_lu_65_accuracy: 0.8676 - re_lu_121_acc - ETA: 34s - loss: 5.4825 - re_lu_65_loss: 3.7068 - re_lu_121_loss: 1.1457 - re_lu_177_loss: 0.3981 - re_lu_233_loss: 0.2319 - re_lu_65_accuracy: 0.8670 - re_l\n",
      "Epoch 00141: loss did not improve from 5.44817\n",
      "1000/1000 [==============================] - 194s 194ms/step - loss: 5.4500 - re_lu_65_loss: 3.6842 - re_lu_121_loss: 1.1360 - re_lu_177_loss: 0.4011 - re_lu_233_loss: 0.2287 - re_lu_65_accuracy: 0.8672 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9725 - val_loss: 155.9009 - val_re_lu_65_loss: 37.9110 - val_re_lu_121_loss: 38.4449 - val_re_lu_177_loss: 39.4525 - val_re_lu_233_loss: 40.0927 - val_re_lu_65_accuracy: 0.8291 - val_re_lu_121_accuracy: 0.7450 - val_re_lu_177_accuracy: 0.8613 - val_re_lu_233_accuracy: 0.8908\n",
      "Learning rate:  5e-06\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4485 - re_lu_65_loss: 3.6806 - re_lu_121_loss: 1.1355 - re_lu_177_loss: 0.4026 - re_lu_233_loss: 0.2297 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9737  - ETA: 2:05 - loss: 5.5404 - re_lu_65_loss: 3.7117 - re_lu_121_loss: 1.1827 - re_lu_177_loss: 0.4078 - re_lu_233_loss: 0.2382 - re_lu_65_accuracy: 0.8680 - re_lu_1 - ETA: 1:51 - loss: 5.6068 - re_lu_65_loss: 3.7452 - re_lu_121_loss: 1.1973 - re_lu_177_loss: 0.4174 - re_lu_233_loss: 0.2469 - re_lu_65_accuracy: 0.8675 - re_lu_121_accuracy: 0. - ETA: 1:40 - loss: 5.5345 - re_lu_65_loss: 3.7150 - re_lu_121_loss: 1.1678 - re_lu_177_loss: 0.4097 - re_lu_233_loss: 0.2421 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy - ETA: 1:28 - loss: 5.5228 - re_lu_65_loss: 3.7258 - re_lu_121_loss: 1.1530 - re_lu_177_loss: 0.4024 - re_lu_233_loss: 0.241 - ETA: 41s - loss: 5.3857 - re_lu_65_loss: 3.6464 - re_lu_121_loss: 1.1191 - re_lu_177_loss: 0.3891 - re_lu_233_loss: 0.2311 - re_lu_65_accur - ETA: 32s - loss: 5.3575 - re_lu_65_loss: 3.6282 - re_lu_121_loss: 1.1134 - re_lu_177_loss: 0.3875 - re_lu_233_loss: 0.228 - ETA: 21s - loss: 5.4053 - re_lu_65_loss: 3.6523 - re_lu_1\n",
      "Epoch 00142: loss did not improve from 5.44817\n",
      "1000/1000 [==============================] - 194s 194ms/step - loss: 5.4485 - re_lu_65_loss: 3.6806 - re_lu_121_loss: 1.1355 - re_lu_177_loss: 0.4026 - re_lu_233_loss: 0.2297 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9613 - re_lu_233_accuracy: 0.9737 - val_loss: 155.9145 - val_re_lu_65_loss: 37.9141 - val_re_lu_121_loss: 38.4460 - val_re_lu_177_loss: 39.4550 - val_re_lu_233_loss: 40.0995 - val_re_lu_65_accuracy: 0.8285 - val_re_lu_121_accuracy: 0.7446 - val_re_lu_177_accuracy: 0.8609 - val_re_lu_233_accuracy: 0.8890\n",
      "Learning rate:  5e-06\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4405 - re_lu_65_loss: 3.6768 - re_lu_121_loss: 1.1344 - re_lu_177_loss: 0.4011 - re_lu_233_loss: 0.2282 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9722  - ETA: 2:50 - loss: 5.8649 - re_lu_65_loss: 3.9612 - re_lu_121_loss: 1.2210 - re_lu_177_loss: 0.4195 - re_lu_233_loss: 0.2631 - re_lu_65_accuracy: 0.8726 - re_lu_121_accuracy: 0.9059 - re_lu_177_ac - ETA: 2:47 - loss: 4.9092 - re_lu_65_loss: 3.4478 -  - ETA: 2:15 - loss: 5.1454 - re_lu_65_lo - ETA: 1:39 - loss: 5.3180 - re_lu_65_loss: 3.6453 - re_lu_121_loss: 1.0754 - re_lu_177_loss: 0.3841 - re_lu_233_loss: 0.2132 - re_lu_65_accuracy: 0.8662 - re_lu_121_accuracy: 0 - ETA: 1:27 - loss: 5.3944 - re_lu_65_loss: 3.6833 - re_lu_121_loss: 1.1083 - re_lu_177_loss: 0.3884 - re_lu_233_loss: 0.2143 - re_lu_65_accuracy: 0.8662 - re_lu_121_accuracy: 0.9031 - re_lu_177_accuracy:  - ETA: 1:21 - loss: 5.4687 - re_lu_65_loss: 3.7188 - re_lu_121_loss: 1.1306 - re_lu_177_loss: 0.4017 - re_lu_233_loss: 0.2176 - re_lu_65_accuracy: 0.8660 - re_lu_121_accuracy: 0.9027 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy:  - ETA: 1:20 - loss: 5.5053 - re_lu_65_loss: 3.7454 - re_lu_121_lo - ETA: 54s - loss: 5.4761 - re_lu_65_loss: 3.7322 - re_lu_121_loss: 1.1243 - re_lu_177_loss: 0.3992 - re_lu_233_loss: 0.2203 - re_lu_65_accuracy: 0.8664 - re_lu_121_accuracy: 0.9029 - re_lu_1 - ETA: 49s - loss: 5.4733 - re_lu_65_loss:  - ETA: 32s - loss: 5.4390 - re_lu_65_loss: 3.6794 - re_lu_121_loss: 1.1273 - re_lu_177_loss: 0.4030 - re_lu_233_loss: 0.2294 - re_lu_65_accuracy: 0.8671 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0 - ETA: 28s - loss: 5.4596 - re_lu_65_loss - ETA: 10s - loss: 5.4386 - re_lu_65_loss: 3.6781 - re_lu_121_loss: 1.1255 - re_lu_177_loss: 0.4048 - re_lu_233_loss: 0.2302 - re_lu_65_accuracy: 0.8670 - re_lu_121_accuracy\n",
      "Epoch 00143: loss improved from 5.44817 to 5.44051, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 5.4405 - re_lu_65_loss: 3.6768 - re_lu_121_loss: 1.1344 - re_lu_177_loss: 0.4011 - re_lu_233_loss: 0.2282 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9722 - val_loss: 155.9069 - val_re_lu_65_loss: 37.9150 - val_re_lu_121_loss: 38.4444 - val_re_lu_177_loss: 39.4532 - val_re_lu_233_loss: 40.0942 - val_re_lu_65_accuracy: 0.8307 - val_re_lu_121_accuracy: 0.7497 - val_re_lu_177_accuracy: 0.8629 - val_re_lu_233_accuracy: 0.8902\n",
      "Learning rate:  5e-06\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4294 - re_lu_65_loss: 3.6707 - re_lu_121_loss: 1.1327 - re_lu_177_loss: 0.3987 - re_lu_233_loss: 0.2273 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9610 - re_lu_233_accuracy: 0.9731- ETA: 8s - loss: 5.3846 - re_lu_65_loss: 3.6474 - re_lu_121_loss: 1.1175 - re_lu_177_loss: 0.3972 - re_lu_233_loss: 0.2227 - re_lu_65_accuracy: 0.8684 - re_lu_121_accuracy: 0.9029 - re_lu_177_\n",
      "Epoch 00144: loss improved from 5.44051 to 5.42941, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.4294 - re_lu_65_loss: 3.6707 - re_lu_121_loss: 1.1327 - re_lu_177_loss: 0.3987 - re_lu_233_loss: 0.2273 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9610 - re_lu_233_accuracy: 0.9731 - val_loss: 155.9197 - val_re_lu_65_loss: 37.9209 - val_re_lu_121_loss: 38.4515 - val_re_lu_177_loss: 39.4526 - val_re_lu_233_loss: 40.0947 - val_re_lu_65_accuracy: 0.8273 - val_re_lu_121_accuracy: 0.7455 - val_re_lu_177_accuracy: 0.8605 - val_re_lu_233_accuracy: 0.8892\n",
      "Learning rate:  5e-06\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4225 - re_lu_65_loss: 3.6656 - re_lu_121_loss: 1.1300 - re_lu_177_loss: 0.3990 - re_lu_233_loss: 0.2280 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9723  ETA: 10s - loss: 5.4078 - re_lu_65_loss: 3.6521 - re_lu_121_loss: 1.1267 - re_lu_177_loss: 0.4010 - re_lu_233_loss: 0.2280 - re_lu_65_accuracy: 0.8683 - re_lu_121_accuracy: 0.9016 \n",
      "Epoch 00145: loss improved from 5.42941 to 5.42255, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.4225 - re_lu_65_loss: 3.6656 - re_lu_121_loss: 1.1300 - re_lu_177_loss: 0.3990 - re_lu_233_loss: 0.2280 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9723 - val_loss: 155.8972 - val_re_lu_65_loss: 37.9044 - val_re_lu_121_loss: 38.4398 - val_re_lu_177_loss: 39.4562 - val_re_lu_233_loss: 40.0968 - val_re_lu_65_accuracy: 0.8303 - val_re_lu_121_accuracy: 0.7472 - val_re_lu_177_accuracy: 0.8618 - val_re_lu_233_accuracy: 0.8908\n",
      "Learning rate:  5e-06\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4223 - re_lu_65_loss: 3.6663 - re_lu_121_loss: 1.1307 - re_lu_177_loss: 0.3978 - re_lu_233_loss: 0.2274 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9015 - re_lu_177_accuracy: 0.9598 - re_lu_233_accuracy: 0.9723  ETA: 26s - loss: 5.4 - ETA: 2s - loss: 5.4393 - re_lu_65_loss: 3.6793 - re_lu_121_loss: 1.1332 - re_lu_177_loss: 0.3982 - re_lu_233_loss: 0.2286 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy: 0.9014 - re_lu_177_accuracy: 0.9598 - re_lu_233_\n",
      "Epoch 00146: loss improved from 5.42255 to 5.42226, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 5.4223 - re_lu_65_loss: 3.6663 - re_lu_121_loss: 1.1307 - re_lu_177_loss: 0.3978 - re_lu_233_loss: 0.2274 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9015 - re_lu_177_accuracy: 0.9598 - re_lu_233_accuracy: 0.9723 - val_loss: 155.9458 - val_re_lu_65_loss: 37.9143 - val_re_lu_121_loss: 38.4505 - val_re_lu_177_loss: 39.4689 - val_re_lu_233_loss: 40.1121 - val_re_lu_65_accuracy: 0.8297 - val_re_lu_121_accuracy: 0.7462 - val_re_lu_177_accuracy: 0.8611 - val_re_lu_233_accuracy: 0.8903\n",
      "Learning rate:  5e-06\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4170 - re_lu_65_loss: 3.6656 - re_lu_121_loss: 1.1271 - re_lu_177_loss: 0.3974 - re_lu_233_loss: 0.2269 - re_lu_65_accuracy: 0.8681 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9737  - ETA: 2:48 - loss: 6.0384 - re_lu_65_loss: 4.0721 - re - ETA: 2:18 - loss: 5.4151 - re_lu_65_loss: 3.7256 - re_lu_121_loss: 1.0655 - re_lu_177_loss: 0.3905 - re_lu_233_loss: 0.2336 - re_lu_65_accuracy: 0.8677 - re_lu_121_accuracy: 0.9059 - re_lu_177_accur - ETA: 2:10 - loss: 5.3264 - re_lu_65_loss: 3.6660 - re_lu_121_loss: 1.0610 - re_lu_177_loss: 0.3768 - re_lu_233_loss: 0.2225 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9053 - re_lu_177_accuracy: 0.9617 - re_l - ETA: 2:06 - loss: 5.3516 - re_lu_65_loss: 3.6921 - re_lu_121_loss: 1.0645 - re_lu_177_loss: 0.3758 - re_lu_233_loss: 0.2192 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9052 - re_lu_177_accuracy: 0.9618 - re_lu_233_accuracy: 0.9 - ETA: 2:06 - loss: 5.3315 - - ETA: 1:28 - loss: 5.3070 - re_lu_65_loss: 3.5987 - re_lu_121_loss: 1.0843 - re_lu_177_loss: 0.3939 - re_lu_233_loss: 0.2301 - re_lu_6 - ETA: 1:09 - loss: 5.3970 - re_lu_65_loss: 3.6506 - re_lu_121_loss: 1.1123 - re_lu_177_ - ETA: 4s - loss: 5.4342 - re_lu_65_loss: 3.6782 - re_lu_121_loss: 1.1329 - re_lu_177_loss: 0.3967 - re_lu_233_loss: 0.2263 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9607 - re_\n",
      "Epoch 00147: loss improved from 5.42226 to 5.41701, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 5.4170 - re_lu_65_loss: 3.6656 - re_lu_121_loss: 1.1271 - re_lu_177_loss: 0.3974 - re_lu_233_loss: 0.2269 - re_lu_65_accuracy: 0.8681 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9737 - val_loss: 155.9703 - val_re_lu_65_loss: 37.9260 - val_re_lu_121_loss: 38.4640 - val_re_lu_177_loss: 39.4713 - val_re_lu_233_loss: 40.1091 - val_re_lu_65_accuracy: 0.8293 - val_re_lu_121_accuracy: 0.7458 - val_re_lu_177_accuracy: 0.8622 - val_re_lu_233_accuracy: 0.8902\n",
      "Learning rate:  5e-06\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4210 - re_lu_65_loss: 3.6648 - re_lu_121_loss: 1.1286 - re_lu_177_loss: 0.3988 - re_lu_233_loss: 0.2288 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9728  - ETA: 2:50 - loss: - ETA: 1s - loss: 5.4272 - re_lu_65_loss: 3.6673 - re_lu_121_loss: 1.1299 - re_lu_177_loss: 0.4005 - re_lu_233_loss: 0.2296 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9029 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy:\n",
      "Epoch 00148: loss did not improve from 5.41701\n",
      "1000/1000 [==============================] - 196s 196ms/step - loss: 5.4210 - re_lu_65_loss: 3.6648 - re_lu_121_loss: 1.1286 - re_lu_177_loss: 0.3988 - re_lu_233_loss: 0.2288 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9728 - val_loss: 155.8882 - val_re_lu_65_loss: 37.9063 - val_re_lu_121_loss: 38.4427 - val_re_lu_177_loss: 39.4458 - val_re_lu_233_loss: 40.0934 - val_re_lu_65_accuracy: 0.8299 - val_re_lu_121_accuracy: 0.7457 - val_re_lu_177_accuracy: 0.8607 - val_re_lu_233_accuracy: 0.8911\n",
      "Learning rate:  5e-06\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4048 - re_lu_65_loss: 3.6588 - re_lu_121_loss: 1.1248 - re_lu_177_loss: 0.3962 - re_lu_233_loss: 0.2251 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9730  - ETA: 2:36 - loss: 5.5936 - re_lu_65_loss: 3.7772 - re_lu_121_loss: 1.1408 - re_lu_177_loss: 0.4199 - re_lu_233_loss: 0.2557 - re_lu_65_accuracy: 0.8644 - re_lu_121_accuracy: 0.9001 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9 - ETA: 2:35 - loss: 5.5741 - re_lu_65_loss: 3.7602 - re_lu_121_loss: 1.141\n",
      "Epoch 00149: loss improved from 5.41701 to 5.40476, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 5.4048 - re_lu_65_loss: 3.6588 - re_lu_121_loss: 1.1248 - re_lu_177_loss: 0.3962 - re_lu_233_loss: 0.2251 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9730 - val_loss: 155.9467 - val_re_lu_65_loss: 37.9202 - val_re_lu_121_loss: 38.4598 - val_re_lu_177_loss: 39.4617 - val_re_lu_233_loss: 40.1050 - val_re_lu_65_accuracy: 0.8278 - val_re_lu_121_accuracy: 0.7478 - val_re_lu_177_accuracy: 0.8612 - val_re_lu_233_accuracy: 0.8900\n",
      "Learning rate:  5e-06\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3979 - re_lu_65_loss: 3.6566 - re_lu_121_loss: 1.1208 - re_lu_177_loss: 0.3954 - re_lu_233_loss: 0.2252 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9724  ETA: 13s - loss: 5.4364 - re_lu_65_loss: 3.6670 - re_lu_121_loss: 1.1363 - re_lu_177_loss: 0.4056 - re_lu_233_loss: 0.2275 - re_lu_65_accuracy: 0.8\n",
      "Epoch 00150: loss improved from 5.40476 to 5.39789, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 203s 203ms/step - loss: 5.3979 - re_lu_65_loss: 3.6566 - re_lu_121_loss: 1.1208 - re_lu_177_loss: 0.3954 - re_lu_233_loss: 0.2252 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9724 - val_loss: 155.9229 - val_re_lu_65_loss: 37.9113 - val_re_lu_121_loss: 38.4553 - val_re_lu_177_loss: 39.4545 - val_re_lu_233_loss: 40.1016 - val_re_lu_65_accuracy: 0.8281 - val_re_lu_121_accuracy: 0.7465 - val_re_lu_177_accuracy: 0.8618 - val_re_lu_233_accuracy: 0.8897\n",
      "Learning rate:  5e-06\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.4006 - re_lu_65_loss: 3.6571 - re_lu_121_loss: 1.1231 - re_lu_177_loss: 0.3952 - re_lu_233_loss: 0.2252 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9724  - ETA: 2:40 - loss: 5.2729 - re_lu_65_loss: 3.6952 - re_lu_121_loss: 1.029 - ETA: 2:11 - loss: 5.6314 - re_lu_65_loss: 3.8693 - re_lu_121_loss: 1.1904 - re_lu_177_loss: 0.3807 - re_lu_233_loss: 0.1910 - re_lu_65_accuracy: 0.8665 - re_lu_121_accuracy: 0.9007 - re_ - ETA: 2:01 - loss: 5.5274 - re_lu_65_loss: 3.7887 - re_lu_121_loss: 1.1640 - re_lu_177_loss: 0.3787 - re_lu_233_loss: 0.1960 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9611 - re_ - ETA: 1:57 - loss: 5.5660 - re_lu_65_loss: 3.7852 - re_lu_121_loss: 1.1752 - re_lu_177_loss: 0.3951 -  - ETA: 1:32 - loss: 5.3581 - re_lu_65_loss: 3.6535 - re_lu_121_loss: 1.1168 - re_lu_177_loss: 0.3827 - re_lu_233_loss: 0.2051 - re_lu_65_accuracy: 0.8692 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9614 -  - ETA: 1:28 - loss: 5.2953 - re_lu_65_loss: 3.6135 - re_lu_121_loss: 1.0955 - re_lu_177_los - ETA: 1: - ETA: 39s - loss: 5.3797 - re_lu_65_loss: 3.6527 - re_lu_121_loss: 1.1231 - re_lu_177_loss: 0.3865 - re_lu_233_loss: 0.2175 - re_lu_65_accuracy: 0.8683 - re_lu_121_accuracy: 0.9031 - re_lu_177_accuracy: 0.9610 - re - ETA: 16s - loss: 5.4671 - re_lu_65_loss: 3.6971 - re_lu_121_loss: 1.1394 - re_lu_177_loss: 0.4018 - re_lu_233_lo\n",
      "Epoch 00151: loss did not improve from 5.39789\n",
      "1000/1000 [==============================] - 192s 192ms/step - loss: 5.4006 - re_lu_65_loss: 3.6571 - re_lu_121_loss: 1.1231 - re_lu_177_loss: 0.3952 - re_lu_233_loss: 0.2252 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9724 - val_loss: 155.9442 - val_re_lu_65_loss: 37.9139 - val_re_lu_121_loss: 38.4627 - val_re_lu_177_loss: 39.4645 - val_re_lu_233_loss: 40.1031 - val_re_lu_65_accuracy: 0.8292 - val_re_lu_121_accuracy: 0.7454 - val_re_lu_177_accuracy: 0.8615 - val_re_lu_233_accuracy: 0.8884\n",
      "Learning rate:  5e-06\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3875 - re_lu_65_loss: 3.6500 - re_lu_121_loss: 1.1180 - re_lu_177_loss: 0.3945 - re_lu_233_loss: 0.2250 - re_lu_65_accuracy: 0.8676 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9725  - ETA: 2:49 - loss: 3.9595 - re_lu_65_loss: 2.7453 - re_lu_121_loss: 0.8366 - re_lu_177_loss: 0.2419 - re_lu_233_loss: 0.1356 - re_lu_65_accuracy: 0.8778 - re_lu_121_accuracy: 0.9087 - re_lu_177_accur\n",
      "Epoch 00152: loss improved from 5.39789 to 5.38748, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 211s 211ms/step - loss: 5.3875 - re_lu_65_loss: 3.6500 - re_lu_121_loss: 1.1180 - re_lu_177_loss: 0.3945 - re_lu_233_loss: 0.2250 - re_lu_65_accuracy: 0.8676 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9604 - re_lu_233_accuracy: 0.9725 - val_loss: 156.0033 - val_re_lu_65_loss: 37.9236 - val_re_lu_121_loss: 38.4778 - val_re_lu_177_loss: 39.4797 - val_re_lu_233_loss: 40.1222 - val_re_lu_65_accuracy: 0.8300 - val_re_lu_121_accuracy: 0.7444 - val_re_lu_177_accuracy: 0.8604 - val_re_lu_233_accuracy: 0.8890\n",
      "Learning rate:  5e-06\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3856 - re_lu_65_loss: 3.6485 - re_lu_121_loss: 1.1185 - re_lu_177_loss: 0.3940 - re_lu_233_loss: 0.2246 - re_lu_65_accuracy: 0.8676 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9734  ETA: 23s - lo\n",
      "Epoch 00153: loss improved from 5.38748 to 5.38560, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 492s 492ms/step - loss: 5.3856 - re_lu_65_loss: 3.6485 - re_lu_121_loss: 1.1185 - re_lu_177_loss: 0.3940 - re_lu_233_loss: 0.2246 - re_lu_65_accuracy: 0.8676 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9734 - val_loss: 155.9967 - val_re_lu_65_loss: 37.9165 - val_re_lu_121_loss: 38.4722 - val_re_lu_177_loss: 39.4856 - val_re_lu_233_loss: 40.1225 - val_re_lu_65_accuracy: 0.8302 - val_re_lu_121_accuracy: 0.7474 - val_re_lu_177_accuracy: 0.8621 - val_re_lu_233_accuracy: 0.8894\n",
      "Learning rate:  5e-06\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3744 - re_lu_65_loss: 3.6426 - re_lu_121_loss: 1.1145 - re_lu_177_loss: 0.3933 - re_lu_233_loss: 0.2240 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9727\n",
      "Epoch 00154: loss improved from 5.38560 to 5.37444, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 1217s 1s/step - loss: 5.3744 - re_lu_65_loss: 3.6426 - re_lu_121_loss: 1.1145 - re_lu_177_loss: 0.3933 - re_lu_233_loss: 0.2240 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9026 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9727 - val_loss: 156.0057 - val_re_lu_65_loss: 37.9230 - val_re_lu_121_loss: 38.4690 - val_re_lu_177_loss: 39.4886 - val_re_lu_233_loss: 40.1251 - val_re_lu_65_accuracy: 0.8273 - val_re_lu_121_accuracy: 0.7463 - val_re_lu_177_accuracy: 0.8612 - val_re_lu_233_accuracy: 0.8891\n",
      "Learning rate:  5e-06\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3792 - re_lu_65_loss: 3.6492 - re_lu_121_loss: 1.1136 - re_lu_177_loss: 0.3924 - re_lu_233_loss: 0.2240 - re_lu_65_accuracy: 0.8675 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9602 - re_lu_233_accuracy: 0.9719  - ETA: 1:17 - loss: 5.3801 - re_lu_65_loss: 3.6589 - r\n",
      "Epoch 00155: loss did not improve from 5.37444\n",
      "1000/1000 [==============================] - 644s 644ms/step - loss: 5.3792 - re_lu_65_loss: 3.6492 - re_lu_121_loss: 1.1136 - re_lu_177_loss: 0.3924 - re_lu_233_loss: 0.2240 - re_lu_65_accuracy: 0.8675 - re_lu_121_accuracy: 0.9021 - re_lu_177_accuracy: 0.9602 - re_lu_233_accuracy: 0.9719 - val_loss: 156.0153 - val_re_lu_65_loss: 37.9236 - val_re_lu_121_loss: 38.4818 - val_re_lu_177_loss: 39.4852 - val_re_lu_233_loss: 40.1247 - val_re_lu_65_accuracy: 0.8277 - val_re_lu_121_accuracy: 0.7479 - val_re_lu_177_accuracy: 0.8615 - val_re_lu_233_accuracy: 0.8886\n",
      "Learning rate:  5e-06\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3727 - re_lu_65_loss: 3.6445 - re_lu_121_loss: 1.1139 - re_lu_177_loss: 0.3915 - re_lu_233_loss: 0.2228 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9603 - re_lu_233_accuracy: 0.9726\n",
      "Epoch 00156: loss improved from 5.37444 to 5.37274, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 437s 437ms/step - loss: 5.3727 - re_lu_65_loss: 3.6445 - re_lu_121_loss: 1.1139 - re_lu_177_loss: 0.3915 - re_lu_233_loss: 0.2228 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9603 - re_lu_233_accuracy: 0.9726 - val_loss: 155.9451 - val_re_lu_65_loss: 37.9108 - val_re_lu_121_loss: 38.4621 - val_re_lu_177_loss: 39.4656 - val_re_lu_233_loss: 40.1066 - val_re_lu_65_accuracy: 0.8315 - val_re_lu_121_accuracy: 0.7526 - val_re_lu_177_accuracy: 0.8632 - val_re_lu_233_accuracy: 0.8901\n",
      "Learning rate:  5e-06\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3764 - re_lu_65_loss: 3.6460 - re_lu_121_loss: 1.1133 - re_lu_177_loss: 0.3928 - re_lu_233_loss: 0.2242 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9722\n",
      "Epoch 00157: loss did not improve from 5.37274\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 5.3764 - re_lu_65_loss: 3.6460 - re_lu_121_loss: 1.1133 - re_lu_177_loss: 0.3928 - re_lu_233_loss: 0.2242 - re_lu_65_accuracy: 0.8673 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9722 - val_loss: 155.9598 - val_re_lu_65_loss: 37.9061 - val_re_lu_121_loss: 38.4590 - val_re_lu_177_loss: 39.4751 - val_re_lu_233_loss: 40.1197 - val_re_lu_65_accuracy: 0.8297 - val_re_lu_121_accuracy: 0.7489 - val_re_lu_177_accuracy: 0.8629 - val_re_lu_233_accuracy: 0.8905\n",
      "Learning rate:  5e-06\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3598 - re_lu_65_loss: 3.6334 - re_lu_121_loss: 1.1114 - re_lu_177_loss: 0.3919 - re_lu_233_loss: 0.2232 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9744\n",
      "Epoch 00158: loss improved from 5.37274 to 5.35985, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 229s 229ms/step - loss: 5.3598 - re_lu_65_loss: 3.6334 - re_lu_121_loss: 1.1114 - re_lu_177_loss: 0.3919 - re_lu_233_loss: 0.2232 - re_lu_65_accuracy: 0.8679 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9744 - val_loss: 155.9881 - val_re_lu_65_loss: 37.9160 - val_re_lu_121_loss: 38.4675 - val_re_lu_177_loss: 39.4827 - val_re_lu_233_loss: 40.1220 - val_re_lu_65_accuracy: 0.8279 - val_re_lu_121_accuracy: 0.7442 - val_re_lu_177_accuracy: 0.8629 - val_re_lu_233_accuracy: 0.8886\n",
      "Learning rate:  5e-06\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3573 - re_lu_65_loss: 3.6347 - re_lu_121_loss: 1.1093 - re_lu_177_loss: 0.3904 - re_lu_233_loss: 0.2229 - re_lu_65_accuracy: 0.8689 - re_lu_121_accuracy: 0.9024 - re_lu_177_accuracy: 0.9612 - re_lu_233_accuracy: 0.9729\n",
      "Epoch 00159: loss improved from 5.35985 to 5.35728, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 230s 230ms/step - loss: 5.3573 - re_lu_65_loss: 3.6347 - re_lu_121_loss: 1.1093 - re_lu_177_loss: 0.3904 - re_lu_233_loss: 0.2229 - re_lu_65_accuracy: 0.8689 - re_lu_121_accuracy: 0.9024 - re_lu_177_accuracy: 0.9612 - re_lu_233_accuracy: 0.9729 - val_loss: 156.0192 - val_re_lu_65_loss: 37.9340 - val_re_lu_121_loss: 38.4804 - val_re_lu_177_loss: 39.4838 - val_re_lu_233_loss: 40.1210 - val_re_lu_65_accuracy: 0.8282 - val_re_lu_121_accuracy: 0.7512 - val_re_lu_177_accuracy: 0.8641 - val_re_lu_233_accuracy: 0.8903\n",
      "Learning rate:  5e-06\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3564 - re_lu_65_loss: 3.6372 - re_lu_121_loss: 1.1062 - re_lu_177_loss: 0.3899 - re_lu_233_loss: 0.2230 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9016 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9722\n",
      "Epoch 00160: loss improved from 5.35728 to 5.35640, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 230s 230ms/step - loss: 5.3564 - re_lu_65_loss: 3.6372 - re_lu_121_loss: 1.1062 - re_lu_177_loss: 0.3899 - re_lu_233_loss: 0.2230 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9016 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9722 - val_loss: 155.9872 - val_re_lu_65_loss: 37.9234 - val_re_lu_121_loss: 38.4694 - val_re_lu_177_loss: 39.4746 - val_re_lu_233_loss: 40.1198 - val_re_lu_65_accuracy: 0.8288 - val_re_lu_121_accuracy: 0.7495 - val_re_lu_177_accuracy: 0.8630 - val_re_lu_233_accuracy: 0.8902\n",
      "Learning rate:  5e-06\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3386 - re_lu_65_loss: 3.6272 - re_lu_121_loss: 1.1034 - re_lu_177_loss: 0.3873 - re_lu_233_loss: 0.2207 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9728\n",
      "Epoch 00161: loss improved from 5.35640 to 5.33859, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 243s 243ms/step - loss: 5.3386 - re_lu_65_loss: 3.6272 - re_lu_121_loss: 1.1034 - re_lu_177_loss: 0.3873 - re_lu_233_loss: 0.2207 - re_lu_65_accuracy: 0.8686 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9728 - val_loss: 156.0205 - val_re_lu_65_loss: 37.9300 - val_re_lu_121_loss: 38.4846 - val_re_lu_177_loss: 39.4856 - val_re_lu_233_loss: 40.1205 - val_re_lu_65_accuracy: 0.8305 - val_re_lu_121_accuracy: 0.7502 - val_re_lu_177_accuracy: 0.8633 - val_re_lu_233_accuracy: 0.8899\n",
      "Learning rate:  5e-07\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3434 - re_lu_65_loss: 3.6267 - re_lu_121_loss: 1.1054 - re_lu_177_loss: 0.3892 - re_lu_233_loss: 0.2221 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9719\n",
      "Epoch 00162: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 5.3434 - re_lu_65_loss: 3.6267 - re_lu_121_loss: 1.1054 - re_lu_177_loss: 0.3892 - re_lu_233_loss: 0.2221 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9719 - val_loss: 155.9887 - val_re_lu_65_loss: 37.9244 - val_re_lu_121_loss: 38.4780 - val_re_lu_177_loss: 39.4781 - val_re_lu_233_loss: 40.1082 - val_re_lu_65_accuracy: 0.8290 - val_re_lu_121_accuracy: 0.7484 - val_re_lu_177_accuracy: 0.8616 - val_re_lu_233_accuracy: 0.8894\n",
      "Learning rate:  5e-07\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3415 - re_lu_65_loss: 3.6266 - re_lu_121_loss: 1.1045 - re_lu_177_loss: 0.3889 - re_lu_233_loss: 0.2215 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9719- ETA: 5s - loss: 5.3046 - re_lu_65_loss: 3.6044 - re_lu_121_loss: 1.0965 - re_lu_177_loss: 0.3856 - re_lu_233_loss: 0.2181 - re_lu_65_accuracy: 0.8684 - re_lu_121_accuracy: 0.9025 - re_lu_177_accuracy: 0.9606 - \n",
      "Epoch 00163: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 217s 217ms/step - loss: 5.3415 - re_lu_65_loss: 3.6266 - re_lu_121_loss: 1.1045 - re_lu_177_loss: 0.3889 - re_lu_233_loss: 0.2215 - re_lu_65_accuracy: 0.8680 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9605 - re_lu_233_accuracy: 0.9719 - val_loss: 156.0099 - val_re_lu_65_loss: 37.9317 - val_re_lu_121_loss: 38.4839 - val_re_lu_177_loss: 39.4807 - val_re_lu_233_loss: 40.1137 - val_re_lu_65_accuracy: 0.8271 - val_re_lu_121_accuracy: 0.7472 - val_re_lu_177_accuracy: 0.8620 - val_re_lu_233_accuracy: 0.8894\n",
      "Learning rate:  5e-07\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3465 - re_lu_65_loss: 3.6294 - re_lu_121_loss: 1.1060 - re_lu_177_loss: 0.3892 - re_lu_233_loss: 0.2220 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9024 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9717\n",
      "Epoch 00164: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 219s 219ms/step - loss: 5.3465 - re_lu_65_loss: 3.6294 - re_lu_121_loss: 1.1060 - re_lu_177_loss: 0.3892 - re_lu_233_loss: 0.2220 - re_lu_65_accuracy: 0.8685 - re_lu_121_accuracy: 0.9024 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9717 - val_loss: 156.0041 - val_re_lu_65_loss: 37.9289 - val_re_lu_121_loss: 38.4879 - val_re_lu_177_loss: 39.4743 - val_re_lu_233_loss: 40.1129 - val_re_lu_65_accuracy: 0.8314 - val_re_lu_121_accuracy: 0.7517 - val_re_lu_177_accuracy: 0.8646 - val_re_lu_233_accuracy: 0.8899\n",
      "Learning rate:  5e-07\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3551 - re_lu_65_loss: 3.6380 - re_lu_121_loss: 1.1050 - re_lu_177_loss: 0.3893 - re_lu_233_loss: 0.2228 - re_lu_65_accuracy: 0.8676 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9721\n",
      "Epoch 00165: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 5.3551 - re_lu_65_loss: 3.6380 - re_lu_121_loss: 1.1050 - re_lu_177_loss: 0.3893 - re_lu_233_loss: 0.2228 - re_lu_65_accuracy: 0.8676 - re_lu_121_accuracy: 0.9023 - re_lu_177_accuracy: 0.9608 - re_lu_233_accuracy: 0.9721 - val_loss: 155.9933 - val_re_lu_65_loss: 37.9321 - val_re_lu_121_loss: 38.4794 - val_re_lu_177_loss: 39.4696 - val_re_lu_233_loss: 40.1123 - val_re_lu_65_accuracy: 0.8284 - val_re_lu_121_accuracy: 0.7522 - val_re_lu_177_accuracy: 0.8646 - val_re_lu_233_accuracy: 0.8907\n",
      "Learning rate:  5e-07\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3451 - re_lu_65_loss: 3.6321 - re_lu_121_loss: 1.1036 - re_lu_177_loss: 0.3882 - re_lu_233_loss: 0.2212 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9721\n",
      "Epoch 00166: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 217s 217ms/step - loss: 5.3451 - re_lu_65_loss: 3.6321 - re_lu_121_loss: 1.1036 - re_lu_177_loss: 0.3882 - re_lu_233_loss: 0.2212 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9018 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9721 - val_loss: 155.9815 - val_re_lu_65_loss: 37.9290 - val_re_lu_121_loss: 38.4777 - val_re_lu_177_loss: 39.4671 - val_re_lu_233_loss: 40.1076 - val_re_lu_65_accuracy: 0.8264 - val_re_lu_121_accuracy: 0.7475 - val_re_lu_177_accuracy: 0.8627 - val_re_lu_233_accuracy: 0.8896\n",
      "Learning rate:  5e-07\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3412 - re_lu_65_loss: 3.6277 - re_lu_121_loss: 1.1037 - re_lu_177_loss: 0.3885 - re_lu_233_loss: 0.2213 - re_lu_65_accuracy: 0.8683 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9724\n",
      "Epoch 00167: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 220s 220ms/step - loss: 5.3412 - re_lu_65_loss: 3.6277 - re_lu_121_loss: 1.1037 - re_lu_177_loss: 0.3885 - re_lu_233_loss: 0.2213 - re_lu_65_accuracy: 0.8683 - re_lu_121_accuracy: 0.9019 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9724 - val_loss: 155.9962 - val_re_lu_65_loss: 37.9336 - val_re_lu_121_loss: 38.4796 - val_re_lu_177_loss: 39.4711 - val_re_lu_233_loss: 40.1119 - val_re_lu_65_accuracy: 0.8284 - val_re_lu_121_accuracy: 0.7513 - val_re_lu_177_accuracy: 0.8629 - val_re_lu_233_accuracy: 0.8897\n",
      "Learning rate:  5e-07\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3492 - re_lu_65_loss: 3.6329 - re_lu_121_loss: 1.1055 - re_lu_177_loss: 0.3892 - re_lu_233_loss: 0.2216 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9729\n",
      "Epoch 00168: loss did not improve from 5.33859\n",
      "1000/1000 [==============================] - 219s 219ms/step - loss: 5.3492 - re_lu_65_loss: 3.6329 - re_lu_121_loss: 1.1055 - re_lu_177_loss: 0.3892 - re_lu_233_loss: 0.2216 - re_lu_65_accuracy: 0.8678 - re_lu_121_accuracy: 0.9022 - re_lu_177_accuracy: 0.9609 - re_lu_233_accuracy: 0.9729 - val_loss: 156.0036 - val_re_lu_65_loss: 37.9241 - val_re_lu_121_loss: 38.4810 - val_re_lu_177_loss: 39.4784 - val_re_lu_233_loss: 40.1201 - val_re_lu_65_accuracy: 0.8299 - val_re_lu_121_accuracy: 0.7488 - val_re_lu_177_accuracy: 0.8632 - val_re_lu_233_accuracy: 0.8891\n",
      "Learning rate:  5e-07\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3299 - re_lu_65_loss: 3.6240 - re_lu_121_loss: 1.1008 - re_lu_177_loss: 0.3860 - re_lu_233_loss: 0.2192 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9611 - re_lu_233_accuracy: 0.9738\n",
      "Epoch 00169: loss improved from 5.33859 to 5.32995, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 232s 232ms/step - loss: 5.3299 - re_lu_65_loss: 3.6240 - re_lu_121_loss: 1.1008 - re_lu_177_loss: 0.3860 - re_lu_233_loss: 0.2192 - re_lu_65_accuracy: 0.8682 - re_lu_121_accuracy: 0.9028 - re_lu_177_accuracy: 0.9611 - re_lu_233_accuracy: 0.9738 - val_loss: 156.0576 - val_re_lu_65_loss: 37.9408 - val_re_lu_121_loss: 38.5019 - val_re_lu_177_loss: 39.4919 - val_re_lu_233_loss: 40.1229 - val_re_lu_65_accuracy: 0.8257 - val_re_lu_121_accuracy: 0.7506 - val_re_lu_177_accuracy: 0.8627 - val_re_lu_233_accuracy: 0.8901\n",
      "Learning rate:  5e-07\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3268 - re_lu_65_loss: 3.6210 - re_lu_121_loss: 1.1010 - re_lu_177_loss: 0.3858 - re_lu_233_loss: 0.2190 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9728  ETA: 27s - loss\n",
      "Epoch 00170: loss improved from 5.32995 to 5.32680, saving model to single_person_model.h5\n",
      "1000/1000 [==============================] - 247s 247ms/step - loss: 5.3268 - re_lu_65_loss: 3.6210 - re_lu_121_loss: 1.1010 - re_lu_177_loss: 0.3858 - re_lu_233_loss: 0.2190 - re_lu_65_accuracy: 0.8674 - re_lu_121_accuracy: 0.9017 - re_lu_177_accuracy: 0.9606 - re_lu_233_accuracy: 0.9728 - val_loss: 156.0276 - val_re_lu_65_loss: 37.9374 - val_re_lu_121_loss: 38.4918 - val_re_lu_177_loss: 39.4809 - val_re_lu_233_loss: 40.1176 - val_re_lu_65_accuracy: 0.8294 - val_re_lu_121_accuracy: 0.7494 - val_re_lu_177_accuracy: 0.8642 - val_re_lu_233_accuracy: 0.8903\n",
      "Learning rate:  5e-07\n",
      "Epoch 171/200\n",
      " 221/1000 [=====>........................] - ETA: 8:55 - loss: 5.5116 - re_lu_65_loss: 3.6867 - re_lu_121_loss: 1.1619 - re_lu_177_loss: 0.4269 - re_lu_233_loss: 0.2360 - re_lu_65_accuracy: 0.8652 - re_lu_121_accuracy: 0.8995 - re_lu_177_accuracy: 0.9603 - re_lu_233_accuracy: 0.9731"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), batch_size=4, callbacks = callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
